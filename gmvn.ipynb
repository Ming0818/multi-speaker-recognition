{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2289 DR1-MCPM0-SA1-00.wav\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "indir = 'chunks/' # already VAD\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "mypath = 'chunks/'\n",
    "flist = [f for f in listdir(indir) if isfile(join(indir, f))]\n",
    "print(len(flist), flist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attributes(fname):\n",
    "    attr = fname.split('.')[0].split('-')\n",
    "    dialect = attr[0]\n",
    "    gender = attr[1][0]\n",
    "    speaker_id = attr[1]\n",
    "    sentence_type = attr[2][:2]\n",
    "    return dialect, gender, speaker_id, sentence_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = {}\n",
    "test = {}\n",
    "\n",
    "for fname in flist:\n",
    "    input_path = indir + fname\n",
    "    y, sr = librosa.load(input_path, sr=None) # set sr=None for orig file sr otherwise it is converted to ~22K\n",
    "\n",
    "    # scaling the maximum of absolute amplitude to 1\n",
    "    processed_data = y/max(abs(y))\n",
    "    \n",
    "    # TODO: calc VAD (already done)\n",
    "    \n",
    "    # https://groups.google.com/forum/#!topic/librosa/V4Z1HpTKn8Q\n",
    "    mfcc = librosa.feature.mfcc(y=processed_data, sr=sr, n_mfcc=13, n_fft=(25*sr)//1000, hop_length=(10*sr)//1000)\n",
    "    mfcc[0] = librosa.feature.rmse(processed_data, hop_length=int(0.010*sr), n_fft=int(0.025*sr)) \n",
    "    mfcc_delta = librosa.feature.delta(mfcc)\n",
    "    mfcc_delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "    features = np.vstack([mfcc, mfcc_delta, mfcc_delta2]) \n",
    "    \n",
    "    # split train test\n",
    "    dialect, gender, speaker_id, sentence_type = get_attributes(fname)\n",
    "    if sentence_type == 'SA':\n",
    "        test.setdefault(speaker_id, []).append(features)\n",
    "    else:\n",
    "        train.setdefault(speaker_id, []).append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MADC0', 'MAEB0', 'MAKB0', 'MAKR0', 'MAPV0', 'MARC0', 'MARW0', 'MBEF0', 'MBGT0', 'MBJV0', 'MBMA0', 'MBWP0', 'MCAL0', 'MCDC0', 'MCDD0', 'MCDR0', 'MCEF0', 'MCEW0', 'MCHL0', 'MCLM0', 'MCPM0', 'MCSS0', 'MCTM0', 'MDAC0', 'MDAS0', 'MDBB1', 'MDBP0', 'MDCD0', 'MDDC0', 'MDEF0', 'MDEM0', 'MDHL0', 'MDHS0', 'MDJM0', 'MDLB0', 'MDLC0', 'MDLC2', 'MDLH0', 'MDMA0', 'MDMT0', 'MDNS0', 'MDPK0', 'MDPS0', 'MDSJ0', 'MDSS0', 'MDSS1', 'MDTB0', 'MDWD0', 'MDWH0', 'MDWM0', 'MEDR0', 'MEFG0', 'MEGJ0', 'MESG0', 'MEWM0', 'MFER0', 'MFMC0', 'MFRM0', 'MFWK0', 'MGAF0', 'MGAG0', 'MGES0', 'MGJC0', 'MGRL0', 'MGRP0', 'MGSH0', 'MGXP0', 'MHIT0', 'MHJB0', 'MHMG0', 'MHMR0', 'MHRM0', 'MILB0', 'MJAC0', 'MJAE0', 'MJBG0', 'MJDA0', 'MJDC0', 'MJDE0', 'MJEB0', 'MJEB1', 'MJEE0', 'MJHI0', 'MJJB0', 'MJJJ0', 'MJKR0', 'MJLB0', 'MJLG1', 'MJLS0', 'MJMA0', 'MJMD0', 'MJMM0', 'MJPM0', 'MJPM1', 'MJRH0', 'MJRH1', 'MJRP0', 'MJSR0', 'MJWS0', 'MJWT0', 'MJXL0', 'MKAH0', 'MKAJ0', 'MKAM0', 'MKDT0', 'MKJO0', 'MKLS0', 'MKLS1', 'MKLW0', 'MKXL0', 'MLBC0', 'MLEL0', 'MLJC0', 'MLJH0', 'MLNS0', 'MLSH0', 'MMAA0', 'MMAG0', 'MMAM0', 'MMAR0', 'MMBS0', 'MMDM0', 'MMDS0', 'MMEB0', 'MMGC0', 'MMGG0', 'MMGK0', 'MMJB1', 'MMRP0', 'MMSM0', 'MMXS0', 'MNET0', 'MPEB0', 'MPGH0', 'MPGR0', 'MPPC0', 'MPRB0', 'MPRD0', 'MPRK0', 'MPRT0', 'MPSW0', 'MRAB0', 'MRAB1', 'MRAI0', 'MRBC0', 'MRCG0', 'MRCW0', 'MRDD0', 'MRDS0', 'MREE0', 'MREH1', 'MRFK0', 'MRFL0', 'MRGM0', 'MRGS0', 'MRHL0', 'MRJB1', 'MRJH0', 'MRJM0', 'MRJM1', 'MRJT0', 'MRLJ0', 'MRLR0', 'MRMS0', 'MRSO0', 'MRSP0', 'MRTC0', 'MRTJ0', 'MRWA0', 'MRWS0', 'MSAT0', 'MSFH0', 'MSFV0', 'MSMC0', 'MSMS0', 'MSRG0', 'MSTF0', 'MTAS0', 'MTAT1', 'MTBC0', 'MTDB0', 'MTJG0', 'MTJM0', 'MTJS0', 'MTKP0', 'MTLB0', 'MTPF0', 'MTPG0', 'MTPP0', 'MTQC0', 'MTRC0', 'MTRR0', 'MTRT0', 'MVJH0', 'MWAD0', 'MWAR0', 'MWDK0', 'MWGR0', 'MWSB0', 'MZMB0']\n",
      "{'MRSP0': 165, 'MRAI0': 143, 'MAEB0': 1, 'MRJB1': 156, 'MTRC0': 190, 'MKDT0': 104, 'MJHI0': 82, 'MCHL0': 18, 'MGAF0': 59, 'MJAC0': 73, 'MRWA0': 168, 'MJMM0': 91, 'MCAL0': 12, 'MJJJ0': 84, 'MHJB0': 68, 'MDPK0': 41, 'MKXL0': 109, 'MDTB0': 46, 'MDJM0': 33, 'MJDC0': 77, 'MJDE0': 78, 'MTBC0': 179, 'MFER0': 55, 'MJDA0': 76, 'MGAG0': 60, 'MWGR0': 197, 'MRSO0': 164, 'MSFH0': 171, 'MCEW0': 17, 'MARW0': 6, 'MHRM0': 71, 'MPRD0': 137, 'MJPM1': 93, 'MDBP0': 26, 'MRDD0': 147, 'MGXP0': 66, 'MSRG0': 175, 'MGRP0': 64, 'MJLS0': 88, 'MBJV0': 9, 'MWSB0': 198, 'MDLH0': 37, 'MCLM0': 19, 'MILB0': 72, 'MLJH0': 113, 'MRGM0': 153, 'MGJC0': 62, 'MSTF0': 176, 'MRHL0': 155, 'MDSS0': 44, 'MRJT0': 160, 'MDBB1': 25, 'MJAE0': 74, 'MRMS0': 163, 'MJXL0': 100, 'MRFL0': 152, 'MRAB0': 141, 'MPRK0': 138, 'MJBG0': 75, 'MPPC0': 135, 'MKJO0': 105, 'MHIT0': 67, 'MVJH0': 193, 'MMXS0': 130, 'MMBS0': 120, 'MMSM0': 129, 'MDSJ0': 43, 'MLNS0': 114, 'MTPG0': 187, 'MCDC0': 13, 'MSAT0': 170, 'MGRL0': 63, 'MARC0': 5, 'MPGH0': 133, 'MDAS0': 24, 'MJEB1': 80, 'MPRB0': 136, 'MMGC0': 124, 'MWAR0': 195, 'MCEF0': 16, 'MJRP0': 96, 'MTJG0': 181, 'MBWP0': 11, 'MTAS0': 177, 'MPEB0': 132, 'MDNS0': 40, 'MMGG0': 125, 'MDMA0': 38, 'MLEL0': 111, 'MAKR0': 3, 'MJRH0': 94, 'MMAG0': 117, 'MMRP0': 128, 'MREH1': 150, 'MKAH0': 101, 'MRJH0': 157, 'MEDR0': 50, 'MADC0': 0, 'MTLB0': 185, 'MTDB0': 180, 'MCPM0': 20, 'MESG0': 53, 'MTAT1': 178, 'MDWH0': 48, 'MDHL0': 31, 'MRLJ0': 161, 'MRBC0': 144, 'MBEF0': 7, 'MTJM0': 182, 'MTPP0': 188, 'MMJB1': 127, 'MLSH0': 115, 'MDMT0': 39, 'MMAM0': 118, 'MPRT0': 139, 'MMEB0': 123, 'MRGS0': 154, 'MKAM0': 103, 'MCTM0': 22, 'MJWS0': 98, 'MPGR0': 134, 'MTRT0': 192, 'MJWT0': 99, 'MWDK0': 196, 'MDAC0': 23, 'MJJB0': 83, 'MRDS0': 148, 'MDPS0': 42, 'MTRR0': 191, 'MDHS0': 32, 'MBGT0': 8, 'MJSR0': 97, 'MTPF0': 186, 'MRCG0': 145, 'MLBC0': 110, 'MCDR0': 15, 'MAKB0': 2, 'MRAB1': 142, 'MNET0': 131, 'MAPV0': 4, 'MJLB0': 86, 'MDDC0': 28, 'MMAR0': 119, 'MCSS0': 21, 'MRCW0': 146, 'MFRM0': 57, 'MTJS0': 183, 'MTKP0': 184, 'MZMB0': 199, 'MEWM0': 54, 'MGES0': 61, 'MDEM0': 30, 'MKLS1': 107, 'MJMD0': 90, 'MCDD0': 14, 'MTQC0': 189, 'MFMC0': 56, 'MDEF0': 29, 'MDLC2': 36, 'MRJM1': 159, 'MMGK0': 126, 'MGSH0': 65, 'MJPM0': 92, 'MREE0': 149, 'MJLG1': 87, 'MKLW0': 108, 'MLJC0': 112, 'MKLS0': 106, 'MRFK0': 151, 'MSMC0': 173, 'MMDM0': 121, 'MRTC0': 166, 'MBMA0': 10, 'MDWM0': 49, 'MEFG0': 51, 'MPSW0': 140, 'MJRH1': 95, 'MRLR0': 162, 'MJEB0': 79, 'MJKR0': 85, 'MDCD0': 27, 'MEGJ0': 52, 'MMAA0': 116, 'MHMR0': 70, 'MMDS0': 122, 'MFWK0': 58, 'MSFV0': 172, 'MDWD0': 47, 'MHMG0': 69, 'MRTJ0': 167, 'MKAJ0': 102, 'MRWS0': 169, 'MSMS0': 174, 'MJEE0': 81, 'MRJM0': 158, 'MWAD0': 194, 'MDLB0': 34, 'MDLC0': 35, 'MDSS1': 45, 'MJMA0': 89}\n"
     ]
    }
   ],
   "source": [
    "ids = list(test.keys())\n",
    "ids.sort()\n",
    "print(ids)\n",
    "\n",
    "idx = {}\n",
    "for i in range(len(ids)):\n",
    "    idx[ids[i]] = i # TODO: for MATLAB set i+1 (i.e 1 to 200)\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat(x, win_size=10, hop_size=3):\n",
    "    r, c = x.shape\n",
    "    y = []\n",
    "    for i in range(0, c, hop_size):\n",
    "        if i + win_size > c:\n",
    "            break\n",
    "        y.append(x[:, i:i + win_size].T.flatten())\n",
    "    return np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(137520, 390) (36091, 390)\n",
      "(137520,) (36091,)\n"
     ]
    }
   ],
   "source": [
    "# gmvn\n",
    "X_train = []\n",
    "Y_train = []\n",
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# test\n",
    "for speaker_id, feature_list in test.items():\n",
    "    speaker_id = idx[speaker_id]\n",
    "    for features in feature_list:\n",
    "        frames = concat(features)\n",
    "        for frame in frames:\n",
    "            X_test.append(frame)\n",
    "            Y_test.append(speaker_id)\n",
    "            \n",
    "X_test = np.array(X_test)\n",
    "Y_test = np.array(Y_test)\n",
    "\n",
    "# train\n",
    "for speaker_id, feature_list in train.items():\n",
    "    speaker_id = idx[speaker_id]    \n",
    "    for features in feature_list:\n",
    "        frames = concat(features)\n",
    "        for frame in frames:\n",
    "            X_train.append(frame)\n",
    "            Y_train.append(speaker_id)\n",
    "            \n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "\n",
    "# mean var normalize\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle training data\n",
    "from sklearn.utils import shuffle\n",
    "X_train, Y_train = shuffle(X_train, Y_train)\n",
    "print('Shuffled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 4.71730816\n",
      "Iteration 2, loss = 3.78623088\n",
      "Iteration 3, loss = 3.38797034\n",
      "Iteration 4, loss = 3.13454551\n",
      "Iteration 5, loss = 2.94932082\n",
      "Iteration 6, loss = 2.80586097\n",
      "Iteration 7, loss = 2.68735592\n",
      "Iteration 8, loss = 2.58932403\n",
      "Iteration 9, loss = 2.50644659\n",
      "Iteration 10, loss = 2.43427894\n",
      "Iteration 11, loss = 2.37067284\n",
      "Iteration 12, loss = 2.31609285\n",
      "Iteration 13, loss = 2.26741936\n",
      "Iteration 14, loss = 2.22292598\n",
      "Iteration 15, loss = 2.18275502\n",
      "Iteration 16, loss = 2.14833112\n",
      "Iteration 17, loss = 2.11331054\n",
      "Iteration 18, loss = 2.08407377\n",
      "Iteration 19, loss = 2.05708875\n",
      "Iteration 20, loss = 2.03027751\n",
      "Iteration 21, loss = 2.00547440\n",
      "Iteration 22, loss = 1.98419588\n",
      "Iteration 23, loss = 1.96284947\n",
      "Iteration 24, loss = 1.94444603\n",
      "Iteration 25, loss = 1.92402935\n",
      "Iteration 26, loss = 1.90717032\n",
      "Iteration 27, loss = 1.89015804\n",
      "Iteration 28, loss = 1.87385501\n",
      "Iteration 29, loss = 1.86028455\n",
      "Iteration 30, loss = 1.84497108\n",
      "Iteration 31, loss = 1.83076248\n",
      "Iteration 32, loss = 1.81789787\n",
      "Iteration 33, loss = 1.80560734\n",
      "Iteration 34, loss = 1.79426701\n",
      "Iteration 35, loss = 1.78307183\n",
      "Iteration 36, loss = 1.77208403\n",
      "Iteration 37, loss = 1.76174897\n",
      "Iteration 38, loss = 1.75090641\n",
      "Iteration 39, loss = 1.74287921\n",
      "Iteration 40, loss = 1.73210545\n",
      "Iteration 41, loss = 1.72393251\n",
      "Iteration 42, loss = 1.71392593\n",
      "Iteration 43, loss = 1.70629926\n",
      "Iteration 44, loss = 1.69959348\n",
      "Iteration 45, loss = 1.69047663\n",
      "Iteration 46, loss = 1.68313203\n",
      "Iteration 47, loss = 1.67466844\n",
      "Iteration 48, loss = 1.66903207\n",
      "Iteration 49, loss = 1.66254262\n",
      "Iteration 50, loss = 1.65478785\n",
      "Iteration 51, loss = 1.64775569\n",
      "Iteration 52, loss = 1.64137669\n",
      "Iteration 53, loss = 1.63490863\n",
      "Iteration 54, loss = 1.62826288\n",
      "Iteration 55, loss = 1.62142340\n",
      "Iteration 56, loss = 1.61673132\n",
      "Iteration 57, loss = 1.61070500\n",
      "Iteration 58, loss = 1.60633623\n",
      "Iteration 59, loss = 1.60238314\n",
      "Iteration 60, loss = 1.59494975\n",
      "Iteration 61, loss = 1.59160955\n",
      "Iteration 62, loss = 1.58586192\n",
      "Iteration 63, loss = 1.57984142\n",
      "Iteration 64, loss = 1.57467825\n",
      "Iteration 65, loss = 1.57081272\n",
      "Iteration 66, loss = 1.56598390\n",
      "Iteration 67, loss = 1.56224228\n",
      "Iteration 68, loss = 1.55619818\n",
      "Iteration 69, loss = 1.55201393\n",
      "Iteration 70, loss = 1.54773363\n",
      "Iteration 71, loss = 1.54338948\n",
      "Iteration 72, loss = 1.54161134\n",
      "Iteration 73, loss = 1.53666112\n",
      "Iteration 74, loss = 1.53378797\n",
      "Iteration 75, loss = 1.52822243\n",
      "Iteration 76, loss = 1.52536658\n",
      "Iteration 77, loss = 1.52227666\n",
      "Iteration 78, loss = 1.51844990\n",
      "Iteration 79, loss = 1.51305174\n",
      "Iteration 80, loss = 1.51244072\n",
      "Iteration 81, loss = 1.50963493\n",
      "Iteration 82, loss = 1.50565722\n",
      "Iteration 83, loss = 1.50010867\n",
      "Iteration 84, loss = 1.49812244\n",
      "Iteration 85, loss = 1.49478092\n",
      "Iteration 86, loss = 1.49066881\n",
      "Iteration 87, loss = 1.48998047\n",
      "Iteration 88, loss = 1.48580189\n",
      "Iteration 89, loss = 1.48430202\n",
      "Iteration 90, loss = 1.48067573\n",
      "Iteration 91, loss = 1.47832673\n",
      "Iteration 92, loss = 1.47458267\n",
      "Iteration 93, loss = 1.47192941\n",
      "Iteration 94, loss = 1.46895614\n",
      "Iteration 95, loss = 1.46670450\n",
      "Iteration 96, loss = 1.46423909\n",
      "Iteration 97, loss = 1.46159883\n",
      "Iteration 98, loss = 1.45774225\n",
      "Iteration 99, loss = 1.45606107\n",
      "Iteration 100, loss = 1.45125263\n",
      "Iteration 101, loss = 1.45141550\n",
      "Iteration 102, loss = 1.44936796\n",
      "Iteration 103, loss = 1.44643109\n",
      "Iteration 104, loss = 1.44465470\n",
      "Iteration 105, loss = 1.44249103\n",
      "Iteration 106, loss = 1.43976483\n",
      "Iteration 107, loss = 1.43714743\n",
      "Iteration 108, loss = 1.43518128\n",
      "Iteration 109, loss = 1.43271059\n",
      "Iteration 110, loss = 1.43073518\n",
      "Iteration 111, loss = 1.42862585\n",
      "Iteration 112, loss = 1.42703823\n",
      "Iteration 113, loss = 1.42481286\n",
      "Iteration 114, loss = 1.42316486\n",
      "Iteration 115, loss = 1.42004277\n",
      "Iteration 116, loss = 1.42061456\n",
      "Iteration 117, loss = 1.41658689\n",
      "Iteration 118, loss = 1.41493836\n",
      "Iteration 119, loss = 1.41374044\n",
      "Iteration 120, loss = 1.41212207\n",
      "Iteration 121, loss = 1.40769816\n",
      "Iteration 122, loss = 1.40683981\n",
      "Iteration 123, loss = 1.40329521\n",
      "Iteration 124, loss = 1.40505062\n",
      "Iteration 125, loss = 1.40164104\n",
      "Iteration 126, loss = 1.39996908\n",
      "Iteration 127, loss = 1.39989276\n",
      "Iteration 128, loss = 1.39740207\n",
      "Iteration 129, loss = 1.39425260\n",
      "Iteration 130, loss = 1.39234633\n",
      "Iteration 131, loss = 1.39063097\n",
      "Iteration 132, loss = 1.38875847\n",
      "Iteration 133, loss = 1.38902597\n",
      "Iteration 134, loss = 1.38686156\n",
      "Iteration 135, loss = 1.38533125\n",
      "Iteration 136, loss = 1.38543565\n",
      "Iteration 137, loss = 1.38254769\n",
      "Iteration 138, loss = 1.38225640\n",
      "Iteration 139, loss = 1.37902363\n",
      "Iteration 140, loss = 1.37805558\n",
      "Iteration 141, loss = 1.37558975\n",
      "Iteration 142, loss = 1.37528948\n",
      "Iteration 143, loss = 1.37192286\n",
      "Iteration 144, loss = 1.37174483\n",
      "Iteration 145, loss = 1.37137952\n",
      "Iteration 146, loss = 1.36969864\n",
      "Iteration 147, loss = 1.36904410\n",
      "Iteration 148, loss = 1.36616661\n",
      "Iteration 149, loss = 1.36425617\n",
      "Iteration 150, loss = 1.36415725\n",
      "Iteration 151, loss = 1.36307961\n",
      "Iteration 152, loss = 1.36094380\n",
      "Iteration 153, loss = 1.35789326\n",
      "Iteration 154, loss = 1.35870141\n",
      "Iteration 155, loss = 1.35682083\n",
      "Iteration 156, loss = 1.35644306\n",
      "Iteration 157, loss = 1.35339631\n",
      "Iteration 158, loss = 1.35301161\n",
      "Iteration 159, loss = 1.35230345\n",
      "Iteration 160, loss = 1.35146865\n",
      "Iteration 161, loss = 1.34925045\n",
      "Iteration 162, loss = 1.35012288\n",
      "Iteration 163, loss = 1.34534029\n",
      "Iteration 164, loss = 1.34687624\n",
      "Iteration 165, loss = 1.34494475\n",
      "Iteration 166, loss = 1.34291086\n",
      "Iteration 167, loss = 1.34254389\n",
      "Iteration 168, loss = 1.34211190\n",
      "Iteration 169, loss = 1.34060864\n",
      "Iteration 170, loss = 1.33717546\n",
      "Iteration 171, loss = 1.33801228\n",
      "Iteration 172, loss = 1.33711640\n",
      "Iteration 173, loss = 1.33543866\n",
      "Iteration 174, loss = 1.33502917\n",
      "Iteration 175, loss = 1.33512615\n",
      "Iteration 176, loss = 1.33073537\n",
      "Iteration 177, loss = 1.33145204\n",
      "Iteration 178, loss = 1.32955651\n",
      "Iteration 179, loss = 1.32866600\n",
      "Iteration 180, loss = 1.32820099\n",
      "Iteration 181, loss = 1.32650860\n",
      "Iteration 182, loss = 1.32648098\n",
      "Iteration 183, loss = 1.32618313\n",
      "Iteration 184, loss = 1.32254141\n",
      "Iteration 185, loss = 1.32474358\n",
      "Iteration 186, loss = 1.32339527\n",
      "Iteration 187, loss = 1.32046660\n",
      "Iteration 188, loss = 1.31977739\n",
      "Iteration 189, loss = 1.31986011\n",
      "Iteration 190, loss = 1.31760111\n",
      "Iteration 191, loss = 1.31871698\n",
      "Iteration 192, loss = 1.31681451\n",
      "Iteration 193, loss = 1.31586275\n",
      "Iteration 194, loss = 1.31412084\n",
      "Iteration 195, loss = 1.31294653\n",
      "Iteration 196, loss = 1.31176461\n",
      "Iteration 197, loss = 1.31099116\n",
      "Iteration 198, loss = 1.31130557\n",
      "Iteration 199, loss = 1.30952096\n",
      "Iteration 200, loss = 1.30970751\n",
      "Iteration 201, loss = 1.30725858\n",
      "Iteration 202, loss = 1.30675823\n",
      "Iteration 203, loss = 1.30755195\n",
      "Iteration 204, loss = 1.30586871\n",
      "Iteration 205, loss = 1.30565931\n",
      "Iteration 206, loss = 1.30386672\n",
      "Iteration 207, loss = 1.30188878\n",
      "Iteration 208, loss = 1.30216942\n",
      "Iteration 209, loss = 1.30174084\n",
      "Iteration 210, loss = 1.30215953\n",
      "Iteration 211, loss = 1.29919042\n",
      "Iteration 212, loss = 1.29808804\n",
      "Iteration 213, loss = 1.29783015\n",
      "Iteration 214, loss = 1.29850399\n",
      "Iteration 215, loss = 1.29730859\n",
      "Iteration 216, loss = 1.29522292\n",
      "Iteration 217, loss = 1.29399356\n",
      "Iteration 218, loss = 1.29390546\n",
      "Iteration 219, loss = 1.29392299\n",
      "Iteration 220, loss = 1.29264405\n",
      "Iteration 221, loss = 1.29211113\n",
      "Iteration 222, loss = 1.29206961\n",
      "Iteration 223, loss = 1.28837531\n",
      "Iteration 224, loss = 1.28868398\n",
      "Iteration 225, loss = 1.28769725\n",
      "Iteration 226, loss = 1.28927545\n",
      "Iteration 227, loss = 1.28762936\n",
      "Iteration 228, loss = 1.28435031\n",
      "Iteration 229, loss = 1.28693512\n",
      "Iteration 230, loss = 1.28523303\n",
      "Iteration 231, loss = 1.28392085\n",
      "Iteration 232, loss = 1.28270522\n",
      "Iteration 233, loss = 1.28263197\n",
      "Iteration 234, loss = 1.28147179\n",
      "Iteration 235, loss = 1.28171076\n",
      "Iteration 236, loss = 1.28035843\n",
      "Iteration 237, loss = 1.28012375\n",
      "Iteration 238, loss = 1.27869360\n",
      "Iteration 239, loss = 1.27760310\n",
      "Iteration 240, loss = 1.27903681\n",
      "Iteration 241, loss = 1.27730989\n",
      "Iteration 242, loss = 1.27645817\n",
      "Iteration 243, loss = 1.27536151\n",
      "Iteration 244, loss = 1.27376360\n",
      "Iteration 245, loss = 1.27247226\n",
      "Iteration 246, loss = 1.27226660\n",
      "Iteration 247, loss = 1.27282272\n",
      "Iteration 248, loss = 1.27152846\n",
      "Iteration 249, loss = 1.26999150\n",
      "Iteration 250, loss = 1.27109655\n",
      "Iteration 251, loss = 1.26977742\n",
      "Iteration 252, loss = 1.27054729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 253, loss = 1.27171232\n",
      "Iteration 254, loss = 1.26853829\n",
      "Iteration 255, loss = 1.26719553\n",
      "Iteration 256, loss = 1.26513318\n",
      "Iteration 257, loss = 1.26621020\n",
      "Iteration 258, loss = 1.26462495\n",
      "Iteration 259, loss = 1.26509413\n",
      "Iteration 260, loss = 1.26449429\n",
      "Iteration 261, loss = 1.26297612\n",
      "Iteration 262, loss = 1.26258637\n",
      "Iteration 263, loss = 1.26263540\n",
      "Iteration 264, loss = 1.26212084\n",
      "Iteration 265, loss = 1.26001725\n",
      "Iteration 266, loss = 1.25960532\n",
      "Iteration 267, loss = 1.26037240\n",
      "Iteration 268, loss = 1.25784532\n",
      "Iteration 269, loss = 1.25812519\n",
      "Iteration 270, loss = 1.25899076\n",
      "Iteration 271, loss = 1.25627569\n",
      "Iteration 272, loss = 1.25749370\n",
      "Iteration 273, loss = 1.25563467\n",
      "Iteration 274, loss = 1.25372125\n",
      "Iteration 275, loss = 1.25483417\n",
      "Iteration 276, loss = 1.25295418\n",
      "Iteration 277, loss = 1.25397911\n",
      "Iteration 278, loss = 1.25545449\n",
      "Iteration 279, loss = 1.25414359\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.002000\n",
      "Iteration 280, loss = 1.11131852\n",
      "Iteration 281, loss = 1.08164425\n",
      "Iteration 282, loss = 1.07749885\n",
      "Iteration 283, loss = 1.07608273\n",
      "Iteration 284, loss = 1.07477557\n",
      "Iteration 285, loss = 1.07427716\n",
      "Iteration 286, loss = 1.07419842\n",
      "Iteration 287, loss = 1.07273919\n",
      "Iteration 288, loss = 1.07252274\n",
      "Iteration 289, loss = 1.07256446\n",
      "Iteration 290, loss = 1.07164982\n",
      "Iteration 291, loss = 1.07132076\n",
      "Iteration 292, loss = 1.07114401\n",
      "Iteration 293, loss = 1.07092816\n",
      "Iteration 294, loss = 1.07010753\n",
      "Iteration 295, loss = 1.07002149\n",
      "Iteration 296, loss = 1.06960523\n",
      "Iteration 297, loss = 1.06942021\n",
      "Iteration 298, loss = 1.06890102\n",
      "Iteration 299, loss = 1.06857298\n",
      "Iteration 300, loss = 1.06821352\n",
      "Iteration 301, loss = 1.06836768\n",
      "Iteration 302, loss = 1.06836425\n",
      "Iteration 303, loss = 1.06731103\n",
      "Iteration 304, loss = 1.06767385\n",
      "Iteration 305, loss = 1.06706941\n",
      "Iteration 306, loss = 1.06707193\n",
      "Iteration 307, loss = 1.06661930\n",
      "Iteration 308, loss = 1.06617994\n",
      "Iteration 309, loss = 1.06635242\n",
      "Iteration 310, loss = 1.06571914\n",
      "Iteration 311, loss = 1.06554127\n",
      "Iteration 312, loss = 1.06558683\n",
      "Iteration 313, loss = 1.06485503\n",
      "Iteration 314, loss = 1.06523688\n",
      "Iteration 315, loss = 1.06489668\n",
      "Iteration 316, loss = 1.06495288\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000400\n",
      "Iteration 317, loss = 1.03306616\n",
      "Iteration 318, loss = 1.02925604\n",
      "Iteration 319, loss = 1.02852669\n",
      "Iteration 320, loss = 1.02825465\n",
      "Iteration 321, loss = 1.02800878\n",
      "Iteration 322, loss = 1.02788816\n",
      "Iteration 323, loss = 1.02775119\n",
      "Iteration 324, loss = 1.02763972\n",
      "Iteration 325, loss = 1.02762221\n",
      "Iteration 326, loss = 1.02753167\n",
      "Iteration 327, loss = 1.02748464\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000080\n",
      "Iteration 328, loss = 1.01976025\n",
      "Iteration 329, loss = 1.01935230\n",
      "Iteration 330, loss = 1.01924927\n",
      "Iteration 331, loss = 1.01918998\n",
      "Iteration 332, loss = 1.01916247\n",
      "Iteration 333, loss = 1.01912528\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000016\n",
      "Iteration 334, loss = 1.01733764\n",
      "Iteration 335, loss = 1.01732855\n",
      "Iteration 336, loss = 1.01731892\n",
      "Iteration 337, loss = 1.01731145\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000003\n",
      "Iteration 338, loss = 1.01693554\n",
      "Iteration 339, loss = 1.01693403\n",
      "Iteration 340, loss = 1.01693317\n",
      "Iteration 341, loss = 1.01693250\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000001\n",
      "Iteration 342, loss = 1.01685654\n",
      "Iteration 343, loss = 1.01685634\n",
      "Iteration 344, loss = 1.01685610\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Learning rate too small. Stopping.\n",
      "Training set score: 0.723204\n",
      "Test set score: 0.324291\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "# mlp = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=400, alpha=1e-4,\n",
    "#                     solver='sgd', verbose=10, tol=1e-4, random_state=1)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(200,), max_iter=1000, alpha=1e-4,\n",
    "                    solver='sgd', verbose=10, tol=1e-4, random_state=1,\n",
    "                    learning_rate_init=.01, learning_rate='adaptive',\n",
    "                    warm_start=True)\n",
    "\n",
    "mlp.fit(X_train, Y_train)\n",
    "print(\"Training set score: %f\" % mlp.score(X_train, Y_train))\n",
    "print(\"Test set score: %f\" % mlp.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.873536299766\n",
      "maxlen 496\n"
     ]
    }
   ],
   "source": [
    "# segment acc\n",
    "from scipy import stats\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "# test\n",
    "maxlen = 0\n",
    "for speaker_id, feature_list in test.items():\n",
    "    speaker_id = idx[speaker_id]\n",
    "    for features in feature_list:\n",
    "        maxlen = max(maxlen, features.shape[1])\n",
    "        x = []\n",
    "        # y = []\n",
    "        frames = concat(features)\n",
    "        for frame in frames:\n",
    "            x.append(frame)\n",
    "            # y.append(speaker_id)\n",
    "        x = scaler.transform(x)\n",
    "        pred = stats.mode(mlp.predict(x)).mode[0]\n",
    "        y_true.append(speaker_id)\n",
    "        y_pred.append(pred)\n",
    "print(sum(np.array(y_true) == np.array(y_pred))/len(y_true))\n",
    "print('maxlen', maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('coefs_gmvn', mlp.coefs_)\n",
    "np.save('intercepts_gmvn', mlp.intercepts_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.985\n",
      "maxlen 496\n"
     ]
    }
   ],
   "source": [
    "# all segment acc ~ file\n",
    "from scipy import stats\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "# test\n",
    "maxlen = 0\n",
    "for speaker_id, feature_list in test.items():\n",
    "    speaker_id = idx[speaker_id]\n",
    "    x = []\n",
    "    for features in feature_list:\n",
    "        maxlen = max(maxlen, features.shape[1])\n",
    "        # y = []\n",
    "        frames = concat(features)\n",
    "        for frame in frames:\n",
    "            x.append(frame)\n",
    "            # y.append(speaker_id)\n",
    "    x = scaler.transform(x)\n",
    "    pred = stats.mode(mlp.predict(x)).mode[0]\n",
    "    y_true.append(speaker_id)\n",
    "    y_pred.append(pred)\n",
    "print(sum(np.array(y_true) == np.array(y_pred))/len(y_true))\n",
    "print('maxlen', maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 4.71842705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pratik varshney\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.130185\n",
      "Test set score: 0.109362\n",
      "\n",
      "Iteration 2, loss = 3.78699473\n",
      "Training set score: 0.205519\n",
      "Test set score: 0.168823\n",
      "\n",
      "Iteration 3, loss = 3.39188390\n",
      "Training set score: 0.253207\n",
      "Test set score: 0.202904\n",
      "\n",
      "Iteration 4, loss = 3.14046168\n",
      "Training set score: 0.290954\n",
      "Test set score: 0.225763\n",
      "\n",
      "Iteration 5, loss = 2.95567318\n",
      "Training set score: 0.321139\n",
      "Test set score: 0.242554\n",
      "\n",
      "Iteration 6, loss = 2.81184253\n",
      "Training set score: 0.346371\n",
      "Test set score: 0.255438\n",
      "\n",
      "Iteration 7, loss = 2.69486814\n",
      "Training set score: 0.367816\n",
      "Test set score: 0.266354\n",
      "\n",
      "Iteration 8, loss = 2.59725279\n",
      "Training set score: 0.386198\n",
      "Test set score: 0.274528\n",
      "\n",
      "Iteration 9, loss = 2.51442501\n",
      "Training set score: 0.402363\n",
      "Test set score: 0.279516\n",
      "\n",
      "Iteration 10, loss = 2.44342985\n",
      "Training set score: 0.415525\n",
      "Test set score: 0.283561\n",
      "\n",
      "Iteration 11, loss = 2.38169425\n",
      "Training set score: 0.427225\n",
      "Test set score: 0.286055\n",
      "\n",
      "Iteration 12, loss = 2.32729595\n",
      "Training set score: 0.438562\n",
      "Test set score: 0.289297\n",
      "\n",
      "Iteration 13, loss = 2.27903001\n",
      "Training set score: 0.447709\n",
      "Test set score: 0.293203\n",
      "\n",
      "Iteration 14, loss = 2.23578377\n",
      "Training set score: 0.456079\n",
      "Test set score: 0.295752\n",
      "\n",
      "Iteration 15, loss = 2.19698700\n",
      "Training set score: 0.464172\n",
      "Test set score: 0.297997\n",
      "\n",
      "Iteration 16, loss = 2.16175785\n",
      "Training set score: 0.471640\n",
      "Test set score: 0.300629\n",
      "\n",
      "Iteration 17, loss = 2.12976434\n",
      "Training set score: 0.478956\n",
      "Test set score: 0.302984\n",
      "\n",
      "Iteration 18, loss = 2.10032392\n",
      "Training set score: 0.484620\n",
      "Test set score: 0.304286\n",
      "\n",
      "Iteration 19, loss = 2.07320065\n",
      "Training set score: 0.490271\n",
      "Test set score: 0.305589\n",
      "\n",
      "Iteration 20, loss = 2.04797359\n",
      "Training set score: 0.495790\n",
      "Test set score: 0.306087\n",
      "\n",
      "Iteration 21, loss = 2.02430038\n",
      "Training set score: 0.500720\n",
      "Test set score: 0.307362\n",
      "\n",
      "Iteration 22, loss = 2.00218109\n",
      "Training set score: 0.505054\n",
      "Test set score: 0.307500\n",
      "\n",
      "Iteration 23, loss = 1.98159160\n",
      "Training set score: 0.509562\n",
      "Test set score: 0.308830\n",
      "\n",
      "Iteration 24, loss = 1.96232556\n",
      "Training set score: 0.514114\n",
      "Test set score: 0.309773\n",
      "\n",
      "Iteration 25, loss = 1.94413130\n",
      "Training set score: 0.518070\n",
      "Test set score: 0.310687\n",
      "\n",
      "Iteration 26, loss = 1.92696614\n",
      "Training set score: 0.521728\n",
      "Test set score: 0.311158\n",
      "\n",
      "Iteration 27, loss = 1.91075854\n",
      "Training set score: 0.525218\n",
      "Test set score: 0.310936\n",
      "\n",
      "Iteration 28, loss = 1.89516948\n",
      "Training set score: 0.528345\n",
      "Test set score: 0.310798\n",
      "\n",
      "Iteration 29, loss = 1.88051351\n",
      "Training set score: 0.531465\n",
      "Test set score: 0.311684\n",
      "\n",
      "Iteration 30, loss = 1.86659133\n",
      "Training set score: 0.534388\n",
      "Test set score: 0.311989\n",
      "\n",
      "Iteration 31, loss = 1.85324393\n",
      "Training set score: 0.536540\n",
      "Test set score: 0.313097\n",
      "\n",
      "Iteration 32, loss = 1.84075060\n",
      "Training set score: 0.538860\n",
      "Test set score: 0.312848\n",
      "\n",
      "Iteration 33, loss = 1.82881079\n",
      "Training set score: 0.541536\n",
      "Test set score: 0.313458\n",
      "\n",
      "Iteration 34, loss = 1.81731130\n",
      "Training set score: 0.543455\n",
      "Test set score: 0.313568\n",
      "\n",
      "Iteration 35, loss = 1.80619779\n",
      "Training set score: 0.545179\n",
      "Test set score: 0.313873\n",
      "\n",
      "Iteration 36, loss = 1.79557575\n",
      "Training set score: 0.547360\n",
      "Test set score: 0.314095\n",
      "\n",
      "Iteration 37, loss = 1.78525032\n",
      "Training set score: 0.549724\n",
      "Test set score: 0.314400\n",
      "\n",
      "Iteration 38, loss = 1.77569401\n",
      "Training set score: 0.551236\n",
      "Test set score: 0.315480\n",
      "\n",
      "Iteration 39, loss = 1.76654090\n",
      "Training set score: 0.553207\n",
      "Test set score: 0.315065\n",
      "\n",
      "Iteration 40, loss = 1.75761892\n",
      "Training set score: 0.555257\n",
      "Test set score: 0.315397\n",
      "\n",
      "Iteration 41, loss = 1.74889786\n",
      "Training set score: 0.557163\n",
      "Test set score: 0.315647\n",
      "\n",
      "Iteration 42, loss = 1.74046870\n",
      "Training set score: 0.558711\n",
      "Test set score: 0.316339\n",
      "\n",
      "Iteration 43, loss = 1.73230958\n",
      "Training set score: 0.560718\n",
      "Test set score: 0.316090\n",
      "\n",
      "Iteration 44, loss = 1.72449753\n",
      "Training set score: 0.561758\n",
      "Test set score: 0.315841\n",
      "\n",
      "Iteration 45, loss = 1.71703761\n",
      "Training set score: 0.563307\n",
      "Test set score: 0.315813\n",
      "\n",
      "Iteration 46, loss = 1.70966358\n",
      "Training set score: 0.564689\n",
      "Test set score: 0.316589\n",
      "\n",
      "Iteration 47, loss = 1.70262650\n",
      "Training set score: 0.566194\n",
      "Test set score: 0.315951\n",
      "\n",
      "Iteration 48, loss = 1.69592718\n",
      "Training set score: 0.567510\n",
      "Test set score: 0.316090\n",
      "\n",
      "Iteration 49, loss = 1.68927883\n",
      "Training set score: 0.568972\n",
      "Test set score: 0.316118\n",
      "\n",
      "Iteration 50, loss = 1.68279846\n",
      "Training set score: 0.569888\n",
      "Test set score: 0.316395\n",
      "\n",
      "Iteration 51, loss = 1.67657601\n",
      "Training set score: 0.571415\n",
      "Test set score: 0.316921\n",
      "\n",
      "Iteration 52, loss = 1.67054819\n",
      "Training set score: 0.572317\n",
      "Test set score: 0.317475\n",
      "\n",
      "Iteration 53, loss = 1.66460261\n",
      "Training set score: 0.573713\n",
      "Test set score: 0.317946\n",
      "\n",
      "Iteration 54, loss = 1.65892363\n",
      "Training set score: 0.574491\n",
      "Test set score: 0.317503\n",
      "\n",
      "Iteration 55, loss = 1.65315661\n",
      "Training set score: 0.575444\n",
      "Test set score: 0.317835\n",
      "\n",
      "Iteration 56, loss = 1.64780506\n",
      "Training set score: 0.576433\n",
      "Test set score: 0.317946\n",
      "\n",
      "Iteration 57, loss = 1.64245337\n",
      "Training set score: 0.577654\n",
      "Test set score: 0.317835\n",
      "\n",
      "Iteration 58, loss = 1.63737384\n",
      "Training set score: 0.578818\n",
      "Test set score: 0.317919\n",
      "\n",
      "Iteration 59, loss = 1.63220224\n",
      "Training set score: 0.580039\n",
      "Test set score: 0.317891\n",
      "\n",
      "Iteration 60, loss = 1.62716535\n",
      "Training set score: 0.581145\n",
      "Test set score: 0.318584\n",
      "\n",
      "Iteration 61, loss = 1.62239597\n",
      "Training set score: 0.582308\n",
      "Test set score: 0.317808\n",
      "\n",
      "Iteration 62, loss = 1.61777839\n",
      "Training set score: 0.583610\n",
      "Test set score: 0.317669\n",
      "\n",
      "Iteration 63, loss = 1.61304221\n",
      "Training set score: 0.584213\n",
      "Test set score: 0.318057\n",
      "\n",
      "Iteration 64, loss = 1.60855393\n",
      "Training set score: 0.584417\n",
      "Test set score: 0.318279\n",
      "\n",
      "Iteration 65, loss = 1.60410795\n",
      "Training set score: 0.585173\n",
      "Test set score: 0.318417\n",
      "\n",
      "Iteration 66, loss = 1.59977179\n",
      "Training set score: 0.586344\n",
      "Test set score: 0.318833\n",
      "\n",
      "Iteration 67, loss = 1.59557663\n",
      "Training set score: 0.587144\n",
      "Test set score: 0.318196\n",
      "\n",
      "Iteration 68, loss = 1.59144287\n",
      "Training set score: 0.588300\n",
      "Test set score: 0.318445\n",
      "\n",
      "Iteration 69, loss = 1.58729373\n",
      "Training set score: 0.589471\n",
      "Test set score: 0.318861\n",
      "\n",
      "Iteration 70, loss = 1.58325276\n",
      "Training set score: 0.589951\n",
      "Test set score: 0.319470\n",
      "\n",
      "Iteration 71, loss = 1.57938017\n",
      "Training set score: 0.590721\n",
      "Test set score: 0.319221\n",
      "\n",
      "Iteration 72, loss = 1.57561702\n",
      "Training set score: 0.591332\n",
      "Test set score: 0.319387\n",
      "\n",
      "Iteration 73, loss = 1.57187669\n",
      "Training set score: 0.592372\n",
      "Test set score: 0.318556\n",
      "\n",
      "Iteration 74, loss = 1.56831096\n",
      "Training set score: 0.593332\n",
      "Test set score: 0.318861\n",
      "\n",
      "Iteration 75, loss = 1.56470211\n",
      "Training set score: 0.593957\n",
      "Test set score: 0.318805\n",
      "\n",
      "Iteration 76, loss = 1.56114260\n",
      "Training set score: 0.595193\n",
      "Test set score: 0.318584\n",
      "\n",
      "Iteration 77, loss = 1.55769070\n",
      "Training set score: 0.595404\n",
      "Test set score: 0.318611\n",
      "\n",
      "Iteration 78, loss = 1.55433698\n",
      "Training set score: 0.596044\n",
      "Test set score: 0.318362\n",
      "\n",
      "Iteration 79, loss = 1.55105125\n",
      "Training set score: 0.596757\n",
      "Test set score: 0.319055\n",
      "\n",
      "Iteration 80, loss = 1.54788658\n",
      "Training set score: 0.597389\n",
      "Test set score: 0.318528\n",
      "\n",
      "Iteration 81, loss = 1.54451726\n",
      "Training set score: 0.598408\n",
      "Test set score: 0.318029\n",
      "\n",
      "Iteration 82, loss = 1.54134138\n",
      "Training set score: 0.598786\n",
      "Test set score: 0.318029\n",
      "\n",
      "Iteration 83, loss = 1.53828154\n",
      "Training set score: 0.598989\n",
      "Test set score: 0.318362\n",
      "\n",
      "Iteration 84, loss = 1.53535485\n",
      "Training set score: 0.599840\n",
      "Test set score: 0.318279\n",
      "\n",
      "Iteration 85, loss = 1.53233716\n",
      "Training set score: 0.600567\n",
      "Test set score: 0.318362\n",
      "\n",
      "Iteration 86, loss = 1.52942723\n",
      "Training set score: 0.600778\n",
      "Test set score: 0.318500\n",
      "\n",
      "Iteration 87, loss = 1.52660722\n",
      "Training set score: 0.601542\n",
      "Test set score: 0.318417\n",
      "\n",
      "Iteration 88, loss = 1.52375861\n",
      "Training set score: 0.602203\n",
      "Test set score: 0.318805\n",
      "\n",
      "Iteration 89, loss = 1.52111488\n",
      "Training set score: 0.602894\n",
      "Test set score: 0.318999\n",
      "\n",
      "Iteration 90, loss = 1.51832158\n",
      "Training set score: 0.603592\n",
      "Test set score: 0.319304\n",
      "\n",
      "Iteration 91, loss = 1.51561762\n",
      "Training set score: 0.604479\n",
      "Test set score: 0.319193\n",
      "\n",
      "Iteration 92, loss = 1.51308618\n",
      "Training set score: 0.604450\n",
      "Test set score: 0.318888\n",
      "\n",
      "Iteration 93, loss = 1.51062989\n",
      "Training set score: 0.605287\n",
      "Test set score: 0.318085\n",
      "\n",
      "Iteration 94, loss = 1.50786584\n",
      "Training set score: 0.605599\n",
      "Test set score: 0.318362\n",
      "\n",
      "Iteration 95, loss = 1.50538798\n",
      "Training set score: 0.606479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.317919\n",
      "\n",
      "Iteration 96, loss = 1.50294932\n",
      "Training set score: 0.607003\n",
      "Test set score: 0.318307\n",
      "\n",
      "Iteration 97, loss = 1.50046350\n",
      "Training set score: 0.607475\n",
      "Test set score: 0.317752\n",
      "\n",
      "Iteration 98, loss = 1.49813745\n",
      "Training set score: 0.607933\n",
      "Test set score: 0.317946\n",
      "\n",
      "Iteration 99, loss = 1.49580275\n",
      "Training set score: 0.608573\n",
      "Test set score: 0.317752\n",
      "\n",
      "Iteration 100, loss = 1.49360012\n",
      "Training set score: 0.608944\n",
      "Test set score: 0.317309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "# mlp = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=400, alpha=1e-4,\n",
    "#                     solver='sgd', verbose=10, tol=1e-4, random_state=1)\n",
    "mlp2 = MLPClassifier(hidden_layer_sizes=(200,), max_iter=1, alpha=1e-3,\n",
    "                    solver='sgd', verbose=10, tol=1e-3, random_state=1,\n",
    "                    learning_rate_init=.01, learning_rate='adaptive',\n",
    "                    warm_start=True)\n",
    "\n",
    "max_iter = 100\n",
    "for i in range(max_iter):\n",
    "    mlp2.fit(X_train, Y_train)\n",
    "    print(\"Training set score: %f\" % mlp2.score(X_train, Y_train))\n",
    "    print(\"Test set score: %f\" % mlp2.score(X_test, Y_test))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.861826697892\n",
      "maxlen 496\n"
     ]
    }
   ],
   "source": [
    "# segment acc\n",
    "from scipy import stats\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "# test\n",
    "maxlen = 0\n",
    "for speaker_id, feature_list in test.items():\n",
    "    speaker_id = idx[speaker_id]\n",
    "    for features in feature_list:\n",
    "        maxlen = max(maxlen, features.shape[1])\n",
    "        x = []\n",
    "        # y = []\n",
    "        frames = concat(features)\n",
    "        for frame in frames:\n",
    "            x.append(frame)\n",
    "            # y.append(speaker_id)\n",
    "        x = scaler.transform(x)\n",
    "        pred = stats.mode(mlp2.predict(x)).mode[0]\n",
    "        y_true.append(speaker_id)\n",
    "        y_pred.append(pred)\n",
    "print(sum(np.array(y_true) == np.array(y_pred))/len(y_true))\n",
    "print('maxlen', maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.955\n",
      "maxlen 496\n"
     ]
    }
   ],
   "source": [
    "# all segment acc ~ file\n",
    "from scipy import stats\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "# test\n",
    "maxlen = 0\n",
    "for speaker_id, feature_list in test.items():\n",
    "    speaker_id = idx[speaker_id]\n",
    "    x = []\n",
    "    for features in feature_list:\n",
    "        maxlen = max(maxlen, features.shape[1])\n",
    "        # y = []\n",
    "        frames = concat(features)\n",
    "        for frame in frames:\n",
    "            x.append(frame)\n",
    "            # y.append(speaker_id)\n",
    "    x = scaler.transform(x)\n",
    "    pred = stats.mode(mlp2.predict(x)).mode[0]\n",
    "    y_true.append(speaker_id)\n",
    "    y_pred.append(pred)\n",
    "print(sum(np.array(y_true) == np.array(y_pred))/len(y_true))\n",
    "print('maxlen', maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 101, loss = 1.49129646\n",
      "Training set score: 0.609446\n",
      "Test set score: 0.316672\n",
      "\n",
      "Iteration 102, loss = 1.48910984\n",
      "Training set score: 0.609562\n",
      "Test set score: 0.317170\n",
      "\n",
      "Iteration 103, loss = 1.48686376\n",
      "Training set score: 0.610042\n",
      "Test set score: 0.317420\n",
      "\n",
      "Iteration 104, loss = 1.48475710\n",
      "Training set score: 0.610878\n",
      "Test set score: 0.317281\n",
      "\n",
      "Iteration 105, loss = 1.48252212\n",
      "Training set score: 0.611075\n",
      "Test set score: 0.316977\n",
      "\n",
      "Iteration 106, loss = 1.48048121\n",
      "Training set score: 0.611511\n",
      "Test set score: 0.316395\n",
      "\n",
      "Iteration 107, loss = 1.47840514\n",
      "Training set score: 0.612347\n",
      "Test set score: 0.316478\n",
      "\n",
      "Iteration 108, loss = 1.47642136\n",
      "Training set score: 0.612769\n",
      "Test set score: 0.316395\n",
      "\n",
      "Iteration 109, loss = 1.47455120\n",
      "Training set score: 0.613045\n",
      "Test set score: 0.316450\n",
      "\n",
      "Iteration 110, loss = 1.47253606\n",
      "Training set score: 0.613823\n",
      "Test set score: 0.316312\n",
      "\n",
      "Iteration 111, loss = 1.47050352\n",
      "Training set score: 0.614049\n",
      "Test set score: 0.315508\n",
      "\n",
      "Iteration 112, loss = 1.46857468\n",
      "Training set score: 0.614376\n",
      "Test set score: 0.315896\n",
      "\n",
      "Iteration 113, loss = 1.46668666\n",
      "Training set score: 0.614725\n",
      "Test set score: 0.315508\n",
      "\n",
      "Iteration 114, loss = 1.46477060\n",
      "Training set score: 0.615001\n",
      "Test set score: 0.315453\n",
      "\n",
      "Iteration 115, loss = 1.46287477\n",
      "Training set score: 0.615140\n",
      "Test set score: 0.316034\n",
      "\n",
      "Iteration 116, loss = 1.46101748\n",
      "Training set score: 0.615489\n",
      "Test set score: 0.315868\n",
      "\n",
      "Iteration 117, loss = 1.45927082\n",
      "Training set score: 0.615852\n",
      "Test set score: 0.315563\n",
      "\n",
      "Iteration 118, loss = 1.45739805\n",
      "Training set score: 0.615772\n",
      "Test set score: 0.315813\n",
      "\n",
      "Iteration 119, loss = 1.45551256\n",
      "Training set score: 0.616354\n",
      "Test set score: 0.315647\n",
      "\n",
      "Iteration 120, loss = 1.45390723\n",
      "Training set score: 0.616928\n",
      "Test set score: 0.316173\n",
      "\n",
      "Iteration 121, loss = 1.45195944\n",
      "Training set score: 0.617176\n",
      "Test set score: 0.315868\n",
      "\n",
      "Iteration 122, loss = 1.45027546\n",
      "Training set score: 0.617757\n",
      "Test set score: 0.315619\n",
      "\n",
      "Iteration 123, loss = 1.44870432\n",
      "Training set score: 0.617954\n",
      "Test set score: 0.315453\n",
      "\n",
      "Iteration 124, loss = 1.44701065\n",
      "Training set score: 0.617917\n",
      "Test set score: 0.315314\n",
      "\n",
      "Iteration 125, loss = 1.44533220\n",
      "Training set score: 0.618426\n",
      "Test set score: 0.315619\n",
      "\n",
      "Iteration 126, loss = 1.44381485\n",
      "Training set score: 0.618579\n",
      "Test set score: 0.315813\n",
      "\n",
      "Iteration 127, loss = 1.44220415\n",
      "Training set score: 0.619161\n",
      "Test set score: 0.315176\n",
      "\n",
      "Iteration 128, loss = 1.44063658\n",
      "Training set score: 0.619546\n",
      "Test set score: 0.315369\n",
      "\n",
      "Iteration 129, loss = 1.43898753\n",
      "Training set score: 0.619786\n",
      "Test set score: 0.314594\n",
      "\n",
      "Iteration 130, loss = 1.43739103\n",
      "Training set score: 0.620259\n",
      "Test set score: 0.315037\n",
      "\n",
      "Iteration 131, loss = 1.43586883\n",
      "Training set score: 0.620375\n",
      "Test set score: 0.315342\n",
      "\n",
      "Iteration 132, loss = 1.43432822\n",
      "Training set score: 0.620819\n",
      "Test set score: 0.315369\n",
      "\n",
      "Iteration 133, loss = 1.43273808\n",
      "Training set score: 0.621124\n",
      "Test set score: 0.316007\n",
      "\n",
      "Iteration 134, loss = 1.43131139\n",
      "Training set score: 0.621597\n",
      "Test set score: 0.316173\n",
      "\n",
      "Iteration 135, loss = 1.42990768\n",
      "Training set score: 0.621699\n",
      "Test set score: 0.316007\n",
      "\n",
      "Iteration 136, loss = 1.42828682\n",
      "Training set score: 0.621888\n",
      "Test set score: 0.315619\n",
      "\n",
      "Iteration 137, loss = 1.42674372\n",
      "Training set score: 0.622186\n",
      "Test set score: 0.315203\n",
      "\n",
      "Iteration 138, loss = 1.42541285\n",
      "Training set score: 0.621866\n",
      "Test set score: 0.315286\n",
      "\n",
      "Iteration 139, loss = 1.42400660\n",
      "Training set score: 0.622411\n",
      "Test set score: 0.314760\n",
      "\n",
      "Iteration 140, loss = 1.42262505\n",
      "Training set score: 0.622528\n",
      "Test set score: 0.314843\n",
      "\n",
      "Iteration 141, loss = 1.42123261\n",
      "Training set score: 0.622666\n",
      "Test set score: 0.314594\n",
      "\n",
      "Iteration 142, loss = 1.41982965\n",
      "Training set score: 0.622702\n",
      "Test set score: 0.314732\n",
      "\n",
      "Iteration 143, loss = 1.41844145\n",
      "Training set score: 0.623168\n",
      "Test set score: 0.314677\n",
      "\n",
      "Iteration 144, loss = 1.41704689\n",
      "Training set score: 0.623720\n",
      "Test set score: 0.314206\n",
      "\n",
      "Iteration 145, loss = 1.41575738\n",
      "Training set score: 0.623938\n",
      "Test set score: 0.314621\n",
      "\n",
      "Iteration 146, loss = 1.41448878\n",
      "Training set score: 0.624280\n",
      "Test set score: 0.313956\n",
      "\n",
      "Iteration 147, loss = 1.41316345\n",
      "Training set score: 0.624484\n",
      "Test set score: 0.314372\n",
      "\n",
      "Iteration 148, loss = 1.41185368\n",
      "Training set score: 0.624855\n",
      "Test set score: 0.314400\n",
      "\n",
      "Iteration 149, loss = 1.41063371\n",
      "Training set score: 0.625029\n",
      "Test set score: 0.313901\n",
      "\n",
      "Iteration 150, loss = 1.40940970\n",
      "Training set score: 0.625305\n",
      "Test set score: 0.314538\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    mlp2.fit(X_train, Y_train)\n",
    "    print(\"Training set score: %f\" % mlp2.score(X_train, Y_train))\n",
    "    print(\"Test set score: %f\" % mlp2.score(X_test, Y_test))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.864168618267\n",
      "maxlen 496\n"
     ]
    }
   ],
   "source": [
    "# segment acc\n",
    "from scipy import stats\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "# test\n",
    "maxlen = 0\n",
    "for speaker_id, feature_list in test.items():\n",
    "    speaker_id = idx[speaker_id]\n",
    "    for features in feature_list:\n",
    "        maxlen = max(maxlen, features.shape[1])\n",
    "        x = []\n",
    "        # y = []\n",
    "        frames = concat(features)\n",
    "        for frame in frames:\n",
    "            x.append(frame)\n",
    "            # y.append(speaker_id)\n",
    "        x = scaler.transform(x)\n",
    "        pred = stats.mode(mlp2.predict(x)).mode[0]\n",
    "        y_true.append(speaker_id)\n",
    "        y_pred.append(pred)\n",
    "print(sum(np.array(y_true) == np.array(y_pred))/len(y_true))\n",
    "print('maxlen', maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96\n",
      "maxlen 496\n"
     ]
    }
   ],
   "source": [
    "# all segment acc ~ file\n",
    "from scipy import stats\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "# test\n",
    "maxlen = 0\n",
    "for speaker_id, feature_list in test.items():\n",
    "    speaker_id = idx[speaker_id]\n",
    "    x = []\n",
    "    for features in feature_list:\n",
    "        maxlen = max(maxlen, features.shape[1])\n",
    "        # y = []\n",
    "        frames = concat(features)\n",
    "        for frame in frames:\n",
    "            x.append(frame)\n",
    "            # y.append(speaker_id)\n",
    "    x = scaler.transform(x)\n",
    "    pred = stats.mode(mlp2.predict(x)).mode[0]\n",
    "    y_true.append(speaker_id)\n",
    "    y_pred.append(pred)\n",
    "print(sum(np.array(y_true) == np.array(y_pred))/len(y_true))\n",
    "print('maxlen', maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 4.71781510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pratik varshney\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.130076\n",
      "Test set score: 0.109695\n",
      "\n",
      "Iteration 2, loss = 3.78631292\n",
      "Training set score: 0.205054\n",
      "Test set score: 0.168518\n",
      "\n",
      "Iteration 3, loss = 3.39134134\n",
      "Training set score: 0.253476\n",
      "Test set score: 0.202183\n",
      "\n",
      "Iteration 4, loss = 3.13987274\n",
      "Training set score: 0.290518\n",
      "Test set score: 0.225070\n",
      "\n",
      "Iteration 5, loss = 2.95490548\n",
      "Training set score: 0.320957\n",
      "Test set score: 0.243191\n",
      "\n",
      "Iteration 6, loss = 2.81082890\n",
      "Training set score: 0.346640\n",
      "Test set score: 0.255853\n",
      "\n",
      "Iteration 7, loss = 2.69388481\n",
      "Training set score: 0.367808\n",
      "Test set score: 0.267019\n",
      "\n",
      "Iteration 8, loss = 2.59627334\n",
      "Training set score: 0.386046\n",
      "Test set score: 0.274030\n",
      "\n",
      "Iteration 9, loss = 2.51333534\n",
      "Training set score: 0.401912\n",
      "Test set score: 0.279405\n",
      "\n",
      "Iteration 10, loss = 2.44201357\n",
      "Training set score: 0.415561\n",
      "Test set score: 0.283312\n",
      "\n",
      "Iteration 11, loss = 2.38022132\n",
      "Training set score: 0.427276\n",
      "Test set score: 0.287634\n",
      "\n",
      "Iteration 12, loss = 2.32582483\n",
      "Training set score: 0.438111\n",
      "Test set score: 0.291070\n",
      "\n",
      "Iteration 13, loss = 2.27746303\n",
      "Training set score: 0.447659\n",
      "Test set score: 0.293508\n",
      "\n",
      "Iteration 14, loss = 2.23427553\n",
      "Training set score: 0.456283\n",
      "Test set score: 0.295586\n",
      "\n",
      "Iteration 15, loss = 2.19519653\n",
      "Training set score: 0.463911\n",
      "Test set score: 0.298329\n",
      "\n",
      "Iteration 16, loss = 2.15992929\n",
      "Training set score: 0.471306\n",
      "Test set score: 0.302624\n",
      "\n",
      "Iteration 17, loss = 2.12762234\n",
      "Training set score: 0.478229\n",
      "Test set score: 0.303317\n",
      "\n",
      "Iteration 18, loss = 2.09806901\n",
      "Training set score: 0.484773\n",
      "Test set score: 0.305284\n",
      "\n",
      "Iteration 19, loss = 2.07064555\n",
      "Training set score: 0.490685\n",
      "Test set score: 0.306226\n",
      "\n",
      "Iteration 20, loss = 2.04521659\n",
      "Training set score: 0.495790\n",
      "Test set score: 0.306420\n",
      "\n",
      "Iteration 21, loss = 2.02149274\n",
      "Training set score: 0.500611\n",
      "Test set score: 0.307196\n",
      "\n",
      "Iteration 22, loss = 1.99948674\n",
      "Training set score: 0.504756\n",
      "Test set score: 0.307473\n",
      "\n",
      "Iteration 23, loss = 1.97868755\n",
      "Training set score: 0.508762\n",
      "Test set score: 0.307916\n",
      "\n",
      "Iteration 24, loss = 1.95937590\n",
      "Training set score: 0.512675\n",
      "Test set score: 0.308775\n",
      "\n",
      "Iteration 25, loss = 1.94118748\n",
      "Training set score: 0.516659\n",
      "Test set score: 0.310410\n",
      "\n",
      "Iteration 26, loss = 1.92378399\n",
      "Training set score: 0.520470\n",
      "Test set score: 0.310382\n",
      "\n",
      "Iteration 27, loss = 1.90741337\n",
      "Training set score: 0.523837\n",
      "Test set score: 0.311823\n",
      "\n",
      "Iteration 28, loss = 1.89206082\n",
      "Training set score: 0.527792\n",
      "Test set score: 0.311546\n",
      "\n",
      "Iteration 29, loss = 1.87735008\n",
      "Training set score: 0.530308\n",
      "Test set score: 0.312377\n",
      "\n",
      "Iteration 30, loss = 1.86342498\n",
      "Training set score: 0.533442\n",
      "Test set score: 0.312876\n",
      "\n",
      "Iteration 31, loss = 1.85004989\n",
      "Training set score: 0.536140\n",
      "Test set score: 0.313347\n",
      "\n",
      "Iteration 32, loss = 1.83738587\n",
      "Training set score: 0.538787\n",
      "Test set score: 0.314040\n",
      "\n",
      "Iteration 33, loss = 1.82522450\n",
      "Training set score: 0.541834\n",
      "Test set score: 0.314289\n",
      "\n",
      "Iteration 34, loss = 1.81353716\n",
      "Training set score: 0.543761\n",
      "Test set score: 0.314898\n",
      "\n",
      "Iteration 35, loss = 1.80234869\n",
      "Training set score: 0.546386\n",
      "Test set score: 0.315453\n",
      "\n",
      "Iteration 36, loss = 1.79168763\n",
      "Training set score: 0.548946\n",
      "Test set score: 0.315536\n",
      "\n",
      "Iteration 37, loss = 1.78148177\n",
      "Training set score: 0.551033\n",
      "Test set score: 0.315369\n",
      "\n",
      "Iteration 38, loss = 1.77167264\n",
      "Training set score: 0.552901\n",
      "Test set score: 0.315148\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "# mlp = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=400, alpha=1e-4,\n",
    "#                     solver='sgd', verbose=10, tol=1e-4, random_state=1)\n",
    "mlp3 = MLPClassifier(hidden_layer_sizes=(200,), max_iter=1, alpha=5e-4,\n",
    "                    solver='sgd', verbose=10, tol=5e-4, random_state=1,\n",
    "                    learning_rate_init=.01, learning_rate='adaptive',\n",
    "                    warm_start=True)\n",
    "test_scores = []\n",
    "for i in range(150):\n",
    "    mlp3.fit(X_train, Y_train)\n",
    "    print(\"Training set score: %f\" % mlp3.score(X_train, Y_train))\n",
    "    sc = mlp3.score(X_test, Y_test)\n",
    "    print(\"Test set score: %f\" % sc)\n",
    "    print()\n",
    "    test_scores.append(sc)\n",
    "    if i>2 and test_scores[i] < test_scores[i-1] and test_scores[i-1] < test_scores[i-2]:\n",
    "        print('Test scores decreased in last 2 iter. Stopping.')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 43, loss = 1.72783009\n",
      "Training set score: 0.561846\n",
      "Test set score: 0.316256\n",
      "\n",
      "Iteration 44, loss = 1.72011018\n",
      "Training set score: 0.563118\n",
      "Test set score: 0.316561\n",
      "\n",
      "Iteration 45, loss = 1.71243133\n",
      "Training set score: 0.564718\n",
      "Test set score: 0.316589\n",
      "\n",
      "Iteration 46, loss = 1.70521025\n",
      "Training set score: 0.566114\n",
      "Test set score: 0.316866\n",
      "\n",
      "Iteration 47, loss = 1.69804745\n",
      "Training set score: 0.567554\n",
      "Test set score: 0.316921\n",
      "\n",
      "Iteration 48, loss = 1.69103457\n",
      "Training set score: 0.569030\n",
      "Test set score: 0.317198\n",
      "\n",
      "Iteration 49, loss = 1.68437581\n",
      "Training set score: 0.570193\n",
      "Test set score: 0.317143\n",
      "\n",
      "Iteration 50, loss = 1.67777922\n",
      "Training set score: 0.571175\n",
      "Test set score: 0.317558\n",
      "\n",
      "Iteration 51, loss = 1.67146303\n",
      "Training set score: 0.572593\n",
      "Test set score: 0.318029\n",
      "\n",
      "Iteration 52, loss = 1.66528261\n",
      "Training set score: 0.574091\n",
      "Test set score: 0.317891\n",
      "\n",
      "Iteration 53, loss = 1.65934850\n",
      "Training set score: 0.575073\n",
      "Test set score: 0.318196\n",
      "\n",
      "Iteration 54, loss = 1.65338124\n",
      "Training set score: 0.576316\n",
      "Test set score: 0.318362\n",
      "\n",
      "Iteration 55, loss = 1.64775162\n",
      "Training set score: 0.577756\n",
      "Test set score: 0.318196\n",
      "\n",
      "Iteration 56, loss = 1.64216120\n",
      "Training set score: 0.578396\n",
      "Test set score: 0.318667\n",
      "\n",
      "Iteration 57, loss = 1.63664548\n",
      "Training set score: 0.579588\n",
      "Test set score: 0.318667\n",
      "\n",
      "Iteration 58, loss = 1.63105454\n",
      "Training set score: 0.580468\n",
      "Test set score: 0.319636\n",
      "\n",
      "Iteration 59, loss = 1.62594092\n",
      "Training set score: 0.581646\n",
      "Test set score: 0.319221\n",
      "\n",
      "Iteration 60, loss = 1.62085313\n",
      "Training set score: 0.582599\n",
      "Test set score: 0.319082\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test_scores), 150):\n",
    "    mlp3.fit(X_train, Y_train)\n",
    "    print(\"Training set score: %f\" % mlp3.score(X_train, Y_train))\n",
    "    sc = mlp3.score(X_test, Y_test)\n",
    "    print(\"Test set score: %f\" % sc)\n",
    "    print()\n",
    "    test_scores.append(sc)\n",
    "    if i>2 and test_scores[i] < test_scores[i-1] and test_scores[i-1] < test_scores[i-2]:\n",
    "        print('Test scores decreased in last 2 iter. Stopping.')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88056206089\n",
      "maxlen 496\n"
     ]
    }
   ],
   "source": [
    "# segment acc\n",
    "from scipy import stats\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "# test\n",
    "maxlen = 0\n",
    "for speaker_id, feature_list in test.items():\n",
    "    speaker_id = idx[speaker_id]\n",
    "    for features in feature_list:\n",
    "        maxlen = max(maxlen, features.shape[1])\n",
    "        x = []\n",
    "        # y = []\n",
    "        frames = concat(features)\n",
    "        for frame in frames:\n",
    "            x.append(frame)\n",
    "            # y.append(speaker_id)\n",
    "        x = scaler.transform(x)\n",
    "        pred = stats.mode(mlp3.predict(x)).mode[0]\n",
    "        y_true.append(speaker_id)\n",
    "        y_pred.append(pred)\n",
    "print(sum(np.array(y_true) == np.array(y_pred))/len(y_true))\n",
    "print('maxlen', maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96\n",
      "maxlen 496\n"
     ]
    }
   ],
   "source": [
    "# all segment acc ~ file\n",
    "from scipy import stats\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "# test\n",
    "maxlen = 0\n",
    "for speaker_id, feature_list in test.items():\n",
    "    speaker_id = idx[speaker_id]\n",
    "    x = []\n",
    "    for features in feature_list:\n",
    "        maxlen = max(maxlen, features.shape[1])\n",
    "        # y = []\n",
    "        frames = concat(features)\n",
    "        for frame in frames:\n",
    "            x.append(frame)\n",
    "            # y.append(speaker_id)\n",
    "    x = scaler.transform(x)\n",
    "    pred = stats.mode(mlp2.predict(x)).mode[0]\n",
    "    y_true.append(speaker_id)\n",
    "    y_pred.append(pred)\n",
    "print(sum(np.array(y_true) == np.array(y_pred))/len(y_true))\n",
    "print('maxlen', maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 3.89630197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pratik varshney\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.253956\n",
      "Test set score: 0.197639\n",
      "\n",
      "Iteration 2, loss = 3.02859132\n",
      "Training set score: 0.328905\n",
      "Test set score: 0.237206\n",
      "\n",
      "Iteration 3, loss = 2.73404115\n",
      "Training set score: 0.368965\n",
      "Test set score: 0.253609\n",
      "\n",
      "Iteration 4, loss = 2.56842211\n",
      "Training set score: 0.395528\n",
      "Test set score: 0.264747\n",
      "\n",
      "Iteration 5, loss = 2.45548164\n",
      "Training set score: 0.415300\n",
      "Test set score: 0.272921\n",
      "\n",
      "Iteration 6, loss = 2.37351458\n",
      "Training set score: 0.430606\n",
      "Test set score: 0.277022\n",
      "\n",
      "Iteration 7, loss = 2.30687964\n",
      "Training set score: 0.441398\n",
      "Test set score: 0.281261\n",
      "\n",
      "Iteration 8, loss = 2.25293919\n",
      "Training set score: 0.450233\n",
      "Test set score: 0.283838\n",
      "\n",
      "Iteration 9, loss = 2.21090773\n",
      "Training set score: 0.459031\n",
      "Test set score: 0.286470\n",
      "\n",
      "Iteration 10, loss = 2.17442721\n",
      "Training set score: 0.465285\n",
      "Test set score: 0.285833\n",
      "\n",
      "Iteration 11, loss = 2.14255675\n",
      "Training set score: 0.470855\n",
      "Test set score: 0.285473\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 12, loss = 2.11561201\n",
      "Training set score: 0.475509\n",
      "Test set score: 0.287108\n",
      "\n",
      "Iteration 13, loss = 2.09218001\n",
      "Training set score: 0.478381\n",
      "Test set score: 0.286664\n",
      "\n",
      "Iteration 14, loss = 2.06930670\n",
      "Training set score: 0.483522\n",
      "Test set score: 0.285722\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 15, loss = 2.04967962\n",
      "Training set score: 0.487035\n",
      "Test set score: 0.285888\n",
      "\n",
      "Iteration 16, loss = 2.03210546\n",
      "Training set score: 0.489943\n",
      "Test set score: 0.287994\n",
      "\n",
      "Iteration 17, loss = 2.01683021\n",
      "Training set score: 0.493448\n",
      "Test set score: 0.287883\n",
      "\n",
      "Iteration 18, loss = 2.00081633\n",
      "Training set score: 0.497288\n",
      "Test set score: 0.290017\n",
      "\n",
      "Iteration 19, loss = 1.98670472\n",
      "Training set score: 0.498473\n",
      "Test set score: 0.288576\n",
      "\n",
      "Iteration 20, loss = 1.97527781\n",
      "Training set score: 0.501200\n",
      "Test set score: 0.289463\n",
      "\n",
      "Iteration 21, loss = 1.96361772\n",
      "Training set score: 0.502858\n",
      "Test set score: 0.290017\n",
      "\n",
      "Iteration 22, loss = 1.95180690\n",
      "Training set score: 0.504581\n",
      "Test set score: 0.290266\n",
      "\n",
      "Iteration 23, loss = 1.94249748\n",
      "Training set score: 0.506639\n",
      "Test set score: 0.290599\n",
      "\n",
      "Iteration 24, loss = 1.93405272\n",
      "Training set score: 0.510471\n",
      "Test set score: 0.289019\n",
      "\n",
      "Iteration 25, loss = 1.92496071\n",
      "Training set score: 0.510806\n",
      "Test set score: 0.290100\n",
      "\n",
      "Iteration 26, loss = 1.91763230\n",
      "Training set score: 0.513045\n",
      "Test set score: 0.290765\n",
      "\n",
      "Iteration 27, loss = 1.90834490\n",
      "Training set score: 0.514347\n",
      "Test set score: 0.292261\n",
      "\n",
      "Iteration 28, loss = 1.90143781\n",
      "Training set score: 0.515103\n",
      "Test set score: 0.292067\n",
      "\n",
      "Iteration 29, loss = 1.89419724\n",
      "Training set score: 0.516761\n",
      "Test set score: 0.289574\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 30, loss = 1.88685337\n",
      "Training set score: 0.517139\n",
      "Test set score: 0.288964\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 31, loss = 1.88167901\n",
      "Training set score: 0.519452\n",
      "Test set score: 0.290460\n",
      "\n",
      "Iteration 32, loss = 1.87529913\n",
      "Training set score: 0.519859\n",
      "Test set score: 0.291541\n",
      "\n",
      "Iteration 33, loss = 1.86848476\n",
      "Training set score: 0.520084\n",
      "Test set score: 0.290183\n",
      "\n",
      "Iteration 34, loss = 1.86398021\n",
      "Training set score: 0.521110\n",
      "Test set score: 0.288327\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 35, loss = 1.85848584\n",
      "Training set score: 0.522484\n",
      "Test set score: 0.290654\n",
      "\n",
      "Iteration 36, loss = 1.85399237\n",
      "Training set score: 0.523429\n",
      "Test set score: 0.291485\n",
      "\n",
      "Iteration 37, loss = 1.84971842\n",
      "Training set score: 0.523597\n",
      "Test set score: 0.289297\n",
      "\n",
      "Iteration 38, loss = 1.84463682\n",
      "Training set score: 0.523604\n",
      "Test set score: 0.288881\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 39, loss = 1.83940267\n",
      "Training set score: 0.524862\n",
      "Test set score: 0.290211\n",
      "\n",
      "Iteration 40, loss = 1.83584980\n",
      "Training set score: 0.525582\n",
      "Test set score: 0.287939\n",
      "\n",
      "Iteration 41, loss = 1.83145716\n",
      "Training set score: 0.525116\n",
      "Test set score: 0.288493\n",
      "\n",
      "Iteration 42, loss = 1.82792526\n",
      "Training set score: 0.526069\n",
      "Test set score: 0.288022\n",
      "\n",
      "Iteration 43, loss = 1.82426040\n",
      "Training set score: 0.527196\n",
      "Test set score: 0.288909\n",
      "\n",
      "Iteration 44, loss = 1.82032222\n",
      "Training set score: 0.527276\n",
      "Test set score: 0.288687\n",
      "\n",
      "Iteration 45, loss = 1.81487277\n",
      "Training set score: 0.528352\n",
      "Test set score: 0.287606\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 46, loss = 1.81171307\n",
      "Training set score: 0.527792\n",
      "Test set score: 0.288299\n",
      "\n",
      "Iteration 47, loss = 1.80894665\n",
      "Training set score: 0.530352\n",
      "Test set score: 0.287523\n",
      "\n",
      "Iteration 48, loss = 1.80523423\n",
      "Training set score: 0.530301\n",
      "Test set score: 0.289047\n",
      "\n",
      "Iteration 49, loss = 1.80332592\n",
      "Training set score: 0.531494\n",
      "Test set score: 0.286609\n",
      "\n",
      "Iteration 50, loss = 1.79826620\n",
      "Training set score: 0.530752\n",
      "Test set score: 0.287800\n",
      "\n",
      "Iteration 51, loss = 1.79616412\n",
      "Training set score: 0.531275\n",
      "Test set score: 0.286914\n",
      "\n",
      "Iteration 52, loss = 1.79333305\n",
      "Training set score: 0.532017\n",
      "Test set score: 0.285362\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 53, loss = 1.78959028\n",
      "Training set score: 0.532730\n",
      "Test set score: 0.287135\n",
      "\n",
      "Iteration 54, loss = 1.78834850\n",
      "Training set score: 0.533588\n",
      "Test set score: 0.288216\n",
      "\n",
      "Iteration 55, loss = 1.78435344\n",
      "Training set score: 0.534250\n",
      "Test set score: 0.286359\n",
      "\n",
      "Iteration 56, loss = 1.78298227\n",
      "Training set score: 0.533755\n",
      "Test set score: 0.284836\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 57, loss = 1.78079856\n",
      "Training set score: 0.535035\n",
      "Test set score: 0.286304\n",
      "\n",
      "Iteration 58, loss = 1.77651132\n",
      "Training set score: 0.536271\n",
      "Test set score: 0.286664\n",
      "\n",
      "Iteration 59, loss = 1.77512261\n",
      "Training set score: 0.536809\n",
      "Test set score: 0.286166\n",
      "\n",
      "Iteration 60, loss = 1.77271334\n",
      "Training set score: 0.536736\n",
      "Test set score: 0.286193\n",
      "\n",
      "Iteration 61, loss = 1.76951872\n",
      "Training set score: 0.538307\n",
      "Test set score: 0.286443\n",
      "\n",
      "Iteration 62, loss = 1.76809493\n",
      "Training set score: 0.537718\n",
      "Test set score: 0.287745\n",
      "\n",
      "Iteration 63, loss = 1.76566954\n",
      "Training set score: 0.539958\n",
      "Test set score: 0.287551\n",
      "\n",
      "Iteration 64, loss = 1.76192655\n",
      "Training set score: 0.540743\n",
      "Test set score: 0.287191\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 65, loss = 1.76046670\n",
      "Training set score: 0.540220\n",
      "Test set score: 0.286332\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 66, loss = 1.75844068\n",
      "Training set score: 0.541005\n",
      "Test set score: 0.286332\n",
      "\n",
      "Iteration 67, loss = 1.75637705\n",
      "Training set score: 0.542045\n",
      "Test set score: 0.285639\n",
      "\n",
      "Iteration 68, loss = 1.75392682\n",
      "Training set score: 0.542357\n",
      "Test set score: 0.285473\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 69, loss = 1.75210987\n",
      "Training set score: 0.542961\n",
      "Test set score: 0.286304\n",
      "\n",
      "Iteration 70, loss = 1.74960083\n",
      "Training set score: 0.541492\n",
      "Test set score: 0.287135\n",
      "\n",
      "Iteration 71, loss = 1.74850919\n",
      "Training set score: 0.543645\n",
      "Test set score: 0.285556\n",
      "\n",
      "Iteration 72, loss = 1.74618557\n",
      "Training set score: 0.542823\n",
      "Test set score: 0.285085\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 73, loss = 1.74491853\n",
      "Training set score: 0.542808\n",
      "Test set score: 0.285473\n",
      "\n",
      "Iteration 74, loss = 1.74292885\n",
      "Training set score: 0.543594\n",
      "Test set score: 0.284365\n",
      "\n",
      "Iteration 75, loss = 1.74115487\n",
      "Training set score: 0.545259\n",
      "Test set score: 0.284309\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 76, loss = 1.73980532\n",
      "Training set score: 0.543790\n",
      "Test set score: 0.283949\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 77, loss = 1.73871700\n",
      "Training set score: 0.546190\n",
      "Test set score: 0.283506\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 78, loss = 1.73634497\n",
      "Training set score: 0.547040\n",
      "Test set score: 0.283866\n",
      "\n",
      "Iteration 79, loss = 1.73447289\n",
      "Training set score: 0.548284\n",
      "Test set score: 0.283893\n",
      "\n",
      "Iteration 80, loss = 1.73434884\n",
      "Training set score: 0.547120\n",
      "Test set score: 0.283450\n",
      "\n",
      "Iteration 81, loss = 1.73180881\n",
      "Training set score: 0.548218\n",
      "Test set score: 0.284642\n",
      "\n",
      "Iteration 82, loss = 1.72989520\n",
      "Training set score: 0.547317\n",
      "Test set score: 0.283783\n",
      "\n",
      "Iteration 83, loss = 1.72874467\n",
      "Training set score: 0.548080\n",
      "Test set score: 0.283644\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 84, loss = 1.72646299\n",
      "Training set score: 0.548982\n",
      "Test set score: 0.284642\n",
      "\n",
      "Iteration 85, loss = 1.72578671\n",
      "Training set score: 0.549484\n",
      "Test set score: 0.283506\n",
      "\n",
      "Iteration 86, loss = 1.72409941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.548786\n",
      "Test set score: 0.284060\n",
      "\n",
      "Iteration 87, loss = 1.72305084\n",
      "Training set score: 0.549295\n",
      "Test set score: 0.281594\n",
      "\n",
      "Iteration 88, loss = 1.72137496\n",
      "Training set score: 0.549091\n",
      "Test set score: 0.283700\n",
      "\n",
      "Iteration 89, loss = 1.72087031\n",
      "Training set score: 0.551222\n",
      "Test set score: 0.283367\n",
      "\n",
      "Iteration 90, loss = 1.71940485\n",
      "Training set score: 0.550742\n",
      "Test set score: 0.283173\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 91, loss = 1.71658201\n",
      "Training set score: 0.551105\n",
      "Test set score: 0.282259\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 92, loss = 1.71619120\n",
      "Training set score: 0.550887\n",
      "Test set score: 0.282619\n",
      "\n",
      "Iteration 93, loss = 1.71458046\n",
      "Training set score: 0.552291\n",
      "Test set score: 0.282757\n",
      "\n",
      "Iteration 94, loss = 1.71307891\n",
      "Training set score: 0.551760\n",
      "Test set score: 0.282397\n",
      "\n",
      "Iteration 95, loss = 1.71241414\n",
      "Training set score: 0.552472\n",
      "Test set score: 0.281289\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 96, loss = 1.71167720\n",
      "Training set score: 0.552792\n",
      "Test set score: 0.281095\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 97, loss = 1.71025275\n",
      "Training set score: 0.552145\n",
      "Test set score: 0.282065\n",
      "\n",
      "Iteration 98, loss = 1.70822584\n",
      "Training set score: 0.552916\n",
      "Test set score: 0.283035\n",
      "\n",
      "Iteration 99, loss = 1.70903926\n",
      "Training set score: 0.552974\n",
      "Test set score: 0.283727\n",
      "\n",
      "Iteration 100, loss = 1.70537342\n",
      "Training set score: 0.553265\n",
      "Test set score: 0.281815\n",
      "\n",
      "Iteration 101, loss = 1.70563246\n",
      "Training set score: 0.552967\n",
      "Test set score: 0.282924\n",
      "\n",
      "Iteration 102, loss = 1.70432446\n",
      "Training set score: 0.552872\n",
      "Test set score: 0.283838\n",
      "\n",
      "Iteration 103, loss = 1.70454299\n",
      "Training set score: 0.554167\n",
      "Test set score: 0.283395\n",
      "\n",
      "Iteration 104, loss = 1.70216939\n",
      "Training set score: 0.552189\n",
      "Test set score: 0.281843\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 105, loss = 1.70099215\n",
      "Training set score: 0.553621\n",
      "Test set score: 0.284060\n",
      "\n",
      "Iteration 106, loss = 1.69968395\n",
      "Training set score: 0.555090\n",
      "Test set score: 0.283035\n",
      "\n",
      "Iteration 107, loss = 1.69799569\n",
      "Training set score: 0.555250\n",
      "Test set score: 0.281899\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 108, loss = 1.69784062\n",
      "Training set score: 0.554508\n",
      "Test set score: 0.283256\n",
      "\n",
      "Iteration 109, loss = 1.69647701\n",
      "Training set score: 0.555774\n",
      "Test set score: 0.283589\n",
      "\n",
      "Iteration 110, loss = 1.69657130\n",
      "Training set score: 0.556305\n",
      "Test set score: 0.282453\n",
      "\n",
      "Iteration 111, loss = 1.69411461\n",
      "Training set score: 0.555643\n",
      "Test set score: 0.283062\n",
      "\n",
      "Iteration 112, loss = 1.69466111\n",
      "Training set score: 0.555439\n",
      "Test set score: 0.282841\n",
      "\n",
      "Iteration 113, loss = 1.69255765\n",
      "Training set score: 0.557163\n",
      "Test set score: 0.284143\n",
      "\n",
      "Iteration 114, loss = 1.69150616\n",
      "Training set score: 0.557221\n",
      "Test set score: 0.282813\n",
      "\n",
      "Iteration 115, loss = 1.69119192\n",
      "Training set score: 0.555883\n",
      "Test set score: 0.281677\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 116, loss = 1.69095013\n",
      "Training set score: 0.556712\n",
      "Test set score: 0.283422\n",
      "\n",
      "Iteration 117, loss = 1.69062507\n",
      "Training set score: 0.556130\n",
      "Test set score: 0.281289\n",
      "\n",
      "Iteration 118, loss = 1.69061117\n",
      "Training set score: 0.557163\n",
      "Test set score: 0.283007\n",
      "\n",
      "Iteration 119, loss = 1.68957311\n",
      "Training set score: 0.557177\n",
      "Test set score: 0.283727\n",
      "\n",
      "Iteration 120, loss = 1.68702482\n",
      "Training set score: 0.558421\n",
      "Test set score: 0.281954\n",
      "\n",
      "Iteration 121, loss = 1.68750392\n",
      "Training set score: 0.558646\n",
      "Test set score: 0.282564\n",
      "\n",
      "Iteration 122, loss = 1.68634985\n",
      "Training set score: 0.557955\n",
      "Test set score: 0.282176\n",
      "\n",
      "Iteration 123, loss = 1.68581459\n",
      "Training set score: 0.558544\n",
      "Test set score: 0.282868\n",
      "\n",
      "Iteration 124, loss = 1.68530441\n",
      "Training set score: 0.558966\n",
      "Test set score: 0.283755\n",
      "\n",
      "Iteration 125, loss = 1.68422018\n",
      "Training set score: 0.559999\n",
      "Test set score: 0.282702\n",
      "\n",
      "Iteration 126, loss = 1.68231701\n",
      "Training set score: 0.560355\n",
      "Test set score: 0.283949\n",
      "\n",
      "Iteration 127, loss = 1.68100817\n",
      "Training set score: 0.560289\n",
      "Test set score: 0.283035\n",
      "\n",
      "Iteration 128, loss = 1.68285843\n",
      "Training set score: 0.559388\n",
      "Test set score: 0.281649\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 129, loss = 1.67976758\n",
      "Training set score: 0.560566\n",
      "Test set score: 0.282370\n",
      "\n",
      "Iteration 130, loss = 1.68019306\n",
      "Training set score: 0.560987\n",
      "Test set score: 0.282591\n",
      "\n",
      "Iteration 131, loss = 1.67991245\n",
      "Training set score: 0.560318\n",
      "Test set score: 0.284891\n",
      "\n",
      "Iteration 132, loss = 1.67922037\n",
      "Training set score: 0.560406\n",
      "Test set score: 0.283145\n",
      "\n",
      "Iteration 133, loss = 1.67878974\n",
      "Training set score: 0.560471\n",
      "Test set score: 0.283478\n",
      "\n",
      "Iteration 134, loss = 1.67722917\n",
      "Training set score: 0.560871\n",
      "Test set score: 0.284087\n",
      "\n",
      "Iteration 135, loss = 1.67633721\n",
      "Training set score: 0.560740\n",
      "Test set score: 0.282286\n",
      "\n",
      "Iteration 136, loss = 1.67457401\n",
      "Training set score: 0.560420\n",
      "Test set score: 0.283589\n",
      "\n",
      "Iteration 137, loss = 1.67450449\n",
      "Training set score: 0.561184\n",
      "Test set score: 0.282647\n",
      "\n",
      "Iteration 138, loss = 1.67351471\n",
      "Training set score: 0.560602\n",
      "Test set score: 0.281649\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 139, loss = 1.67423922\n",
      "Training set score: 0.560035\n",
      "Test set score: 0.283783\n",
      "\n",
      "Iteration 140, loss = 1.67367110\n",
      "Training set score: 0.561227\n",
      "Test set score: 0.282397\n",
      "\n",
      "Iteration 141, loss = 1.67159002\n",
      "Training set score: 0.560958\n",
      "Test set score: 0.281594\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 142, loss = 1.67162771\n",
      "Training set score: 0.561366\n",
      "Test set score: 0.281511\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 143, loss = 1.67203934\n",
      "Training set score: 0.561206\n",
      "Test set score: 0.281843\n",
      "\n",
      "Iteration 144, loss = 1.67114544\n",
      "Training set score: 0.561038\n",
      "Test set score: 0.282009\n",
      "\n",
      "Iteration 145, loss = 1.67075415\n",
      "Training set score: 0.562340\n",
      "Test set score: 0.280291\n",
      "\n",
      "Iteration 146, loss = 1.66888808\n",
      "Training set score: 0.562638\n",
      "Test set score: 0.280347\n",
      "\n",
      "Iteration 147, loss = 1.66779864\n",
      "Training set score: 0.562260\n",
      "Test set score: 0.280956\n",
      "\n",
      "Iteration 148, loss = 1.66722455\n",
      "Training set score: 0.561576\n",
      "Test set score: 0.279460\n",
      "\n",
      "Iteration 149, loss = 1.66673972\n",
      "Training set score: 0.561627\n",
      "Test set score: 0.279682\n",
      "\n",
      "Iteration 150, loss = 1.66609966\n",
      "Training set score: 0.561649\n",
      "Test set score: 0.281067\n",
      "\n",
      "Iteration 151, loss = 1.66684796\n",
      "Training set score: 0.563671\n",
      "Test set score: 0.280319\n",
      "\n",
      "Iteration 152, loss = 1.66527055\n",
      "Training set score: 0.562180\n",
      "Test set score: 0.280181\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 153, loss = 1.66650100\n",
      "Training set score: 0.562442\n",
      "Test set score: 0.279793\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 154, loss = 1.66537275\n",
      "Training set score: 0.563191\n",
      "Test set score: 0.281871\n",
      "\n",
      "Iteration 155, loss = 1.66478716\n",
      "Training set score: 0.564085\n",
      "Test set score: 0.279876\n",
      "\n",
      "Iteration 156, loss = 1.66335389\n",
      "Training set score: 0.562464\n",
      "Test set score: 0.280264\n",
      "\n",
      "Iteration 157, loss = 1.66264523\n",
      "Training set score: 0.562987\n",
      "Test set score: 0.279460\n",
      "\n",
      "Iteration 158, loss = 1.66363856\n",
      "Training set score: 0.563634\n",
      "Test set score: 0.279626\n",
      "\n",
      "Iteration 159, loss = 1.66176161\n",
      "Training set score: 0.563031\n",
      "Test set score: 0.279433\n",
      "\n",
      "Iteration 160, loss = 1.66028026\n",
      "Training set score: 0.564565\n",
      "Test set score: 0.280735\n",
      "\n",
      "Iteration 161, loss = 1.65920742\n",
      "Training set score: 0.562958\n",
      "Test set score: 0.280735\n",
      "\n",
      "Iteration 162, loss = 1.65928716\n",
      "Training set score: 0.563482\n",
      "Test set score: 0.280402\n",
      "\n",
      "Iteration 163, loss = 1.65896378\n",
      "Training set score: 0.562689\n",
      "Test set score: 0.278795\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 164, loss = 1.65884105\n",
      "Training set score: 0.562027\n",
      "Test set score: 0.279072\n",
      "\n",
      "Iteration 165, loss = 1.65813582\n",
      "Training set score: 0.563285\n",
      "Test set score: 0.280098\n",
      "\n",
      "Iteration 166, loss = 1.65971463\n",
      "Training set score: 0.563104\n",
      "Test set score: 0.278435\n",
      "\n",
      "Iteration 167, loss = 1.65863203\n",
      "Training set score: 0.562209\n",
      "Test set score: 0.279460\n",
      "\n",
      "Iteration 168, loss = 1.65746250\n",
      "Training set score: 0.562464\n",
      "Test set score: 0.280347\n",
      "\n",
      "Iteration 169, loss = 1.65846146\n",
      "Training set score: 0.563125\n",
      "Test set score: 0.279793\n",
      "\n",
      "Iteration 170, loss = 1.65703415\n",
      "Training set score: 0.562551\n",
      "Test set score: 0.279211\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 171, loss = 1.65545172\n",
      "Training set score: 0.562733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.277964\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 172, loss = 1.65637488\n",
      "Training set score: 0.563460\n",
      "Test set score: 0.278324\n",
      "\n",
      "Iteration 173, loss = 1.65599798\n",
      "Training set score: 0.562595\n",
      "Test set score: 0.278684\n",
      "\n",
      "Iteration 174, loss = 1.65621384\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.010000\n",
      "Training set score: 0.563438\n",
      "Test set score: 0.279987\n",
      "\n",
      "Iteration 175, loss = 1.41040656\n",
      "Training set score: 0.648342\n",
      "Test set score: 0.299105\n",
      "\n",
      "Iteration 176, loss = 1.30278196\n",
      "Training set score: 0.655868\n",
      "Test set score: 0.300241\n",
      "\n",
      "Iteration 177, loss = 1.27655631\n",
      "Training set score: 0.659729\n",
      "Test set score: 0.301377\n",
      "\n",
      "Iteration 178, loss = 1.26147999\n",
      "Training set score: 0.662595\n",
      "Test set score: 0.301432\n",
      "\n",
      "Iteration 179, loss = 1.25046206\n",
      "Training set score: 0.664754\n",
      "Test set score: 0.301654\n",
      "\n",
      "Iteration 180, loss = 1.24205926\n",
      "Training set score: 0.666434\n",
      "Test set score: 0.302042\n",
      "\n",
      "Iteration 181, loss = 1.23506301\n",
      "Training set score: 0.668216\n",
      "Test set score: 0.301820\n",
      "\n",
      "Iteration 182, loss = 1.22918637\n",
      "Training set score: 0.668935\n",
      "Test set score: 0.301959\n",
      "\n",
      "Iteration 183, loss = 1.22407983\n",
      "Training set score: 0.670026\n",
      "Test set score: 0.301377\n",
      "\n",
      "Iteration 184, loss = 1.21970359\n",
      "Training set score: 0.670608\n",
      "Test set score: 0.301599\n",
      "\n",
      "Iteration 185, loss = 1.21572927\n",
      "Training set score: 0.671553\n",
      "Test set score: 0.301654\n",
      "\n",
      "Iteration 186, loss = 1.21212978\n",
      "Training set score: 0.672615\n",
      "Test set score: 0.302347\n",
      "\n",
      "Iteration 187, loss = 1.20884813\n",
      "Training set score: 0.673611\n",
      "Test set score: 0.302319\n",
      "\n",
      "Iteration 188, loss = 1.20582512\n",
      "Training set score: 0.673975\n",
      "Test set score: 0.302596\n",
      "\n",
      "Iteration 189, loss = 1.20314804\n",
      "Training set score: 0.674898\n",
      "Test set score: 0.302291\n",
      "\n",
      "Iteration 190, loss = 1.20050249\n",
      "Training set score: 0.675116\n",
      "Test set score: 0.302319\n",
      "\n",
      "Iteration 191, loss = 1.19806739\n",
      "Training set score: 0.675982\n",
      "Test set score: 0.302513\n",
      "\n",
      "Iteration 192, loss = 1.19585209\n",
      "Training set score: 0.676774\n",
      "Test set score: 0.302458\n",
      "\n",
      "Iteration 193, loss = 1.19367692\n",
      "Training set score: 0.676869\n",
      "Test set score: 0.301987\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 194, loss = 1.19182158\n",
      "Training set score: 0.677480\n",
      "Test set score: 0.302652\n",
      "\n",
      "Iteration 195, loss = 1.18975890\n",
      "Training set score: 0.678061\n",
      "Test set score: 0.302153\n",
      "\n",
      "Iteration 196, loss = 1.18801218\n",
      "Training set score: 0.678396\n",
      "Test set score: 0.301904\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 197, loss = 1.18620431\n",
      "Training set score: 0.678767\n",
      "Test set score: 0.302319\n",
      "\n",
      "Iteration 198, loss = 1.18460484\n",
      "Training set score: 0.679167\n",
      "Test set score: 0.302236\n",
      "\n",
      "Iteration 199, loss = 1.18291995\n",
      "Training set score: 0.679552\n",
      "Test set score: 0.301904\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 200, loss = 1.18156013\n",
      "Training set score: 0.680199\n",
      "Test set score: 0.301987\n",
      "\n",
      "Iteration 201, loss = 1.18017155\n",
      "Training set score: 0.680156\n",
      "Test set score: 0.301266\n",
      "\n",
      "Iteration 202, loss = 1.17868857\n",
      "Training set score: 0.680272\n",
      "Test set score: 0.301239\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 203, loss = 1.17737502\n",
      "Training set score: 0.680912\n",
      "Test set score: 0.301239\n",
      "\n",
      "Iteration 204, loss = 1.17611069\n",
      "Training set score: 0.681203\n",
      "Test set score: 0.301710\n",
      "\n",
      "Iteration 205, loss = 1.17488975\n",
      "Training set score: 0.681435\n",
      "Test set score: 0.301820\n",
      "\n",
      "Iteration 206, loss = 1.17364793\n",
      "Training set score: 0.681712\n",
      "Test set score: 0.301405\n",
      "\n",
      "Iteration 207, loss = 1.17243698\n",
      "Training set score: 0.682104\n",
      "Test set score: 0.301100\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 208, loss = 1.17126847\n",
      "Training set score: 0.682381\n",
      "Test set score: 0.301432\n",
      "\n",
      "Iteration 209, loss = 1.17013671\n",
      "Training set score: 0.682672\n",
      "Test set score: 0.301737\n",
      "\n",
      "Iteration 210, loss = 1.16893018\n",
      "Training set score: 0.682752\n",
      "Test set score: 0.301848\n",
      "\n",
      "Iteration 211, loss = 1.16816025\n",
      "Training set score: 0.683501\n",
      "Test set score: 0.301654\n",
      "\n",
      "Iteration 212, loss = 1.16702693\n",
      "Training set score: 0.683384\n",
      "Test set score: 0.301959\n",
      "\n",
      "Iteration 213, loss = 1.16604349\n",
      "Training set score: 0.684002\n",
      "Test set score: 0.301460\n",
      "\n",
      "Iteration 214, loss = 1.16512740\n",
      "Training set score: 0.684104\n",
      "Test set score: 0.301571\n",
      "\n",
      "Iteration 215, loss = 1.16415511\n",
      "Training set score: 0.684439\n",
      "Test set score: 0.301543\n",
      "\n",
      "Iteration 216, loss = 1.16324814\n",
      "Training set score: 0.684628\n",
      "Test set score: 0.300961\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 217, loss = 1.16229899\n",
      "Training set score: 0.685086\n",
      "Test set score: 0.301266\n",
      "\n",
      "Iteration 218, loss = 1.16143903\n",
      "Training set score: 0.685275\n",
      "Test set score: 0.301239\n",
      "\n",
      "Iteration 219, loss = 1.16057214\n",
      "Training set score: 0.685086\n",
      "Test set score: 0.301349\n",
      "\n",
      "Iteration 220, loss = 1.15978774\n",
      "Training set score: 0.685500\n",
      "Test set score: 0.301100\n",
      "\n",
      "Iteration 221, loss = 1.15898721\n",
      "Training set score: 0.685464\n",
      "Test set score: 0.301571\n",
      "\n",
      "Iteration 222, loss = 1.15821171\n",
      "Training set score: 0.685442\n",
      "Test set score: 0.301266\n",
      "\n",
      "Iteration 223, loss = 1.15741873\n",
      "Training set score: 0.685900\n",
      "Test set score: 0.300934\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 224, loss = 1.15670154\n",
      "Training set score: 0.685980\n",
      "Test set score: 0.301045\n",
      "\n",
      "Iteration 225, loss = 1.15597980\n",
      "Training set score: 0.686089\n",
      "Test set score: 0.301349\n",
      "\n",
      "Iteration 226, loss = 1.15518665\n",
      "Training set score: 0.686460\n",
      "Test set score: 0.301183\n",
      "\n",
      "Iteration 227, loss = 1.15449639\n",
      "Training set score: 0.686576\n",
      "Test set score: 0.301100\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 228, loss = 1.15377185\n",
      "Training set score: 0.686584\n",
      "Test set score: 0.300906\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 229, loss = 1.15304255\n",
      "Training set score: 0.686853\n",
      "Test set score: 0.301488\n",
      "\n",
      "Iteration 230, loss = 1.15250255\n",
      "Training set score: 0.686998\n",
      "Test set score: 0.301294\n",
      "\n",
      "Iteration 231, loss = 1.15175289\n",
      "Training set score: 0.687173\n",
      "Test set score: 0.301543\n",
      "\n",
      "Iteration 232, loss = 1.15107923\n",
      "Training set score: 0.687071\n",
      "Test set score: 0.301848\n",
      "\n",
      "Iteration 233, loss = 1.15044533\n",
      "Training set score: 0.687864\n",
      "Test set score: 0.301377\n",
      "\n",
      "Iteration 234, loss = 1.14992310\n",
      "Training set score: 0.687340\n",
      "Test set score: 0.301100\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 235, loss = 1.14927751\n",
      "Training set score: 0.687929\n",
      "Test set score: 0.301654\n",
      "\n",
      "Iteration 236, loss = 1.14854702\n",
      "Training set score: 0.687645\n",
      "Test set score: 0.300961\n",
      "\n",
      "Iteration 237, loss = 1.14807702\n",
      "Training set score: 0.687842\n",
      "Test set score: 0.301322\n",
      "\n",
      "Iteration 238, loss = 1.14747301\n",
      "Training set score: 0.688053\n",
      "Test set score: 0.300961\n",
      "\n",
      "Iteration 239, loss = 1.14691069\n",
      "Training set score: 0.688424\n",
      "Test set score: 0.301322\n",
      "\n",
      "Iteration 240, loss = 1.14637038\n",
      "Training set score: 0.688205\n",
      "Test set score: 0.301017\n",
      "\n",
      "Iteration 241, loss = 1.14578591\n",
      "Training set score: 0.688634\n",
      "Test set score: 0.301377\n",
      "\n",
      "Iteration 242, loss = 1.14518074\n",
      "Training set score: 0.688656\n",
      "Test set score: 0.301543\n",
      "\n",
      "Iteration 243, loss = 1.14462697\n",
      "Training set score: 0.688663\n",
      "Test set score: 0.301377\n",
      "\n",
      "Iteration 244, loss = 1.14409501\n",
      "Training set score: 0.689194\n",
      "Test set score: 0.301183\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 245, loss = 1.14352047\n",
      "Training set score: 0.689289\n",
      "Test set score: 0.301432\n",
      "\n",
      "Iteration 246, loss = 1.14300258\n",
      "Training set score: 0.689172\n",
      "Test set score: 0.301543\n",
      "\n",
      "Iteration 247, loss = 1.14242886\n",
      "Training set score: 0.689500\n",
      "Test set score: 0.301294\n",
      "\n",
      "Iteration 248, loss = 1.14201356\n",
      "Training set score: 0.689660\n",
      "Test set score: 0.301072\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 249, loss = 1.14141381\n",
      "Training set score: 0.689303\n",
      "Test set score: 0.300989\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 250, loss = 1.14099807\n",
      "Training set score: 0.689776\n",
      "Test set score: 0.301128\n",
      "\n",
      "Iteration 251, loss = 1.14051204\n",
      "Training set score: 0.689783\n",
      "Test set score: 0.301017\n",
      "\n",
      "Iteration 252, loss = 1.13999865\n",
      "Training set score: 0.690089\n",
      "Test set score: 0.300518\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 253, loss = 1.13944471\n",
      "Training set score: 0.689812\n",
      "Test set score: 0.301266\n",
      "\n",
      "Iteration 254, loss = 1.13906133\n",
      "Training set score: 0.689914\n",
      "Test set score: 0.301100\n",
      "\n",
      "Iteration 255, loss = 1.13844291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.690183\n",
      "Test set score: 0.301266\n",
      "\n",
      "Iteration 256, loss = 1.13806129\n",
      "Training set score: 0.690307\n",
      "Test set score: 0.300823\n",
      "\n",
      "Iteration 257, loss = 1.13756260\n",
      "Training set score: 0.690205\n",
      "Test set score: 0.300490\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 258, loss = 1.13708628\n",
      "Training set score: 0.690780\n",
      "Test set score: 0.301155\n",
      "\n",
      "Iteration 259, loss = 1.13665299\n",
      "Training set score: 0.690750\n",
      "Test set score: 0.300740\n",
      "\n",
      "Iteration 260, loss = 1.13610389\n",
      "Training set score: 0.690932\n",
      "Test set score: 0.300407\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 261, loss = 1.13563784\n",
      "Training set score: 0.690867\n",
      "Test set score: 0.301045\n",
      "\n",
      "Iteration 262, loss = 1.13532288\n",
      "Training set score: 0.690743\n",
      "Test set score: 0.301072\n",
      "\n",
      "Iteration 263, loss = 1.13474850\n",
      "Training set score: 0.690801\n",
      "Test set score: 0.300352\n",
      "\n",
      "Iteration 264, loss = 1.13436235\n",
      "Training set score: 0.690910\n",
      "Test set score: 0.300906\n",
      "\n",
      "Iteration 265, loss = 1.13394653\n",
      "Training set score: 0.690801\n",
      "Test set score: 0.300795\n",
      "\n",
      "Iteration 266, loss = 1.13349106\n",
      "Training set score: 0.691187\n",
      "Test set score: 0.300380\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 267, loss = 1.13296113\n",
      "Training set score: 0.691238\n",
      "Test set score: 0.300352\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 268, loss = 1.13256244\n",
      "Training set score: 0.690910\n",
      "Test set score: 0.300657\n",
      "\n",
      "Iteration 269, loss = 1.13222753\n",
      "Training set score: 0.691129\n",
      "Test set score: 0.300518\n",
      "\n",
      "Iteration 270, loss = 1.13172707\n",
      "Training set score: 0.691347\n",
      "Test set score: 0.300241\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 271, loss = 1.13128322\n",
      "Training set score: 0.691434\n",
      "Test set score: 0.300795\n",
      "\n",
      "Iteration 272, loss = 1.13096926\n",
      "Training set score: 0.691492\n",
      "Test set score: 0.300490\n",
      "\n",
      "Iteration 273, loss = 1.13052452\n",
      "Training set score: 0.691558\n",
      "Test set score: 0.300629\n",
      "\n",
      "Iteration 274, loss = 1.13006162\n",
      "Training set score: 0.691805\n",
      "Test set score: 0.300241\n",
      "\n",
      "Iteration 275, loss = 1.12971740\n",
      "Training set score: 0.691768\n",
      "Test set score: 0.301155\n",
      "\n",
      "Iteration 276, loss = 1.12936175\n",
      "Training set score: 0.691623\n",
      "Test set score: 0.300296\n",
      "\n",
      "Iteration 277, loss = 1.12903506\n",
      "Training set score: 0.692045\n",
      "Test set score: 0.300186\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 278, loss = 1.12848058\n",
      "Training set score: 0.692038\n",
      "Test set score: 0.300712\n",
      "\n",
      "Iteration 279, loss = 1.12816313\n",
      "Training set score: 0.692008\n",
      "Test set score: 0.300075\n",
      "\n",
      "Iteration 280, loss = 1.12781424\n",
      "Training set score: 0.692227\n",
      "Test set score: 0.300407\n",
      "\n",
      "Iteration 281, loss = 1.12739503\n",
      "Training set score: 0.692038\n",
      "Test set score: 0.300601\n",
      "\n",
      "Iteration 282, loss = 1.12705065\n",
      "Training set score: 0.692321\n",
      "Test set score: 0.300463\n",
      "\n",
      "Iteration 283, loss = 1.12669101\n",
      "Training set score: 0.692277\n",
      "Test set score: 0.300490\n",
      "\n",
      "Iteration 284, loss = 1.12631136\n",
      "Training set score: 0.692474\n",
      "Test set score: 0.300075\n",
      "\n",
      "Iteration 285, loss = 1.12599798\n",
      "Training set score: 0.692605\n",
      "Test set score: 0.300269\n",
      "\n",
      "Iteration 286, loss = 1.12561215\n",
      "Training set score: 0.692525\n",
      "Test set score: 0.300047\n",
      "\n",
      "Iteration 287, loss = 1.12524474\n",
      "Training set score: 0.692554\n",
      "Test set score: 0.300380\n",
      "\n",
      "Iteration 288, loss = 1.12482431\n",
      "Training set score: 0.692750\n",
      "Test set score: 0.299853\n",
      "\n",
      "Iteration 289, loss = 1.12452835\n",
      "Training set score: 0.692852\n",
      "Test set score: 0.300130\n",
      "\n",
      "Iteration 290, loss = 1.12410227\n",
      "Training set score: 0.692765\n",
      "Test set score: 0.300269\n",
      "\n",
      "Iteration 291, loss = 1.12378874\n",
      "Training set score: 0.693237\n",
      "Test set score: 0.300130\n",
      "\n",
      "Iteration 292, loss = 1.12348600\n",
      "Training set score: 0.693150\n",
      "Test set score: 0.300407\n",
      "\n",
      "Iteration 293, loss = 1.12307010\n",
      "Training set score: 0.693310\n",
      "Test set score: 0.300269\n",
      "\n",
      "Iteration 294, loss = 1.12273259\n",
      "Training set score: 0.693303\n",
      "Test set score: 0.299909\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 295, loss = 1.12237210\n",
      "Training set score: 0.693477\n",
      "Test set score: 0.300518\n",
      "\n",
      "Iteration 296, loss = 1.12217836\n",
      "Training set score: 0.693535\n",
      "Test set score: 0.300574\n",
      "\n",
      "Iteration 297, loss = 1.12175588\n",
      "Training set score: 0.693346\n",
      "Test set score: 0.299964\n",
      "\n",
      "Iteration 298, loss = 1.12128692\n",
      "Training set score: 0.693550\n",
      "Test set score: 0.300047\n",
      "\n",
      "Iteration 299, loss = 1.12105177\n",
      "Training set score: 0.693405\n",
      "Test set score: 0.300158\n",
      "\n",
      "Iteration 300, loss = 1.12080271\n",
      "Training set score: 0.693586\n",
      "Test set score: 0.300324\n",
      "\n",
      "Iteration 301, loss = 1.12040839\n",
      "Training set score: 0.694059\n",
      "Test set score: 0.300075\n",
      "\n",
      "Iteration 302, loss = 1.12010023\n",
      "Training set score: 0.694015\n",
      "Test set score: 0.300158\n",
      "\n",
      "Iteration 303, loss = 1.11977809\n",
      "Training set score: 0.693943\n",
      "Test set score: 0.299798\n",
      "\n",
      "Iteration 304, loss = 1.11942020\n",
      "Training set score: 0.694175\n",
      "Test set score: 0.300103\n",
      "\n",
      "Iteration 305, loss = 1.11907017\n",
      "Training set score: 0.694168\n",
      "Test set score: 0.299604\n",
      "\n",
      "Iteration 306, loss = 1.11879292\n",
      "Training set score: 0.694481\n",
      "Test set score: 0.299909\n",
      "\n",
      "Iteration 307, loss = 1.11851642\n",
      "Training set score: 0.694132\n",
      "Test set score: 0.299798\n",
      "\n",
      "Iteration 308, loss = 1.11825896\n",
      "Training set score: 0.694277\n",
      "Test set score: 0.299715\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 309, loss = 1.11781876\n",
      "Training set score: 0.694604\n",
      "Test set score: 0.299715\n",
      "\n",
      "Iteration 310, loss = 1.11753261\n",
      "Training set score: 0.694524\n",
      "Test set score: 0.299465\n",
      "\n",
      "Iteration 311, loss = 1.11732978\n",
      "Training set score: 0.694728\n",
      "Test set score: 0.299382\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 312, loss = 1.11692110\n",
      "Training set score: 0.694757\n",
      "Test set score: 0.299465\n",
      "\n",
      "Iteration 313, loss = 1.11668582\n",
      "Training set score: 0.694823\n",
      "Test set score: 0.299327\n",
      "\n",
      "Iteration 314, loss = 1.11631630\n",
      "Training set score: 0.694408\n",
      "Test set score: 0.299244\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 315, loss = 1.11607640\n",
      "Training set score: 0.694903\n",
      "Test set score: 0.299964\n",
      "\n",
      "Iteration 316, loss = 1.11584178\n",
      "Training set score: 0.694837\n",
      "Test set score: 0.299133\n",
      "\n",
      "Iteration 317, loss = 1.11541361\n",
      "Training set score: 0.695063\n",
      "Test set score: 0.299493\n",
      "\n",
      "Iteration 318, loss = 1.11519244\n",
      "Training set score: 0.695033\n",
      "Test set score: 0.299548\n",
      "\n",
      "Iteration 319, loss = 1.11486349\n",
      "Training set score: 0.695193\n",
      "Test set score: 0.299105\n",
      "\n",
      "Iteration 320, loss = 1.11468504\n",
      "Training set score: 0.695339\n",
      "Test set score: 0.298967\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 321, loss = 1.11426063\n",
      "Training set score: 0.695724\n",
      "Test set score: 0.299022\n",
      "\n",
      "Iteration 322, loss = 1.11410569\n",
      "Training set score: 0.695462\n",
      "Test set score: 0.298883\n",
      "\n",
      "Iteration 323, loss = 1.11375737\n",
      "Training set score: 0.695455\n",
      "Test set score: 0.298883\n",
      "\n",
      "Iteration 324, loss = 1.11345258\n",
      "Training set score: 0.695862\n",
      "Test set score: 0.298856\n",
      "\n",
      "Iteration 325, loss = 1.11311738\n",
      "Training set score: 0.695848\n",
      "Test set score: 0.299160\n",
      "\n",
      "Iteration 326, loss = 1.11289863\n",
      "Training set score: 0.695819\n",
      "Test set score: 0.298745\n",
      "\n",
      "Iteration 327, loss = 1.11264170\n",
      "Training set score: 0.695804\n",
      "Test set score: 0.298939\n",
      "\n",
      "Iteration 328, loss = 1.11238724\n",
      "Training set score: 0.695804\n",
      "Test set score: 0.298302\n",
      "\n",
      "Iteration 329, loss = 1.11214041\n",
      "Training set score: 0.696175\n",
      "Test set score: 0.298551\n",
      "\n",
      "Iteration 330, loss = 1.11180358\n",
      "Training set score: 0.696444\n",
      "Test set score: 0.298579\n",
      "\n",
      "Iteration 331, loss = 1.11151128\n",
      "Training set score: 0.695695\n",
      "Test set score: 0.298218\n",
      "\n",
      "Iteration 332, loss = 1.11132860\n",
      "Training set score: 0.696241\n",
      "Test set score: 0.298440\n",
      "\n",
      "Iteration 333, loss = 1.11097903\n",
      "Training set score: 0.695993\n",
      "Test set score: 0.298329\n",
      "\n",
      "Iteration 334, loss = 1.11077048\n",
      "Training set score: 0.695892\n",
      "Test set score: 0.298523\n",
      "\n",
      "Iteration 335, loss = 1.11049044\n",
      "Training set score: 0.696095\n",
      "Test set score: 0.298828\n",
      "\n",
      "Iteration 336, loss = 1.11018920\n",
      "Training set score: 0.696546\n",
      "Test set score: 0.298994\n",
      "\n",
      "Iteration 337, loss = 1.10989423\n",
      "Training set score: 0.696539\n",
      "Test set score: 0.299022\n",
      "\n",
      "Iteration 338, loss = 1.10963939\n",
      "Training set score: 0.696255\n",
      "Test set score: 0.298606\n",
      "\n",
      "Iteration 339, loss = 1.10936580\n",
      "Training set score: 0.696466\n",
      "Test set score: 0.298662\n",
      "\n",
      "Iteration 340, loss = 1.10910525\n",
      "Training set score: 0.696597\n",
      "Test set score: 0.298689\n",
      "\n",
      "Iteration 341, loss = 1.10885761\n",
      "Training set score: 0.696611\n",
      "Test set score: 0.298717\n",
      "\n",
      "Iteration 342, loss = 1.10872743\n",
      "Training set score: 0.696451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.299160\n",
      "\n",
      "Iteration 343, loss = 1.10834820\n",
      "Training set score: 0.696851\n",
      "Test set score: 0.298911\n",
      "\n",
      "Iteration 344, loss = 1.10808281\n",
      "Training set score: 0.696546\n",
      "Test set score: 0.298606\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 345, loss = 1.10791302\n",
      "Training set score: 0.696633\n",
      "Test set score: 0.298385\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 346, loss = 1.10760707\n",
      "Training set score: 0.696568\n",
      "Test set score: 0.298689\n",
      "\n",
      "Iteration 347, loss = 1.10732282\n",
      "Training set score: 0.696655\n",
      "Test set score: 0.298717\n",
      "\n",
      "Iteration 348, loss = 1.10717470\n",
      "Training set score: 0.696859\n",
      "Test set score: 0.298939\n",
      "\n",
      "Iteration 349, loss = 1.10685119\n",
      "Training set score: 0.697048\n",
      "Test set score: 0.298911\n",
      "\n",
      "Iteration 350, loss = 1.10659417\n",
      "Training set score: 0.696873\n",
      "Test set score: 0.298495\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 351, loss = 1.10640795\n",
      "Training set score: 0.697055\n",
      "Test set score: 0.298606\n",
      "\n",
      "Iteration 352, loss = 1.10620190\n",
      "Training set score: 0.697004\n",
      "Test set score: 0.298440\n",
      "\n",
      "Iteration 353, loss = 1.10590131\n",
      "Training set score: 0.697040\n",
      "Test set score: 0.298911\n",
      "\n",
      "Iteration 354, loss = 1.10568639\n",
      "Training set score: 0.697106\n",
      "Test set score: 0.298440\n",
      "\n",
      "Iteration 355, loss = 1.10540767\n",
      "Training set score: 0.696786\n",
      "Test set score: 0.298634\n",
      "\n",
      "Iteration 356, loss = 1.10524497\n",
      "Training set score: 0.697215\n",
      "Test set score: 0.298468\n",
      "\n",
      "Iteration 357, loss = 1.10494207\n",
      "Training set score: 0.697535\n",
      "Test set score: 0.298939\n",
      "\n",
      "Iteration 358, loss = 1.10462404\n",
      "Training set score: 0.697157\n",
      "Test set score: 0.297969\n",
      "\n",
      "Iteration 359, loss = 1.10438089\n",
      "Training set score: 0.697360\n",
      "Test set score: 0.298662\n",
      "\n",
      "Iteration 360, loss = 1.10423109\n",
      "Training set score: 0.697731\n",
      "Test set score: 0.298163\n",
      "\n",
      "Iteration 361, loss = 1.10406082\n",
      "Training set score: 0.697644\n",
      "Test set score: 0.298662\n",
      "\n",
      "Iteration 362, loss = 1.10380506\n",
      "Training set score: 0.697368\n",
      "Test set score: 0.298218\n",
      "\n",
      "Iteration 363, loss = 1.10352395\n",
      "Training set score: 0.697557\n",
      "Test set score: 0.298662\n",
      "\n",
      "Iteration 364, loss = 1.10345395\n",
      "Training set score: 0.697768\n",
      "Test set score: 0.298357\n",
      "\n",
      "Iteration 365, loss = 1.10297639\n",
      "Training set score: 0.697506\n",
      "Test set score: 0.298606\n",
      "\n",
      "Iteration 366, loss = 1.10286637\n",
      "Training set score: 0.697593\n",
      "Test set score: 0.298800\n",
      "\n",
      "Iteration 367, loss = 1.10256730\n",
      "Training set score: 0.697753\n",
      "Test set score: 0.298302\n",
      "\n",
      "Iteration 368, loss = 1.10242478\n",
      "Training set score: 0.698088\n",
      "Test set score: 0.298745\n",
      "\n",
      "Iteration 369, loss = 1.10209245\n",
      "Training set score: 0.698066\n",
      "Test set score: 0.297969\n",
      "\n",
      "Iteration 370, loss = 1.10205106\n",
      "Training set score: 0.697978\n",
      "Test set score: 0.297914\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 371, loss = 1.10175237\n",
      "Training set score: 0.698073\n",
      "Test set score: 0.298246\n",
      "\n",
      "Iteration 372, loss = 1.10151446\n",
      "Training set score: 0.698233\n",
      "Test set score: 0.298080\n",
      "\n",
      "Iteration 373, loss = 1.10119107\n",
      "Training set score: 0.698255\n",
      "Test set score: 0.298052\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 374, loss = 1.10107106\n",
      "Training set score: 0.698633\n",
      "Test set score: 0.297941\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 375, loss = 1.10084793\n",
      "Training set score: 0.698262\n",
      "Test set score: 0.298163\n",
      "\n",
      "Iteration 376, loss = 1.10061209\n",
      "Training set score: 0.698466\n",
      "Test set score: 0.298108\n",
      "\n",
      "Iteration 377, loss = 1.10035774\n",
      "Training set score: 0.698284\n",
      "Test set score: 0.297997\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 378, loss = 1.10018973\n",
      "Training set score: 0.698618\n",
      "Test set score: 0.298024\n",
      "\n",
      "Iteration 379, loss = 1.09987130\n",
      "Training set score: 0.698124\n",
      "Test set score: 0.297498\n",
      "\n",
      "Iteration 380, loss = 1.09970944\n",
      "Training set score: 0.698342\n",
      "Test set score: 0.298191\n",
      "\n",
      "Iteration 381, loss = 1.09939073\n",
      "Training set score: 0.698626\n",
      "Test set score: 0.297720\n",
      "\n",
      "Iteration 382, loss = 1.09937182\n",
      "Training set score: 0.698684\n",
      "Test set score: 0.298080\n",
      "\n",
      "Iteration 383, loss = 1.09900868\n",
      "Training set score: 0.698553\n",
      "Test set score: 0.297664\n",
      "\n",
      "Iteration 384, loss = 1.09880242\n",
      "Training set score: 0.698727\n",
      "Test set score: 0.297969\n",
      "\n",
      "Iteration 385, loss = 1.09853245\n",
      "Training set score: 0.698575\n",
      "Test set score: 0.297997\n",
      "\n",
      "Iteration 386, loss = 1.09845911\n",
      "Training set score: 0.698837\n",
      "Test set score: 0.297997\n",
      "\n",
      "Iteration 387, loss = 1.09802417\n",
      "Training set score: 0.698880\n",
      "Test set score: 0.298080\n",
      "\n",
      "Iteration 388, loss = 1.09794123\n",
      "Training set score: 0.698800\n",
      "Test set score: 0.297941\n",
      "\n",
      "Iteration 389, loss = 1.09766740\n",
      "Training set score: 0.698807\n",
      "Test set score: 0.298108\n",
      "\n",
      "Iteration 390, loss = 1.09744165\n",
      "Training set score: 0.699033\n",
      "Test set score: 0.297470\n",
      "\n",
      "Iteration 391, loss = 1.09729155\n",
      "Training set score: 0.698517\n",
      "Test set score: 0.297692\n",
      "\n",
      "Iteration 392, loss = 1.09706756\n",
      "Training set score: 0.698800\n",
      "Test set score: 0.297997\n",
      "\n",
      "Iteration 393, loss = 1.09687058\n",
      "Training set score: 0.698887\n",
      "Test set score: 0.297914\n",
      "\n",
      "Iteration 394, loss = 1.09663003\n",
      "Training set score: 0.699127\n",
      "Test set score: 0.297747\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 395, loss = 1.09648764\n",
      "Training set score: 0.699338\n",
      "Test set score: 0.298108\n",
      "\n",
      "Iteration 396, loss = 1.09616421\n",
      "Training set score: 0.698837\n",
      "Test set score: 0.297830\n",
      "\n",
      "Iteration 397, loss = 1.09602446\n",
      "Training set score: 0.698837\n",
      "Test set score: 0.297747\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 398, loss = 1.09573891\n",
      "Training set score: 0.699062\n",
      "Test set score: 0.298108\n",
      "\n",
      "Iteration 399, loss = 1.09565097\n",
      "Training set score: 0.699186\n",
      "Test set score: 0.297914\n",
      "\n",
      "Iteration 400, loss = 1.09535421\n",
      "Training set score: 0.699789\n",
      "Test set score: 0.298163\n",
      "\n",
      "Iteration 401, loss = 1.09519366\n",
      "Training set score: 0.699447\n",
      "Test set score: 0.298135\n",
      "\n",
      "Iteration 402, loss = 1.09504003\n",
      "Training set score: 0.699396\n",
      "Test set score: 0.297858\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 403, loss = 1.09479034\n",
      "Training set score: 0.699287\n",
      "Test set score: 0.297775\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 404, loss = 1.09462118\n",
      "Training set score: 0.699833\n",
      "Test set score: 0.297997\n",
      "\n",
      "Iteration 405, loss = 1.09444034\n",
      "Training set score: 0.699833\n",
      "Test set score: 0.298163\n",
      "\n",
      "Iteration 406, loss = 1.09420931\n",
      "Training set score: 0.699796\n",
      "Test set score: 0.297498\n",
      "\n",
      "Iteration 407, loss = 1.09397331\n",
      "Training set score: 0.699658\n",
      "Test set score: 0.297775\n",
      "\n",
      "Iteration 408, loss = 1.09378830\n",
      "Training set score: 0.699535\n",
      "Test set score: 0.297664\n",
      "\n",
      "Iteration 409, loss = 1.09349467\n",
      "Training set score: 0.699673\n",
      "Test set score: 0.297443\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 410, loss = 1.09339819\n",
      "Training set score: 0.699789\n",
      "Test set score: 0.297775\n",
      "\n",
      "Iteration 411, loss = 1.09318079\n",
      "Training set score: 0.699593\n",
      "Test set score: 0.297609\n",
      "\n",
      "Iteration 412, loss = 1.09294578\n",
      "Training set score: 0.699905\n",
      "Test set score: 0.298108\n",
      "\n",
      "Iteration 413, loss = 1.09268708\n",
      "Training set score: 0.700124\n",
      "Test set score: 0.297249\n",
      "\n",
      "Iteration 414, loss = 1.09261828\n",
      "Training set score: 0.700160\n",
      "Test set score: 0.297332\n",
      "\n",
      "Iteration 415, loss = 1.09233655\n",
      "Training set score: 0.700022\n",
      "Test set score: 0.297498\n",
      "\n",
      "Iteration 416, loss = 1.09222435\n",
      "Training set score: 0.699993\n",
      "Test set score: 0.297637\n",
      "\n",
      "Iteration 417, loss = 1.09193808\n",
      "Training set score: 0.700109\n",
      "Test set score: 0.297914\n",
      "\n",
      "Iteration 418, loss = 1.09180478\n",
      "Training set score: 0.700036\n",
      "Test set score: 0.297470\n",
      "\n",
      "Iteration 419, loss = 1.09160837\n",
      "Training set score: 0.700211\n",
      "Test set score: 0.297443\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 420, loss = 1.09142471\n",
      "Training set score: 0.700262\n",
      "Test set score: 0.297332\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 421, loss = 1.09116527\n",
      "Training set score: 0.700233\n",
      "Test set score: 0.297609\n",
      "\n",
      "Iteration 422, loss = 1.09102063\n",
      "Training set score: 0.700298\n",
      "Test set score: 0.297664\n",
      "\n",
      "Iteration 423, loss = 1.09080622\n",
      "Training set score: 0.700342\n",
      "Test set score: 0.297415\n",
      "\n",
      "Iteration 424, loss = 1.09065560\n",
      "Training set score: 0.699971\n",
      "Test set score: 0.297304\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 425, loss = 1.09055651\n",
      "Training set score: 0.700225\n",
      "Test set score: 0.297359\n",
      "\n",
      "Iteration 426, loss = 1.09018605\n",
      "Training set score: 0.700334\n",
      "Test set score: 0.297858\n",
      "\n",
      "Iteration 427, loss = 1.09014706\n",
      "Training set score: 0.700291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.297692\n",
      "\n",
      "Iteration 428, loss = 1.08990139\n",
      "Training set score: 0.700298\n",
      "Test set score: 0.297553\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 429, loss = 1.08973039\n",
      "Training set score: 0.700313\n",
      "Test set score: 0.297387\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 430, loss = 1.08955558\n",
      "Training set score: 0.700465\n",
      "Test set score: 0.297941\n",
      "\n",
      "Iteration 431, loss = 1.08946456\n",
      "Training set score: 0.700349\n",
      "Test set score: 0.297747\n",
      "\n",
      "Iteration 432, loss = 1.08925281\n",
      "Training set score: 0.700429\n",
      "Test set score: 0.297720\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 433, loss = 1.08899214\n",
      "Training set score: 0.700262\n",
      "Test set score: 0.297858\n",
      "\n",
      "Iteration 434, loss = 1.08876771\n",
      "Training set score: 0.700545\n",
      "Test set score: 0.297470\n",
      "\n",
      "Iteration 435, loss = 1.08859822\n",
      "Training set score: 0.700095\n",
      "Test set score: 0.297609\n",
      "\n",
      "Iteration 436, loss = 1.08858665\n",
      "Training set score: 0.700604\n",
      "Test set score: 0.297221\n",
      "\n",
      "Iteration 437, loss = 1.08827456\n",
      "Training set score: 0.700320\n",
      "Test set score: 0.297193\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 438, loss = 1.08812369\n",
      "Training set score: 0.700509\n",
      "Test set score: 0.297443\n",
      "\n",
      "Iteration 439, loss = 1.08790079\n",
      "Training set score: 0.700684\n",
      "Test set score: 0.297526\n",
      "\n",
      "Iteration 440, loss = 1.08780543\n",
      "Training set score: 0.700756\n",
      "Test set score: 0.297526\n",
      "\n",
      "Iteration 441, loss = 1.08760844\n",
      "Training set score: 0.700429\n",
      "Test set score: 0.297526\n",
      "\n",
      "Iteration 442, loss = 1.08734893\n",
      "Training set score: 0.700742\n",
      "Test set score: 0.297775\n",
      "\n",
      "Iteration 443, loss = 1.08722246\n",
      "Training set score: 0.700771\n",
      "Test set score: 0.297553\n",
      "\n",
      "Iteration 444, loss = 1.08711393\n",
      "Training set score: 0.700771\n",
      "Test set score: 0.297387\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 445, loss = 1.08685320\n",
      "Training set score: 0.700553\n",
      "Test set score: 0.297664\n",
      "\n",
      "Iteration 446, loss = 1.08674869\n",
      "Training set score: 0.700887\n",
      "Test set score: 0.297470\n",
      "\n",
      "Iteration 447, loss = 1.08662254\n",
      "Training set score: 0.700858\n",
      "Test set score: 0.297553\n",
      "\n",
      "Iteration 448, loss = 1.08646683\n",
      "Training set score: 0.700771\n",
      "Test set score: 0.297941\n",
      "\n",
      "Iteration 449, loss = 1.08623793\n",
      "Training set score: 0.701040\n",
      "Test set score: 0.297720\n",
      "\n",
      "Iteration 450, loss = 1.08613333\n",
      "Training set score: 0.700800\n",
      "Test set score: 0.297553\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 451, loss = 1.08598620\n",
      "Training set score: 0.701156\n",
      "Test set score: 0.297914\n",
      "\n",
      "Iteration 452, loss = 1.08575523\n",
      "Training set score: 0.700814\n",
      "Test set score: 0.297470\n",
      "\n",
      "Iteration 453, loss = 1.08566804\n",
      "Training set score: 0.701134\n",
      "Test set score: 0.297858\n",
      "\n",
      "Iteration 454, loss = 1.08538938\n",
      "Training set score: 0.701091\n",
      "Test set score: 0.297941\n",
      "\n",
      "Iteration 455, loss = 1.08536784\n",
      "Training set score: 0.700836\n",
      "Test set score: 0.297969\n",
      "\n",
      "Iteration 456, loss = 1.08504728\n",
      "Training set score: 0.701243\n",
      "Test set score: 0.297637\n",
      "\n",
      "Iteration 457, loss = 1.08484515\n",
      "Training set score: 0.701149\n",
      "Test set score: 0.298052\n",
      "\n",
      "Iteration 458, loss = 1.08487107\n",
      "Training set score: 0.701411\n",
      "Test set score: 0.298218\n",
      "\n",
      "Iteration 459, loss = 1.08462315\n",
      "Training set score: 0.701200\n",
      "Test set score: 0.297553\n",
      "\n",
      "Iteration 460, loss = 1.08433621\n",
      "Training set score: 0.701403\n",
      "Test set score: 0.297664\n",
      "\n",
      "Iteration 461, loss = 1.08433344\n",
      "Training set score: 0.701251\n",
      "Test set score: 0.297415\n",
      "\n",
      "Iteration 462, loss = 1.08418423\n",
      "Training set score: 0.701767\n",
      "Test set score: 0.297609\n",
      "\n",
      "Iteration 463, loss = 1.08403004\n",
      "Training set score: 0.701251\n",
      "Test set score: 0.297858\n",
      "\n",
      "Iteration 464, loss = 1.08375986\n",
      "Training set score: 0.701811\n",
      "Test set score: 0.297609\n",
      "\n",
      "Iteration 465, loss = 1.08362147\n",
      "Training set score: 0.701331\n",
      "Test set score: 0.297581\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 466, loss = 1.08348374\n",
      "Training set score: 0.701513\n",
      "Test set score: 0.298024\n",
      "\n",
      "Iteration 467, loss = 1.08334506\n",
      "Training set score: 0.701622\n",
      "Test set score: 0.297498\n",
      "\n",
      "Iteration 468, loss = 1.08317844\n",
      "Training set score: 0.701258\n",
      "Test set score: 0.297720\n",
      "\n",
      "Iteration 469, loss = 1.08298595\n",
      "Training set score: 0.701643\n",
      "Test set score: 0.297720\n",
      "\n",
      "Iteration 470, loss = 1.08276293\n",
      "Training set score: 0.701905\n",
      "Test set score: 0.297276\n",
      "\n",
      "Iteration 471, loss = 1.08267370\n",
      "Training set score: 0.701433\n",
      "Test set score: 0.297664\n",
      "\n",
      "Iteration 472, loss = 1.08245920\n",
      "Training set score: 0.701818\n",
      "Test set score: 0.297221\n",
      "\n",
      "Iteration 473, loss = 1.08237285\n",
      "Training set score: 0.701527\n",
      "Test set score: 0.297415\n",
      "\n",
      "Iteration 474, loss = 1.08227751\n",
      "Training set score: 0.701760\n",
      "Test set score: 0.297027\n",
      "\n",
      "Iteration 475, loss = 1.08201746\n",
      "Training set score: 0.701985\n",
      "Test set score: 0.297526\n",
      "\n",
      "Iteration 476, loss = 1.08202091\n",
      "Training set score: 0.702102\n",
      "Test set score: 0.297359\n",
      "\n",
      "Iteration 477, loss = 1.08176779\n",
      "Training set score: 0.701840\n",
      "Test set score: 0.297249\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 478, loss = 1.08165586\n",
      "Training set score: 0.702269\n",
      "Test set score: 0.297415\n",
      "\n",
      "Iteration 479, loss = 1.08144130\n",
      "Training set score: 0.701912\n",
      "Test set score: 0.297221\n",
      "\n",
      "Iteration 480, loss = 1.08123842\n",
      "Training set score: 0.701891\n",
      "Test set score: 0.297249\n",
      "\n",
      "Iteration 481, loss = 1.08104496\n",
      "Training set score: 0.702349\n",
      "Test set score: 0.297027\n",
      "\n",
      "Iteration 482, loss = 1.08095970\n",
      "Training set score: 0.702065\n",
      "Test set score: 0.297637\n",
      "\n",
      "Iteration 483, loss = 1.08084545\n",
      "Training set score: 0.701796\n",
      "Test set score: 0.297138\n",
      "\n",
      "Iteration 484, loss = 1.08059513\n",
      "Training set score: 0.701963\n",
      "Test set score: 0.296778\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 485, loss = 1.08044371\n",
      "Training set score: 0.702349\n",
      "Test set score: 0.296833\n",
      "\n",
      "Iteration 486, loss = 1.08034480\n",
      "Training set score: 0.702240\n",
      "Test set score: 0.297221\n",
      "\n",
      "Iteration 487, loss = 1.08021521\n",
      "Training set score: 0.701985\n",
      "Test set score: 0.297249\n",
      "\n",
      "Iteration 488, loss = 1.08002676\n",
      "Training set score: 0.702640\n",
      "Test set score: 0.297110\n",
      "\n",
      "Iteration 489, loss = 1.07992120\n",
      "Training set score: 0.702501\n",
      "Test set score: 0.297193\n",
      "\n",
      "Iteration 490, loss = 1.07975945\n",
      "Training set score: 0.702203\n",
      "Test set score: 0.297082\n",
      "\n",
      "Iteration 491, loss = 1.07950346\n",
      "Training set score: 0.702189\n",
      "Test set score: 0.297249\n",
      "\n",
      "Iteration 492, loss = 1.07944251\n",
      "Training set score: 0.702756\n",
      "Test set score: 0.296972\n",
      "\n",
      "Iteration 493, loss = 1.07932630\n",
      "Training set score: 0.702174\n",
      "Test set score: 0.297553\n",
      "\n",
      "Iteration 494, loss = 1.07925261\n",
      "Training set score: 0.702407\n",
      "Test set score: 0.297165\n",
      "\n",
      "Iteration 495, loss = 1.07895814\n",
      "Training set score: 0.702632\n",
      "Test set score: 0.297110\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 496, loss = 1.07896027\n",
      "Training set score: 0.701985\n",
      "Test set score: 0.297110\n",
      "\n",
      "Iteration 497, loss = 1.07873987\n",
      "Training set score: 0.702429\n",
      "Test set score: 0.297581\n",
      "\n",
      "Iteration 498, loss = 1.07861391\n",
      "Training set score: 0.702661\n",
      "Test set score: 0.297359\n",
      "\n",
      "Iteration 499, loss = 1.07842744\n",
      "Training set score: 0.702371\n",
      "Test set score: 0.297304\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 500, loss = 1.07831705\n",
      "Training set score: 0.702429\n",
      "Test set score: 0.297609\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "# mlp = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=400, alpha=1e-4,\n",
    "#                     solver='sgd', verbose=10, tol=1e-4, random_state=1)\n",
    "mlp4 = MLPClassifier(hidden_layer_sizes=(200,), max_iter=1, alpha=1e-4,\n",
    "                    solver='sgd', verbose=10, tol=1e-4, random_state=1,\n",
    "                    learning_rate_init=.05, learning_rate='adaptive',\n",
    "                    warm_start=True)\n",
    "test_scores = []\n",
    "for i in range(500):\n",
    "    mlp4.fit(X_train, Y_train)\n",
    "    print(\"Training set score: %f\" % mlp4.score(X_train, Y_train))\n",
    "    sc = mlp4.score(X_test, Y_test)\n",
    "    print(\"Test set score: %f\" % sc)\n",
    "    print()\n",
    "    test_scores.append(sc)\n",
    "    if i>2 and test_scores[i] < test_scores[i-1] and test_scores[i-1] < test_scores[i-2]:\n",
    "        print('Test scores decreased in last 2 iter. Stopping.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.873536299766\n",
      "maxlen 496\n"
     ]
    }
   ],
   "source": [
    "# segment acc\n",
    "from scipy import stats\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "# test\n",
    "maxlen = 0\n",
    "for speaker_id, feature_list in test.items():\n",
    "    speaker_id = idx[speaker_id]\n",
    "    for features in feature_list:\n",
    "        maxlen = max(maxlen, features.shape[1])\n",
    "        x = []\n",
    "        # y = []\n",
    "        frames = concat(features)\n",
    "        for frame in frames:\n",
    "            x.append(frame)\n",
    "            # y.append(speaker_id)\n",
    "        x = scaler.transform(x)\n",
    "        pred = stats.mode(mlp4.predict(x)).mode[0]\n",
    "        y_true.append(speaker_id)\n",
    "        y_pred.append(pred)\n",
    "print(sum(np.array(y_true) == np.array(y_pred))/len(y_true))\n",
    "print('maxlen', maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.975\n",
      "maxlen 496\n"
     ]
    }
   ],
   "source": [
    "# all segment acc ~ file\n",
    "from scipy import stats\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "# test\n",
    "maxlen = 0\n",
    "for speaker_id, feature_list in test.items():\n",
    "    speaker_id = idx[speaker_id]\n",
    "    x = []\n",
    "    for features in feature_list:\n",
    "        maxlen = max(maxlen, features.shape[1])\n",
    "        # y = []\n",
    "        frames = concat(features)\n",
    "        for frame in frames:\n",
    "            x.append(frame)\n",
    "            # y.append(speaker_id)\n",
    "    x = scaler.transform(x)\n",
    "    pred = stats.mode(mlp4.predict(x)).mode[0]\n",
    "    y_true.append(speaker_id)\n",
    "    y_pred.append(pred)\n",
    "print(sum(np.array(y_true) == np.array(y_pred))/len(y_true))\n",
    "print('maxlen', maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 4.71730816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pratik varshney\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.130352\n",
      "Test set score: 0.109612\n",
      "\n",
      "Iteration 2, loss = 3.78554140\n",
      "Training set score: 0.205250\n",
      "Test set score: 0.168712\n",
      "\n",
      "Iteration 3, loss = 3.39037691\n",
      "Training set score: 0.253192\n",
      "Test set score: 0.202848\n",
      "\n",
      "Iteration 4, loss = 3.13886473\n",
      "Training set score: 0.290569\n",
      "Test set score: 0.225790\n",
      "\n",
      "Iteration 5, loss = 2.95409596\n",
      "Training set score: 0.321044\n",
      "Test set score: 0.242554\n",
      "\n",
      "Iteration 6, loss = 2.80999414\n",
      "Training set score: 0.346757\n",
      "Test set score: 0.255715\n",
      "\n",
      "Iteration 7, loss = 2.69293682\n",
      "Training set score: 0.368383\n",
      "Test set score: 0.266521\n",
      "\n",
      "Iteration 8, loss = 2.59522851\n",
      "Training set score: 0.386075\n",
      "Test set score: 0.273392\n",
      "\n",
      "Iteration 9, loss = 2.51236000\n",
      "Training set score: 0.401956\n",
      "Test set score: 0.279931\n",
      "\n",
      "Iteration 10, loss = 2.44121720\n",
      "Training set score: 0.415525\n",
      "Test set score: 0.284448\n",
      "\n",
      "Iteration 11, loss = 2.37957712\n",
      "Training set score: 0.427269\n",
      "Test set score: 0.286775\n",
      "\n",
      "Iteration 12, loss = 2.32524093\n",
      "Training set score: 0.438067\n",
      "Test set score: 0.290349\n",
      "\n",
      "Iteration 13, loss = 2.27695508\n",
      "Training set score: 0.447259\n",
      "Test set score: 0.292400\n",
      "\n",
      "Iteration 14, loss = 2.23352016\n",
      "Training set score: 0.455403\n",
      "Test set score: 0.295642\n",
      "\n",
      "Iteration 15, loss = 2.19452078\n",
      "Training set score: 0.463300\n",
      "Test set score: 0.299299\n",
      "\n",
      "Iteration 16, loss = 2.15903134\n",
      "Training set score: 0.470870\n",
      "Test set score: 0.300546\n",
      "\n",
      "Iteration 17, loss = 2.12676513\n",
      "Training set score: 0.477771\n",
      "Test set score: 0.302762\n",
      "\n",
      "Iteration 18, loss = 2.09718025\n",
      "Training set score: 0.484250\n",
      "Test set score: 0.304120\n",
      "\n",
      "Iteration 19, loss = 2.06976807\n",
      "Training set score: 0.490620\n",
      "Test set score: 0.304702\n",
      "\n",
      "Iteration 20, loss = 2.04423155\n",
      "Training set score: 0.495753\n",
      "Test set score: 0.306087\n",
      "\n",
      "Iteration 21, loss = 2.02065261\n",
      "Training set score: 0.500553\n",
      "Test set score: 0.306448\n",
      "\n",
      "Iteration 22, loss = 1.99837190\n",
      "Training set score: 0.504799\n",
      "Test set score: 0.307473\n",
      "\n",
      "Iteration 23, loss = 1.97760789\n",
      "Training set score: 0.508937\n",
      "Test set score: 0.308553\n",
      "\n",
      "Iteration 24, loss = 1.95798402\n",
      "Training set score: 0.512675\n",
      "Test set score: 0.309301\n",
      "\n",
      "Iteration 25, loss = 1.93941834\n",
      "Training set score: 0.516405\n",
      "Test set score: 0.310354\n",
      "\n",
      "Iteration 26, loss = 1.92203979\n",
      "Training set score: 0.520361\n",
      "Test set score: 0.310576\n",
      "\n",
      "Iteration 27, loss = 1.90566707\n",
      "Training set score: 0.523822\n",
      "Test set score: 0.310133\n",
      "\n",
      "Iteration 28, loss = 1.88998159\n",
      "Training set score: 0.527072\n",
      "Test set score: 0.310853\n",
      "\n",
      "Iteration 29, loss = 1.87513937\n",
      "Training set score: 0.530294\n",
      "Test set score: 0.311684\n",
      "\n",
      "Iteration 30, loss = 1.86108746\n",
      "Training set score: 0.533042\n",
      "Test set score: 0.312266\n",
      "\n",
      "Iteration 31, loss = 1.84759139\n",
      "Training set score: 0.535937\n",
      "Test set score: 0.312100\n",
      "\n",
      "Iteration 32, loss = 1.83460641\n",
      "Training set score: 0.538598\n",
      "Test set score: 0.312349\n",
      "\n",
      "Iteration 33, loss = 1.82248125\n",
      "Training set score: 0.541027\n",
      "Test set score: 0.313347\n",
      "\n",
      "Iteration 34, loss = 1.81073023\n",
      "Training set score: 0.543361\n",
      "Test set score: 0.313319\n",
      "\n",
      "Iteration 35, loss = 1.79941111\n",
      "Training set score: 0.545644\n",
      "Test set score: 0.313652\n",
      "\n",
      "Iteration 36, loss = 1.78848723\n",
      "Training set score: 0.547855\n",
      "Test set score: 0.313846\n",
      "\n",
      "Iteration 37, loss = 1.77823731\n",
      "Training set score: 0.550095\n",
      "Test set score: 0.314483\n",
      "\n",
      "Iteration 38, loss = 1.76830650\n",
      "Training set score: 0.552451\n",
      "Test set score: 0.315369\n",
      "\n",
      "Iteration 39, loss = 1.75882851\n",
      "Training set score: 0.554523\n",
      "Test set score: 0.315369\n",
      "\n",
      "Iteration 40, loss = 1.74963186\n",
      "Training set score: 0.556312\n",
      "Test set score: 0.316062\n",
      "\n",
      "Iteration 41, loss = 1.74086393\n",
      "Training set score: 0.557672\n",
      "Test set score: 0.316062\n",
      "\n",
      "Iteration 42, loss = 1.73226894\n",
      "Training set score: 0.559431\n",
      "Test set score: 0.315979\n",
      "\n",
      "Iteration 43, loss = 1.72390548\n",
      "Training set score: 0.560915\n",
      "Test set score: 0.316118\n",
      "\n",
      "Iteration 44, loss = 1.71602787\n",
      "Training set score: 0.562391\n",
      "Test set score: 0.315231\n",
      "\n",
      "Iteration 45, loss = 1.70843625\n",
      "Training set score: 0.564260\n",
      "Test set score: 0.315896\n",
      "\n",
      "Iteration 46, loss = 1.70097330\n",
      "Training set score: 0.564900\n",
      "Test set score: 0.315342\n",
      "\n",
      "Iteration 47, loss = 1.69377247\n",
      "Training set score: 0.566718\n",
      "Test set score: 0.315286\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 48, loss = 1.68675791\n",
      "Training set score: 0.568106\n",
      "Test set score: 0.314732\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 49, loss = 1.68001809\n",
      "Training set score: 0.569481\n",
      "Test set score: 0.315231\n",
      "\n",
      "Iteration 50, loss = 1.67360309\n",
      "Training set score: 0.570673\n",
      "Test set score: 0.315065\n",
      "\n",
      "Iteration 51, loss = 1.66716969\n",
      "Training set score: 0.572200\n",
      "Test set score: 0.315674\n",
      "\n",
      "Iteration 52, loss = 1.66098538\n",
      "Training set score: 0.573255\n",
      "Test set score: 0.315813\n",
      "\n",
      "Iteration 53, loss = 1.65484889\n",
      "Training set score: 0.575080\n",
      "Test set score: 0.316395\n",
      "\n",
      "Iteration 54, loss = 1.64900876\n",
      "Training set score: 0.575960\n",
      "Test set score: 0.316478\n",
      "\n",
      "Iteration 55, loss = 1.64321621\n",
      "Training set score: 0.577429\n",
      "Test set score: 0.317170\n",
      "\n",
      "Iteration 56, loss = 1.63765786\n",
      "Training set score: 0.578381\n",
      "Test set score: 0.317143\n",
      "\n",
      "Iteration 57, loss = 1.63211962\n",
      "Training set score: 0.578883\n",
      "Test set score: 0.316783\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 58, loss = 1.62690083\n",
      "Training set score: 0.579981\n",
      "Test set score: 0.317891\n",
      "\n",
      "Iteration 59, loss = 1.62164347\n",
      "Training set score: 0.581021\n",
      "Test set score: 0.317032\n",
      "\n",
      "Iteration 60, loss = 1.61663311\n",
      "Training set score: 0.582054\n",
      "Test set score: 0.316699\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 61, loss = 1.61165218\n",
      "Training set score: 0.582824\n",
      "Test set score: 0.316866\n",
      "\n",
      "Iteration 62, loss = 1.60686172\n",
      "Training set score: 0.583828\n",
      "Test set score: 0.316866\n",
      "\n",
      "Iteration 63, loss = 1.60215849\n",
      "Training set score: 0.584250\n",
      "Test set score: 0.317032\n",
      "\n",
      "Iteration 64, loss = 1.59760464\n",
      "Training set score: 0.585602\n",
      "Test set score: 0.317143\n",
      "\n",
      "Iteration 65, loss = 1.59306601\n",
      "Training set score: 0.586656\n",
      "Test set score: 0.316478\n",
      "\n",
      "Iteration 66, loss = 1.58879225\n",
      "Training set score: 0.587369\n",
      "Test set score: 0.316201\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 67, loss = 1.58445213\n",
      "Training set score: 0.588416\n",
      "Test set score: 0.316062\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 68, loss = 1.58023343\n",
      "Training set score: 0.589638\n",
      "Test set score: 0.316838\n",
      "\n",
      "Iteration 69, loss = 1.57593756\n",
      "Training set score: 0.590111\n",
      "Test set score: 0.316699\n",
      "\n",
      "Iteration 70, loss = 1.57200338\n",
      "Training set score: 0.591092\n",
      "Test set score: 0.316533\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 71, loss = 1.56799841\n",
      "Training set score: 0.591827\n",
      "Test set score: 0.316977\n",
      "\n",
      "Iteration 72, loss = 1.56401757\n",
      "Training set score: 0.592837\n",
      "Test set score: 0.316505\n",
      "\n",
      "Iteration 73, loss = 1.56012423\n",
      "Training set score: 0.593565\n",
      "Test set score: 0.316422\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 74, loss = 1.55643174\n",
      "Training set score: 0.594481\n",
      "Test set score: 0.317143\n",
      "\n",
      "Iteration 75, loss = 1.55282785\n",
      "Training set score: 0.594961\n",
      "Test set score: 0.317087\n",
      "\n",
      "Iteration 76, loss = 1.54922587\n",
      "Training set score: 0.595950\n",
      "Test set score: 0.316561\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 77, loss = 1.54555876\n",
      "Training set score: 0.596764\n",
      "Test set score: 0.316312\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 78, loss = 1.54203447\n",
      "Training set score: 0.597557\n",
      "Test set score: 0.316312\n",
      "\n",
      "Iteration 79, loss = 1.53881392\n",
      "Training set score: 0.598386\n",
      "Test set score: 0.316367\n",
      "\n",
      "Iteration 80, loss = 1.53554215\n",
      "Training set score: 0.599484\n",
      "Test set score: 0.316339\n",
      "\n",
      "Iteration 81, loss = 1.53215381\n",
      "Training set score: 0.599738\n",
      "Test set score: 0.315757\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 82, loss = 1.52880360\n",
      "Training set score: 0.600327\n",
      "Test set score: 0.315730\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 83, loss = 1.52560561\n",
      "Training set score: 0.600880\n",
      "Test set score: 0.315369\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 84, loss = 1.52255398\n",
      "Training set score: 0.601505\n",
      "Test set score: 0.315647\n",
      "\n",
      "Iteration 85, loss = 1.51957682\n",
      "Training set score: 0.602705\n",
      "Test set score: 0.315563\n",
      "\n",
      "Iteration 86, loss = 1.51642680\n",
      "Training set score: 0.602538\n",
      "Test set score: 0.314788\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 87, loss = 1.51345690\n",
      "Training set score: 0.603214\n",
      "Test set score: 0.315176\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 88, loss = 1.51067251\n",
      "Training set score: 0.603752\n",
      "Test set score: 0.315369\n",
      "\n",
      "Iteration 89, loss = 1.50781679\n",
      "Training set score: 0.604021\n",
      "Test set score: 0.314677\n",
      "\n",
      "Iteration 90, loss = 1.50505476\n",
      "Training set score: 0.604596\n",
      "Test set score: 0.314843\n",
      "\n",
      "Iteration 91, loss = 1.50238249\n",
      "Training set score: 0.605185\n",
      "Test set score: 0.314566\n",
      "\n",
      "Iteration 92, loss = 1.49963898\n",
      "Training set score: 0.605759\n",
      "Test set score: 0.314621\n",
      "\n",
      "Iteration 93, loss = 1.49711364\n",
      "Training set score: 0.606057\n",
      "Test set score: 0.315203\n",
      "\n",
      "Iteration 94, loss = 1.49448064\n",
      "Training set score: 0.606530\n",
      "Test set score: 0.315453\n",
      "\n",
      "Iteration 95, loss = 1.49218801\n",
      "Training set score: 0.607250\n",
      "Test set score: 0.315176\n",
      "\n",
      "Iteration 96, loss = 1.48957941\n",
      "Training set score: 0.608006\n",
      "Test set score: 0.315148\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 97, loss = 1.48700538\n",
      "Training set score: 0.608195\n",
      "Test set score: 0.315286\n",
      "\n",
      "Iteration 98, loss = 1.48457080\n",
      "Training set score: 0.608850\n",
      "Test set score: 0.315120\n",
      "\n",
      "Iteration 99, loss = 1.48224858\n",
      "Training set score: 0.609148\n",
      "Test set score: 0.314982\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 100, loss = 1.47983490\n",
      "Training set score: 0.609410\n",
      "Test set score: 0.315037\n",
      "\n",
      "Iteration 101, loss = 1.47752162\n",
      "Training set score: 0.610180\n",
      "Test set score: 0.314871\n",
      "\n",
      "Iteration 102, loss = 1.47515022\n",
      "Training set score: 0.610755\n",
      "Test set score: 0.315231\n",
      "\n",
      "Iteration 103, loss = 1.47286748\n",
      "Training set score: 0.610937\n",
      "Test set score: 0.315314\n",
      "\n",
      "Iteration 104, loss = 1.47051671\n",
      "Training set score: 0.611504\n",
      "Test set score: 0.315397\n",
      "\n",
      "Iteration 105, loss = 1.46841810\n",
      "Training set score: 0.611926\n",
      "Test set score: 0.315591\n",
      "\n",
      "Iteration 106, loss = 1.46614530\n",
      "Training set score: 0.612413\n",
      "Test set score: 0.315924\n",
      "\n",
      "Iteration 107, loss = 1.46389842\n",
      "Training set score: 0.613002\n",
      "Test set score: 0.315868\n",
      "\n",
      "Iteration 108, loss = 1.46178558\n",
      "Training set score: 0.613329\n",
      "Test set score: 0.316090\n",
      "\n",
      "Iteration 109, loss = 1.45968627\n",
      "Training set score: 0.613998\n",
      "Test set score: 0.315868\n",
      "\n",
      "Iteration 110, loss = 1.45767769\n",
      "Training set score: 0.614085\n",
      "Test set score: 0.315896\n",
      "\n",
      "Iteration 111, loss = 1.45577036\n",
      "Training set score: 0.614543\n",
      "Test set score: 0.315259\n",
      "\n",
      "Iteration 112, loss = 1.45371425\n",
      "Training set score: 0.614391\n",
      "Test set score: 0.315425\n",
      "\n",
      "Iteration 113, loss = 1.45176599\n",
      "Training set score: 0.615350\n",
      "Test set score: 0.315397\n",
      "\n",
      "Iteration 114, loss = 1.44988741\n",
      "Training set score: 0.615787\n",
      "Test set score: 0.315203\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 115, loss = 1.44786026\n",
      "Training set score: 0.616238\n",
      "Test set score: 0.315148\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 116, loss = 1.44603729\n",
      "Training set score: 0.616514\n",
      "Test set score: 0.314871\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 117, loss = 1.44415052\n",
      "Training set score: 0.617118\n",
      "Test set score: 0.315314\n",
      "\n",
      "Iteration 118, loss = 1.44224682\n",
      "Training set score: 0.617241\n",
      "Test set score: 0.315231\n",
      "\n",
      "Iteration 119, loss = 1.44046862\n",
      "Training set score: 0.617663\n",
      "Test set score: 0.315148\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 120, loss = 1.43862417\n",
      "Training set score: 0.617823\n",
      "Test set score: 0.315176\n",
      "\n",
      "Iteration 121, loss = 1.43678046\n",
      "Training set score: 0.618274\n",
      "Test set score: 0.315231\n",
      "\n",
      "Iteration 122, loss = 1.43511186\n",
      "Training set score: 0.618906\n",
      "Test set score: 0.315120\n",
      "\n",
      "Iteration 123, loss = 1.43328473\n",
      "Training set score: 0.618935\n",
      "Test set score: 0.314788\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 124, loss = 1.43164607\n",
      "Training set score: 0.619626\n",
      "Test set score: 0.314732\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 125, loss = 1.43001791\n",
      "Training set score: 0.619495\n",
      "Test set score: 0.315065\n",
      "\n",
      "Iteration 126, loss = 1.42821432\n",
      "Training set score: 0.620077\n",
      "Test set score: 0.314594\n",
      "\n",
      "Iteration 127, loss = 1.42660568\n",
      "Training set score: 0.620688\n",
      "Test set score: 0.314289\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 128, loss = 1.42491546\n",
      "Training set score: 0.621059\n",
      "Test set score: 0.314012\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 129, loss = 1.42345724\n",
      "Training set score: 0.621764\n",
      "Test set score: 0.313762\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 130, loss = 1.42194744\n",
      "Training set score: 0.621866\n",
      "Test set score: 0.313846\n",
      "\n",
      "Iteration 131, loss = 1.42028962\n",
      "Training set score: 0.622302\n",
      "Test set score: 0.314317\n",
      "\n",
      "Iteration 132, loss = 1.41880094\n",
      "Training set score: 0.622288\n",
      "Test set score: 0.314067\n",
      "\n",
      "Iteration 133, loss = 1.41722477\n",
      "Training set score: 0.622942\n",
      "Test set score: 0.314427\n",
      "\n",
      "Iteration 134, loss = 1.41568631\n",
      "Training set score: 0.623095\n",
      "Test set score: 0.314566\n",
      "\n",
      "Iteration 135, loss = 1.41423033\n",
      "Training set score: 0.623095\n",
      "Test set score: 0.314427\n",
      "\n",
      "Iteration 136, loss = 1.41271080\n",
      "Training set score: 0.623706\n",
      "Test set score: 0.314206\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 137, loss = 1.41113930\n",
      "Training set score: 0.623713\n",
      "Test set score: 0.314594\n",
      "\n",
      "Iteration 138, loss = 1.40964430\n",
      "Training set score: 0.624055\n",
      "Test set score: 0.314289\n",
      "\n",
      "Iteration 139, loss = 1.40811820\n",
      "Training set score: 0.624142\n",
      "Test set score: 0.314040\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 140, loss = 1.40670652\n",
      "Training set score: 0.624426\n",
      "Test set score: 0.314372\n",
      "\n",
      "Iteration 141, loss = 1.40511811\n",
      "Training set score: 0.624964\n",
      "Test set score: 0.314649\n",
      "\n",
      "Iteration 142, loss = 1.40372638\n",
      "Training set score: 0.625000\n",
      "Test set score: 0.315065\n",
      "\n",
      "Iteration 143, loss = 1.40227660\n",
      "Training set score: 0.625378\n",
      "Test set score: 0.315231\n",
      "\n",
      "Iteration 144, loss = 1.40085903\n",
      "Training set score: 0.625611\n",
      "Test set score: 0.315397\n",
      "\n",
      "Iteration 145, loss = 1.39954865\n",
      "Training set score: 0.625902\n",
      "Test set score: 0.315231\n",
      "\n",
      "Iteration 146, loss = 1.39814405\n",
      "Training set score: 0.626214\n",
      "Test set score: 0.315314\n",
      "\n",
      "Iteration 147, loss = 1.39682096\n",
      "Training set score: 0.626752\n",
      "Test set score: 0.315397\n",
      "\n",
      "Iteration 148, loss = 1.39546755\n",
      "Training set score: 0.626847\n",
      "Test set score: 0.314926\n",
      "\n",
      "Iteration 149, loss = 1.39408799\n",
      "Training set score: 0.627080\n",
      "Test set score: 0.315148\n",
      "\n",
      "Iteration 150, loss = 1.39282851\n",
      "Training set score: 0.627254\n",
      "Test set score: 0.315342\n",
      "\n",
      "Iteration 151, loss = 1.39151978\n",
      "Training set score: 0.627611\n",
      "Test set score: 0.315120\n",
      "\n",
      "Iteration 152, loss = 1.39017043\n",
      "Training set score: 0.627843\n",
      "Test set score: 0.315259\n",
      "\n",
      "Iteration 153, loss = 1.38905972\n",
      "Training set score: 0.627778\n",
      "Test set score: 0.315369\n",
      "\n",
      "Iteration 154, loss = 1.38784939\n",
      "Training set score: 0.628258\n",
      "Test set score: 0.315037\n",
      "\n",
      "Iteration 155, loss = 1.38645589\n",
      "Training set score: 0.628265\n",
      "Test set score: 0.314871\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 156, loss = 1.38526789\n",
      "Training set score: 0.628869\n",
      "Test set score: 0.314732\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 157, loss = 1.38401153\n",
      "Training set score: 0.628927\n",
      "Test set score: 0.314649\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 158, loss = 1.38269815\n",
      "Training set score: 0.629130\n",
      "Test set score: 0.314566\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 159, loss = 1.38160954\n",
      "Training set score: 0.629654\n",
      "Test set score: 0.314815\n",
      "\n",
      "Iteration 160, loss = 1.38049920\n",
      "Training set score: 0.629988\n",
      "Test set score: 0.314649\n",
      "\n",
      "Iteration 161, loss = 1.37918265\n",
      "Training set score: 0.630010\n",
      "Test set score: 0.314760\n",
      "\n",
      "Iteration 162, loss = 1.37801617\n",
      "Training set score: 0.630301\n",
      "Test set score: 0.314621\n",
      "\n",
      "Iteration 163, loss = 1.37684661\n",
      "Training set score: 0.630497\n",
      "Test set score: 0.314982\n",
      "\n",
      "Iteration 164, loss = 1.37571240\n",
      "Training set score: 0.630694\n",
      "Test set score: 0.315176\n",
      "\n",
      "Iteration 165, loss = 1.37446447\n",
      "Training set score: 0.630454\n",
      "Test set score: 0.314843\n",
      "\n",
      "Iteration 166, loss = 1.37320610\n",
      "Training set score: 0.630941\n",
      "Test set score: 0.315148\n",
      "\n",
      "Iteration 167, loss = 1.37216963\n",
      "Training set score: 0.631297\n",
      "Test set score: 0.314677\n",
      "\n",
      "Iteration 168, loss = 1.37115368\n",
      "Training set score: 0.631683\n",
      "Test set score: 0.314760\n",
      "\n",
      "Iteration 169, loss = 1.36987061\n",
      "Training set score: 0.631981\n",
      "Test set score: 0.314427\n",
      "\n",
      "Iteration 170, loss = 1.36877823\n",
      "Training set score: 0.632301\n",
      "Test set score: 0.314178\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 171, loss = 1.36762236\n",
      "Training set score: 0.632359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.314400\n",
      "\n",
      "Iteration 172, loss = 1.36650822\n",
      "Training set score: 0.632912\n",
      "Test set score: 0.314233\n",
      "\n",
      "Iteration 173, loss = 1.36547886\n",
      "Training set score: 0.632984\n",
      "Test set score: 0.314123\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 174, loss = 1.36446690\n",
      "Training set score: 0.633021\n",
      "Test set score: 0.314150\n",
      "\n",
      "Iteration 175, loss = 1.36335065\n",
      "Training set score: 0.632882\n",
      "Test set score: 0.314067\n",
      "\n",
      "Iteration 176, loss = 1.36239941\n",
      "Training set score: 0.632853\n",
      "Test set score: 0.314289\n",
      "\n",
      "Iteration 177, loss = 1.36141749\n",
      "Training set score: 0.633086\n",
      "Test set score: 0.314455\n",
      "\n",
      "Iteration 178, loss = 1.36036535\n",
      "Training set score: 0.633733\n",
      "Test set score: 0.313873\n",
      "\n",
      "Iteration 179, loss = 1.35934522\n",
      "Training set score: 0.633922\n",
      "Test set score: 0.313956\n",
      "\n",
      "Iteration 180, loss = 1.35835722\n",
      "Training set score: 0.633682\n",
      "Test set score: 0.314400\n",
      "\n",
      "Iteration 181, loss = 1.35729453\n",
      "Training set score: 0.634082\n",
      "Test set score: 0.314538\n",
      "\n",
      "Iteration 182, loss = 1.35625002\n",
      "Training set score: 0.634540\n",
      "Test set score: 0.314233\n",
      "\n",
      "Iteration 183, loss = 1.35519222\n",
      "Training set score: 0.634308\n",
      "Test set score: 0.314178\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 184, loss = 1.35423752\n",
      "Training set score: 0.634584\n",
      "Test set score: 0.313984\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 185, loss = 1.35329118\n",
      "Training set score: 0.634577\n",
      "Test set score: 0.313679\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 186, loss = 1.35233348\n",
      "Training set score: 0.635108\n",
      "Test set score: 0.313984\n",
      "\n",
      "Iteration 187, loss = 1.35138476\n",
      "Training set score: 0.634715\n",
      "Test set score: 0.313762\n",
      "\n",
      "Iteration 188, loss = 1.35043460\n",
      "Training set score: 0.634795\n",
      "Test set score: 0.313596\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 189, loss = 1.34944643\n",
      "Training set score: 0.635260\n",
      "Test set score: 0.314095\n",
      "\n",
      "Iteration 190, loss = 1.34866236\n",
      "Training set score: 0.635209\n",
      "Test set score: 0.313735\n",
      "\n",
      "Iteration 191, loss = 1.34767121\n",
      "Training set score: 0.635493\n",
      "Test set score: 0.313679\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 192, loss = 1.34674422\n",
      "Training set score: 0.636038\n",
      "Test set score: 0.313984\n",
      "\n",
      "Iteration 193, loss = 1.34570883\n",
      "Training set score: 0.635588\n",
      "Test set score: 0.314067\n",
      "\n",
      "Iteration 194, loss = 1.34493513\n",
      "Training set score: 0.636206\n",
      "Test set score: 0.314012\n",
      "\n",
      "Iteration 195, loss = 1.34394540\n",
      "Training set score: 0.636424\n",
      "Test set score: 0.314400\n",
      "\n",
      "Iteration 196, loss = 1.34310785\n",
      "Training set score: 0.636497\n",
      "Test set score: 0.314012\n",
      "\n",
      "Iteration 197, loss = 1.34220555\n",
      "Training set score: 0.636773\n",
      "Test set score: 0.313901\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 198, loss = 1.34137994\n",
      "Training set score: 0.637195\n",
      "Test set score: 0.313956\n",
      "\n",
      "Iteration 199, loss = 1.34046381\n",
      "Training set score: 0.637042\n",
      "Test set score: 0.314040\n",
      "\n",
      "Iteration 200, loss = 1.33963250\n",
      "Training set score: 0.637267\n",
      "Test set score: 0.313901\n",
      "\n",
      "Iteration 201, loss = 1.33870123\n",
      "Training set score: 0.637544\n",
      "Test set score: 0.313513\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 202, loss = 1.33797918\n",
      "Training set score: 0.637405\n",
      "Test set score: 0.314677\n",
      "\n",
      "Iteration 203, loss = 1.33697334\n",
      "Training set score: 0.637565\n",
      "Test set score: 0.314538\n",
      "\n",
      "Iteration 204, loss = 1.33613737\n",
      "Training set score: 0.637842\n",
      "Test set score: 0.313790\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 205, loss = 1.33524067\n",
      "Training set score: 0.638082\n",
      "Test set score: 0.314012\n",
      "\n",
      "Iteration 206, loss = 1.33449973\n",
      "Training set score: 0.638373\n",
      "Test set score: 0.313707\n",
      "\n",
      "Iteration 207, loss = 1.33371719\n",
      "Training set score: 0.638351\n",
      "Test set score: 0.313707\n",
      "\n",
      "Iteration 208, loss = 1.33282858\n",
      "Training set score: 0.638671\n",
      "Test set score: 0.313568\n",
      "\n",
      "Iteration 209, loss = 1.33192514\n",
      "Training set score: 0.638991\n",
      "Test set score: 0.313181\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 210, loss = 1.33112529\n",
      "Training set score: 0.638627\n",
      "Test set score: 0.313707\n",
      "\n",
      "Iteration 211, loss = 1.33041504\n",
      "Training set score: 0.638729\n",
      "Test set score: 0.313208\n",
      "\n",
      "Iteration 212, loss = 1.32950349\n",
      "Training set score: 0.638685\n",
      "Test set score: 0.313347\n",
      "\n",
      "Iteration 213, loss = 1.32876881\n",
      "Training set score: 0.639049\n",
      "Test set score: 0.313347\n",
      "\n",
      "Iteration 214, loss = 1.32795813\n",
      "Training set score: 0.639005\n",
      "Test set score: 0.313208\n",
      "\n",
      "Iteration 215, loss = 1.32725893\n",
      "Training set score: 0.639274\n",
      "Test set score: 0.313402\n",
      "\n",
      "Iteration 216, loss = 1.32652499\n",
      "Training set score: 0.639442\n",
      "Test set score: 0.313624\n",
      "\n",
      "Iteration 217, loss = 1.32570849\n",
      "Training set score: 0.639725\n",
      "Test set score: 0.313513\n",
      "\n",
      "Iteration 218, loss = 1.32486310\n",
      "Training set score: 0.639522\n",
      "Test set score: 0.313790\n",
      "\n",
      "Iteration 219, loss = 1.32417404\n",
      "Training set score: 0.639929\n",
      "Test set score: 0.313652\n",
      "\n",
      "Iteration 220, loss = 1.32350602\n",
      "Training set score: 0.639747\n",
      "Test set score: 0.314261\n",
      "\n",
      "Iteration 221, loss = 1.32281851\n",
      "Training set score: 0.640001\n",
      "Test set score: 0.313956\n",
      "\n",
      "Iteration 222, loss = 1.32194611\n",
      "Training set score: 0.640074\n",
      "Test set score: 0.313679\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 223, loss = 1.32125961\n",
      "Training set score: 0.640271\n",
      "Test set score: 0.313236\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 224, loss = 1.32053880\n",
      "Training set score: 0.640445\n",
      "Test set score: 0.313596\n",
      "\n",
      "Iteration 225, loss = 1.31980302\n",
      "Training set score: 0.640256\n",
      "Test set score: 0.313347\n",
      "\n",
      "Iteration 226, loss = 1.31911313\n",
      "Training set score: 0.640452\n",
      "Test set score: 0.313375\n",
      "\n",
      "Iteration 227, loss = 1.31844777\n",
      "Training set score: 0.640518\n",
      "Test set score: 0.313430\n",
      "\n",
      "Iteration 228, loss = 1.31769344\n",
      "Training set score: 0.640612\n",
      "Test set score: 0.313679\n",
      "\n",
      "Iteration 229, loss = 1.31704801\n",
      "Training set score: 0.640736\n",
      "Test set score: 0.312848\n",
      "\n",
      "Iteration 230, loss = 1.31632168\n",
      "Training set score: 0.640852\n",
      "Test set score: 0.313208\n",
      "\n",
      "Iteration 231, loss = 1.31572235\n",
      "Training set score: 0.640801\n",
      "Test set score: 0.313236\n",
      "\n",
      "Iteration 232, loss = 1.31492661\n",
      "Training set score: 0.640845\n",
      "Test set score: 0.313125\n",
      "\n",
      "Iteration 233, loss = 1.31435267\n",
      "Training set score: 0.640925\n",
      "Test set score: 0.312239\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 234, loss = 1.31371650\n",
      "Training set score: 0.640990\n",
      "Test set score: 0.312377\n",
      "\n",
      "Iteration 235, loss = 1.31296217\n",
      "Training set score: 0.641194\n",
      "Test set score: 0.311961\n",
      "\n",
      "Iteration 236, loss = 1.31244618\n",
      "Training set score: 0.641165\n",
      "Test set score: 0.312349\n",
      "\n",
      "Iteration 237, loss = 1.31173458\n",
      "Training set score: 0.641259\n",
      "Test set score: 0.312155\n",
      "\n",
      "Iteration 238, loss = 1.31112180\n",
      "Training set score: 0.641652\n",
      "Test set score: 0.312349\n",
      "\n",
      "Iteration 239, loss = 1.31044967\n",
      "Training set score: 0.642001\n",
      "Test set score: 0.312349\n",
      "\n",
      "Iteration 240, loss = 1.30979623\n",
      "Training set score: 0.642118\n",
      "Test set score: 0.312682\n",
      "\n",
      "Iteration 241, loss = 1.30909603\n",
      "Training set score: 0.641950\n",
      "Test set score: 0.312405\n",
      "\n",
      "Iteration 242, loss = 1.30847874\n",
      "Training set score: 0.641965\n",
      "Test set score: 0.312045\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 243, loss = 1.30780741\n",
      "Training set score: 0.642227\n",
      "Test set score: 0.312211\n",
      "\n",
      "Iteration 244, loss = 1.30728543\n",
      "Training set score: 0.642394\n",
      "Test set score: 0.312128\n",
      "\n",
      "Iteration 245, loss = 1.30657502\n",
      "Training set score: 0.642292\n",
      "Test set score: 0.311906\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 246, loss = 1.30597846\n",
      "Training set score: 0.642699\n",
      "Test set score: 0.312045\n",
      "\n",
      "Iteration 247, loss = 1.30536695\n",
      "Training set score: 0.642576\n",
      "Test set score: 0.311934\n",
      "\n",
      "Iteration 248, loss = 1.30475584\n",
      "Training set score: 0.642547\n",
      "Test set score: 0.311961\n",
      "\n",
      "Iteration 249, loss = 1.30416795\n",
      "Training set score: 0.642787\n",
      "Test set score: 0.311712\n",
      "\n",
      "Iteration 250, loss = 1.30351425\n",
      "Training set score: 0.643005\n",
      "Test set score: 0.311823\n",
      "\n",
      "Iteration 251, loss = 1.30290630\n",
      "Training set score: 0.642997\n",
      "Test set score: 0.311740\n",
      "\n",
      "Iteration 252, loss = 1.30220397\n",
      "Training set score: 0.643230\n",
      "Test set score: 0.312183\n",
      "\n",
      "Iteration 253, loss = 1.30155019\n",
      "Training set score: 0.643136\n",
      "Test set score: 0.311851\n",
      "\n",
      "Iteration 254, loss = 1.30101148\n",
      "Training set score: 0.643506\n",
      "Test set score: 0.311823\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 255, loss = 1.30048340\n",
      "Training set score: 0.643855\n",
      "Test set score: 0.311906\n",
      "\n",
      "Iteration 256, loss = 1.29995369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.643841\n",
      "Test set score: 0.311906\n",
      "\n",
      "Iteration 257, loss = 1.29935327\n",
      "Training set score: 0.643841\n",
      "Test set score: 0.311878\n",
      "\n",
      "Iteration 258, loss = 1.29874485\n",
      "Training set score: 0.644154\n",
      "Test set score: 0.311906\n",
      "\n",
      "Iteration 259, loss = 1.29826066\n",
      "Training set score: 0.644299\n",
      "Test set score: 0.311795\n",
      "\n",
      "Iteration 260, loss = 1.29763873\n",
      "Training set score: 0.644459\n",
      "Test set score: 0.312349\n",
      "\n",
      "Iteration 261, loss = 1.29698041\n",
      "Training set score: 0.644364\n",
      "Test set score: 0.312460\n",
      "\n",
      "Iteration 262, loss = 1.29653321\n",
      "Training set score: 0.644314\n",
      "Test set score: 0.312543\n",
      "\n",
      "Iteration 263, loss = 1.29594205\n",
      "Training set score: 0.644655\n",
      "Test set score: 0.312599\n",
      "\n",
      "Iteration 264, loss = 1.29537655\n",
      "Training set score: 0.644488\n",
      "Test set score: 0.312349\n",
      "\n",
      "Iteration 265, loss = 1.29473713\n",
      "Training set score: 0.644568\n",
      "Test set score: 0.312100\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 266, loss = 1.29416791\n",
      "Training set score: 0.644924\n",
      "Test set score: 0.312100\n",
      "\n",
      "Iteration 267, loss = 1.29377478\n",
      "Training set score: 0.645077\n",
      "Test set score: 0.311657\n",
      "\n",
      "Iteration 268, loss = 1.29316952\n",
      "Training set score: 0.644764\n",
      "Test set score: 0.312239\n",
      "\n",
      "Iteration 269, loss = 1.29261401\n",
      "Training set score: 0.645295\n",
      "Test set score: 0.312128\n",
      "\n",
      "Iteration 270, loss = 1.29216927\n",
      "Training set score: 0.645092\n",
      "Test set score: 0.311878\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 271, loss = 1.29158134\n",
      "Training set score: 0.645201\n",
      "Test set score: 0.312017\n",
      "\n",
      "Iteration 272, loss = 1.29120008\n",
      "Training set score: 0.645215\n",
      "Test set score: 0.312100\n",
      "\n",
      "Iteration 273, loss = 1.29058528\n",
      "Training set score: 0.645259\n",
      "Test set score: 0.311601\n",
      "\n",
      "Iteration 274, loss = 1.29003524\n",
      "Training set score: 0.645761\n",
      "Test set score: 0.312128\n",
      "\n",
      "Iteration 275, loss = 1.28941657\n",
      "Training set score: 0.645644\n",
      "Test set score: 0.311989\n",
      "\n",
      "Iteration 276, loss = 1.28903012\n",
      "Training set score: 0.645615\n",
      "Test set score: 0.311851\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 277, loss = 1.28854284\n",
      "Training set score: 0.645528\n",
      "Test set score: 0.312599\n",
      "\n",
      "Iteration 278, loss = 1.28792375\n",
      "Training set score: 0.645979\n",
      "Test set score: 0.311795\n",
      "\n",
      "Iteration 279, loss = 1.28760076\n",
      "Training set score: 0.646015\n",
      "Test set score: 0.311629\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 280, loss = 1.28697126\n",
      "Training set score: 0.645950\n",
      "Test set score: 0.311380\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 281, loss = 1.28642734\n",
      "Training set score: 0.646153\n",
      "Test set score: 0.311047\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 282, loss = 1.28595407\n",
      "Training set score: 0.646371\n",
      "Test set score: 0.311961\n",
      "\n",
      "Iteration 283, loss = 1.28546661\n",
      "Training set score: 0.645819\n",
      "Test set score: 0.311158\n",
      "\n",
      "Iteration 284, loss = 1.28502791\n",
      "Training set score: 0.646262\n",
      "Test set score: 0.311767\n",
      "\n",
      "Iteration 285, loss = 1.28447788\n",
      "Training set score: 0.646437\n",
      "Test set score: 0.311629\n",
      "\n",
      "Iteration 286, loss = 1.28402717\n",
      "Training set score: 0.646517\n",
      "Test set score: 0.311324\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 287, loss = 1.28350832\n",
      "Training set score: 0.646211\n",
      "Test set score: 0.311324\n",
      "\n",
      "Iteration 288, loss = 1.28309953\n",
      "Training set score: 0.646757\n",
      "Test set score: 0.311878\n",
      "\n",
      "Iteration 289, loss = 1.28250699\n",
      "Training set score: 0.646451\n",
      "Test set score: 0.311546\n",
      "\n",
      "Iteration 290, loss = 1.28195618\n",
      "Training set score: 0.646524\n",
      "Test set score: 0.311324\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 291, loss = 1.28147914\n",
      "Training set score: 0.646728\n",
      "Test set score: 0.311102\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 292, loss = 1.28109313\n",
      "Training set score: 0.646662\n",
      "Test set score: 0.311075\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 293, loss = 1.28054275\n",
      "Training set score: 0.646808\n",
      "Test set score: 0.311324\n",
      "\n",
      "Iteration 294, loss = 1.27989070\n",
      "Training set score: 0.646815\n",
      "Test set score: 0.311186\n",
      "\n",
      "Iteration 295, loss = 1.27949903\n",
      "Training set score: 0.646793\n",
      "Test set score: 0.312045\n",
      "\n",
      "Iteration 296, loss = 1.27900127\n",
      "Training set score: 0.647317\n",
      "Test set score: 0.311795\n",
      "\n",
      "Iteration 297, loss = 1.27850575\n",
      "Training set score: 0.647150\n",
      "Test set score: 0.312294\n",
      "\n",
      "Iteration 298, loss = 1.27807756\n",
      "Training set score: 0.647346\n",
      "Test set score: 0.312017\n",
      "\n",
      "Iteration 299, loss = 1.27770371\n",
      "Training set score: 0.647600\n",
      "Test set score: 0.312211\n",
      "\n",
      "Iteration 300, loss = 1.27716864\n",
      "Training set score: 0.647898\n",
      "Test set score: 0.312377\n",
      "\n",
      "Iteration 301, loss = 1.27657107\n",
      "Training set score: 0.648015\n",
      "Test set score: 0.312266\n",
      "\n",
      "Iteration 302, loss = 1.27615181\n",
      "Training set score: 0.647782\n",
      "Test set score: 0.312017\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 303, loss = 1.27570971\n",
      "Training set score: 0.648080\n",
      "Test set score: 0.311989\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 304, loss = 1.27523334\n",
      "Training set score: 0.648248\n",
      "Test set score: 0.311934\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 305, loss = 1.27466594\n",
      "Training set score: 0.648211\n",
      "Test set score: 0.311934\n",
      "\n",
      "Iteration 306, loss = 1.27426743\n",
      "Training set score: 0.648611\n",
      "Test set score: 0.312266\n",
      "\n",
      "Iteration 307, loss = 1.27390411\n",
      "Training set score: 0.648335\n",
      "Test set score: 0.311934\n",
      "\n",
      "Iteration 308, loss = 1.27337316\n",
      "Training set score: 0.648778\n",
      "Test set score: 0.311795\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 309, loss = 1.27290190\n",
      "Training set score: 0.648466\n",
      "Test set score: 0.312239\n",
      "\n",
      "Iteration 310, loss = 1.27246990\n",
      "Training set score: 0.648531\n",
      "Test set score: 0.311712\n",
      "\n",
      "Iteration 311, loss = 1.27191340\n",
      "Training set score: 0.648807\n",
      "Test set score: 0.311712\n",
      "\n",
      "Iteration 312, loss = 1.27150856\n",
      "Training set score: 0.648800\n",
      "Test set score: 0.311906\n",
      "\n",
      "Iteration 313, loss = 1.27106032\n",
      "Training set score: 0.648807\n",
      "Test set score: 0.311712\n",
      "\n",
      "Iteration 314, loss = 1.27042482\n",
      "Training set score: 0.648720\n",
      "Test set score: 0.311435\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 315, loss = 1.27007476\n",
      "Training set score: 0.648895\n",
      "Test set score: 0.311740\n",
      "\n",
      "Iteration 316, loss = 1.26964441\n",
      "Training set score: 0.649215\n",
      "Test set score: 0.311961\n",
      "\n",
      "Iteration 317, loss = 1.26915179\n",
      "Training set score: 0.649556\n",
      "Test set score: 0.311795\n",
      "\n",
      "Iteration 318, loss = 1.26868694\n",
      "Training set score: 0.649498\n",
      "Test set score: 0.312017\n",
      "\n",
      "Iteration 319, loss = 1.26826810\n",
      "Training set score: 0.649331\n",
      "Test set score: 0.311324\n",
      "\n",
      "Iteration 320, loss = 1.26770718\n",
      "Training set score: 0.649651\n",
      "Test set score: 0.311407\n",
      "\n",
      "Iteration 321, loss = 1.26728266\n",
      "Training set score: 0.649476\n",
      "Test set score: 0.311130\n",
      "\n",
      "Iteration 322, loss = 1.26676745\n",
      "Training set score: 0.649564\n",
      "Test set score: 0.311435\n",
      "\n",
      "Iteration 323, loss = 1.26644669\n",
      "Training set score: 0.649905\n",
      "Test set score: 0.310715\n",
      "\n",
      "Iteration 324, loss = 1.26591573\n",
      "Training set score: 0.649855\n",
      "Test set score: 0.310881\n",
      "\n",
      "Iteration 325, loss = 1.26553494\n",
      "Training set score: 0.649745\n",
      "Test set score: 0.310576\n",
      "\n",
      "Iteration 326, loss = 1.26501426\n",
      "Training set score: 0.649607\n",
      "Test set score: 0.310576\n",
      "\n",
      "Iteration 327, loss = 1.26451506\n",
      "Training set score: 0.649956\n",
      "Test set score: 0.310244\n",
      "\n",
      "Iteration 328, loss = 1.26409818\n",
      "Training set score: 0.649964\n",
      "Test set score: 0.310271\n",
      "\n",
      "Iteration 329, loss = 1.26371742\n",
      "Training set score: 0.650051\n",
      "Test set score: 0.310465\n",
      "\n",
      "Iteration 330, loss = 1.26323808\n",
      "Training set score: 0.649935\n",
      "Test set score: 0.310160\n",
      "\n",
      "Iteration 331, loss = 1.26282874\n",
      "Training set score: 0.650567\n",
      "Test set score: 0.310050\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 332, loss = 1.26240830\n",
      "Training set score: 0.650189\n",
      "Test set score: 0.309689\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 333, loss = 1.26202818\n",
      "Training set score: 0.650611\n",
      "Test set score: 0.309745\n",
      "\n",
      "Iteration 334, loss = 1.26160383\n",
      "Training set score: 0.650727\n",
      "Test set score: 0.310022\n",
      "\n",
      "Iteration 335, loss = 1.26122724\n",
      "Training set score: 0.650705\n",
      "Test set score: 0.309662\n",
      "\n",
      "Iteration 336, loss = 1.26092023\n",
      "Training set score: 0.651040\n",
      "Test set score: 0.310105\n",
      "\n",
      "Iteration 337, loss = 1.26039731\n",
      "Training set score: 0.650945\n",
      "Test set score: 0.309856\n",
      "\n",
      "Iteration 338, loss = 1.26010149\n",
      "Training set score: 0.651127\n",
      "Test set score: 0.309745\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 339, loss = 1.25961632\n",
      "Training set score: 0.651251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.310133\n",
      "\n",
      "Iteration 340, loss = 1.25915222\n",
      "Training set score: 0.651505\n",
      "Test set score: 0.309966\n",
      "\n",
      "Iteration 341, loss = 1.25890341\n",
      "Training set score: 0.651600\n",
      "Test set score: 0.310410\n",
      "\n",
      "Iteration 342, loss = 1.25853061\n",
      "Training set score: 0.651665\n",
      "Test set score: 0.309689\n",
      "\n",
      "Iteration 343, loss = 1.25805845\n",
      "Training set score: 0.651418\n",
      "Test set score: 0.310050\n",
      "\n",
      "Iteration 344, loss = 1.25770722\n",
      "Training set score: 0.651847\n",
      "Test set score: 0.309440\n",
      "\n",
      "Iteration 345, loss = 1.25726938\n",
      "Training set score: 0.651607\n",
      "Test set score: 0.309773\n",
      "\n",
      "Iteration 346, loss = 1.25694856\n",
      "Training set score: 0.652203\n",
      "Test set score: 0.309440\n",
      "\n",
      "Iteration 347, loss = 1.25659433\n",
      "Training set score: 0.651912\n",
      "Test set score: 0.309385\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 348, loss = 1.25624463\n",
      "Training set score: 0.652152\n",
      "Test set score: 0.309579\n",
      "\n",
      "Iteration 349, loss = 1.25580570\n",
      "Training set score: 0.652094\n",
      "Test set score: 0.309994\n",
      "\n",
      "Iteration 350, loss = 1.25543773\n",
      "Training set score: 0.652400\n",
      "Test set score: 0.309218\n",
      "\n",
      "Iteration 351, loss = 1.25509212\n",
      "Training set score: 0.652334\n",
      "Test set score: 0.309357\n",
      "\n",
      "Iteration 352, loss = 1.25476168\n",
      "Training set score: 0.652458\n",
      "Test set score: 0.309412\n",
      "\n",
      "Iteration 353, loss = 1.25431747\n",
      "Training set score: 0.652850\n",
      "Test set score: 0.309495\n",
      "\n",
      "Iteration 354, loss = 1.25387957\n",
      "Training set score: 0.652763\n",
      "Test set score: 0.308969\n",
      "\n",
      "Iteration 355, loss = 1.25352318\n",
      "Training set score: 0.652960\n",
      "Test set score: 0.309329\n",
      "\n",
      "Iteration 356, loss = 1.25320595\n",
      "Training set score: 0.652807\n",
      "Test set score: 0.309301\n",
      "\n",
      "Iteration 357, loss = 1.25279264\n",
      "Training set score: 0.652756\n",
      "Test set score: 0.309080\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 358, loss = 1.25232942\n",
      "Training set score: 0.652807\n",
      "Test set score: 0.309163\n",
      "\n",
      "Iteration 359, loss = 1.25198719\n",
      "Training set score: 0.652778\n",
      "Test set score: 0.309052\n",
      "\n",
      "Iteration 360, loss = 1.25161422\n",
      "Training set score: 0.652821\n",
      "Test set score: 0.308443\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 361, loss = 1.25123340\n",
      "Training set score: 0.652727\n",
      "Test set score: 0.308692\n",
      "\n",
      "Iteration 362, loss = 1.25087437\n",
      "Training set score: 0.653250\n",
      "Test set score: 0.309135\n",
      "\n",
      "Iteration 363, loss = 1.25056197\n",
      "Training set score: 0.653607\n",
      "Test set score: 0.308692\n",
      "\n",
      "Iteration 364, loss = 1.25013391\n",
      "Training set score: 0.653512\n",
      "Test set score: 0.308858\n",
      "\n",
      "Iteration 365, loss = 1.24959050\n",
      "Training set score: 0.653432\n",
      "Test set score: 0.308637\n",
      "\n",
      "Iteration 366, loss = 1.24931641\n",
      "Training set score: 0.653469\n",
      "Test set score: 0.308443\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 367, loss = 1.24897007\n",
      "Training set score: 0.653592\n",
      "Test set score: 0.309052\n",
      "\n",
      "Iteration 368, loss = 1.24871415\n",
      "Training set score: 0.653956\n",
      "Test set score: 0.308581\n",
      "\n",
      "Iteration 369, loss = 1.24827743\n",
      "Training set score: 0.654123\n",
      "Test set score: 0.308553\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 370, loss = 1.24792629\n",
      "Training set score: 0.653767\n",
      "Test set score: 0.308193\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 371, loss = 1.24748984\n",
      "Training set score: 0.654138\n",
      "Test set score: 0.308498\n",
      "\n",
      "Iteration 372, loss = 1.24711999\n",
      "Training set score: 0.654290\n",
      "Test set score: 0.308747\n",
      "\n",
      "Iteration 373, loss = 1.24666589\n",
      "Training set score: 0.654348\n",
      "Test set score: 0.308553\n",
      "\n",
      "Iteration 374, loss = 1.24642741\n",
      "Training set score: 0.654494\n",
      "Test set score: 0.308359\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 375, loss = 1.24591865\n",
      "Training set score: 0.654399\n",
      "Test set score: 0.308138\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 376, loss = 1.24570759\n",
      "Training set score: 0.654210\n",
      "Test set score: 0.308637\n",
      "\n",
      "Iteration 377, loss = 1.24528210\n",
      "Training set score: 0.654712\n",
      "Test set score: 0.308193\n",
      "\n",
      "Iteration 378, loss = 1.24489958\n",
      "Training set score: 0.654785\n",
      "Test set score: 0.308387\n",
      "\n",
      "Iteration 379, loss = 1.24451783\n",
      "Training set score: 0.654894\n",
      "Test set score: 0.308138\n",
      "\n",
      "Iteration 380, loss = 1.24406491\n",
      "Training set score: 0.654734\n",
      "Test set score: 0.308276\n",
      "\n",
      "Iteration 381, loss = 1.24379758\n",
      "Training set score: 0.654567\n",
      "Test set score: 0.308332\n",
      "\n",
      "Iteration 382, loss = 1.24343555\n",
      "Training set score: 0.654734\n",
      "Test set score: 0.308609\n",
      "\n",
      "Iteration 383, loss = 1.24305300\n",
      "Training set score: 0.654770\n",
      "Test set score: 0.308387\n",
      "\n",
      "Iteration 384, loss = 1.24258900\n",
      "Training set score: 0.654901\n",
      "Test set score: 0.308359\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 385, loss = 1.24231378\n",
      "Training set score: 0.654741\n",
      "Test set score: 0.308165\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 386, loss = 1.24187665\n",
      "Training set score: 0.654712\n",
      "Test set score: 0.308221\n",
      "\n",
      "Iteration 387, loss = 1.24163872\n",
      "Training set score: 0.654843\n",
      "Test set score: 0.308553\n",
      "\n",
      "Iteration 388, loss = 1.24120092\n",
      "Training set score: 0.654945\n",
      "Test set score: 0.308443\n",
      "\n",
      "Iteration 389, loss = 1.24099332\n",
      "Training set score: 0.654763\n",
      "Test set score: 0.308249\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 390, loss = 1.24044777\n",
      "Training set score: 0.654777\n",
      "Test set score: 0.308138\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 391, loss = 1.24013127\n",
      "Training set score: 0.655148\n",
      "Test set score: 0.308055\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 392, loss = 1.23985339\n",
      "Training set score: 0.654828\n",
      "Test set score: 0.308193\n",
      "\n",
      "Iteration 393, loss = 1.23941075\n",
      "Training set score: 0.655243\n",
      "Test set score: 0.307888\n",
      "\n",
      "Iteration 394, loss = 1.23912966\n",
      "Training set score: 0.654996\n",
      "Test set score: 0.308443\n",
      "\n",
      "Iteration 395, loss = 1.23865386\n",
      "Training set score: 0.655032\n",
      "Test set score: 0.308110\n",
      "\n",
      "Iteration 396, loss = 1.23827826\n",
      "Training set score: 0.655221\n",
      "Test set score: 0.307750\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 397, loss = 1.23805471\n",
      "Training set score: 0.655526\n",
      "Test set score: 0.307972\n",
      "\n",
      "Iteration 398, loss = 1.23757734\n",
      "Training set score: 0.655039\n",
      "Test set score: 0.307667\n",
      "\n",
      "Iteration 399, loss = 1.23729273\n",
      "Training set score: 0.655257\n",
      "Test set score: 0.307722\n",
      "\n",
      "Iteration 400, loss = 1.23695075\n",
      "Training set score: 0.655461\n",
      "Test set score: 0.307694\n",
      "\n",
      "Iteration 401, loss = 1.23652931\n",
      "Training set score: 0.655221\n",
      "Test set score: 0.308221\n",
      "\n",
      "Iteration 402, loss = 1.23636546\n",
      "Training set score: 0.655287\n",
      "Test set score: 0.307888\n",
      "\n",
      "Iteration 403, loss = 1.23592304\n",
      "Training set score: 0.655643\n",
      "Test set score: 0.307750\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 404, loss = 1.23554063\n",
      "Training set score: 0.655854\n",
      "Test set score: 0.307639\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 405, loss = 1.23539796\n",
      "Training set score: 0.655563\n",
      "Test set score: 0.307362\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 406, loss = 1.23502008\n",
      "Training set score: 0.655796\n",
      "Test set score: 0.307500\n",
      "\n",
      "Iteration 407, loss = 1.23467805\n",
      "Training set score: 0.656072\n",
      "Test set score: 0.307500\n",
      "\n",
      "Iteration 408, loss = 1.23447218\n",
      "Training set score: 0.655657\n",
      "Test set score: 0.307473\n",
      "\n",
      "Iteration 409, loss = 1.23398511\n",
      "Training set score: 0.655926\n",
      "Test set score: 0.307556\n",
      "\n",
      "Iteration 410, loss = 1.23375755\n",
      "Training set score: 0.655817\n",
      "Test set score: 0.307500\n",
      "\n",
      "Iteration 411, loss = 1.23334960\n",
      "Training set score: 0.656559\n",
      "Test set score: 0.307861\n",
      "\n",
      "Iteration 412, loss = 1.23302441\n",
      "Training set score: 0.655999\n",
      "Test set score: 0.307584\n",
      "\n",
      "Iteration 413, loss = 1.23280914\n",
      "Training set score: 0.656225\n",
      "Test set score: 0.307639\n",
      "\n",
      "Iteration 414, loss = 1.23235460\n",
      "Training set score: 0.656065\n",
      "Test set score: 0.307750\n",
      "\n",
      "Iteration 415, loss = 1.23200705\n",
      "Training set score: 0.655861\n",
      "Test set score: 0.307916\n",
      "\n",
      "Iteration 416, loss = 1.23169502\n",
      "Training set score: 0.656166\n",
      "Test set score: 0.307611\n",
      "\n",
      "Iteration 417, loss = 1.23148343\n",
      "Training set score: 0.656414\n",
      "Test set score: 0.308138\n",
      "\n",
      "Iteration 418, loss = 1.23108031\n",
      "Training set score: 0.656217\n",
      "Test set score: 0.307307\n",
      "\n",
      "Iteration 419, loss = 1.23064870\n",
      "Training set score: 0.656341\n",
      "Test set score: 0.307888\n",
      "\n",
      "Iteration 420, loss = 1.23035664\n",
      "Training set score: 0.656566\n",
      "Test set score: 0.308359\n",
      "\n",
      "Iteration 421, loss = 1.23014412\n",
      "Training set score: 0.656581\n",
      "Test set score: 0.308304\n",
      "\n",
      "Iteration 422, loss = 1.22973714\n",
      "Training set score: 0.656821\n",
      "Test set score: 0.307750\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 423, loss = 1.22940321\n",
      "Training set score: 0.656799\n",
      "Test set score: 0.307916\n",
      "\n",
      "Iteration 424, loss = 1.22921775\n",
      "Training set score: 0.656894\n",
      "Test set score: 0.308553\n",
      "\n",
      "Iteration 425, loss = 1.22887201\n",
      "Training set score: 0.656894\n",
      "Test set score: 0.307694\n",
      "\n",
      "Iteration 426, loss = 1.22850249\n",
      "Training set score: 0.656908\n",
      "Test set score: 0.307390\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 427, loss = 1.22826069\n",
      "Training set score: 0.656704\n",
      "Test set score: 0.307611\n",
      "\n",
      "Iteration 428, loss = 1.22784989\n",
      "Training set score: 0.656915\n",
      "Test set score: 0.307556\n",
      "\n",
      "Iteration 429, loss = 1.22765185\n",
      "Training set score: 0.657039\n",
      "Test set score: 0.308055\n",
      "\n",
      "Iteration 430, loss = 1.22729068\n",
      "Training set score: 0.657235\n",
      "Test set score: 0.307639\n",
      "\n",
      "Iteration 431, loss = 1.22689531\n",
      "Training set score: 0.657090\n",
      "Test set score: 0.307778\n",
      "\n",
      "Iteration 432, loss = 1.22666331\n",
      "Training set score: 0.656683\n",
      "Test set score: 0.308165\n",
      "\n",
      "Iteration 433, loss = 1.22631393\n",
      "Training set score: 0.656792\n",
      "Test set score: 0.308221\n",
      "\n",
      "Iteration 434, loss = 1.22609639\n",
      "Training set score: 0.657010\n",
      "Test set score: 0.308138\n",
      "\n",
      "Iteration 435, loss = 1.22580664\n",
      "Training set score: 0.657104\n",
      "Test set score: 0.307805\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 436, loss = 1.22552716\n",
      "Training set score: 0.656952\n",
      "Test set score: 0.308387\n",
      "\n",
      "Iteration 437, loss = 1.22509834\n",
      "Training set score: 0.657504\n",
      "Test set score: 0.307667\n",
      "\n",
      "Iteration 438, loss = 1.22480558\n",
      "Training set score: 0.657417\n",
      "Test set score: 0.308138\n",
      "\n",
      "Iteration 439, loss = 1.22442176\n",
      "Training set score: 0.657475\n",
      "Test set score: 0.307972\n",
      "\n",
      "Iteration 440, loss = 1.22411568\n",
      "Training set score: 0.657381\n",
      "Test set score: 0.307999\n",
      "\n",
      "Iteration 441, loss = 1.22395469\n",
      "Training set score: 0.657170\n",
      "Test set score: 0.308332\n",
      "\n",
      "Iteration 442, loss = 1.22361997\n",
      "Training set score: 0.657563\n",
      "Test set score: 0.307861\n",
      "\n",
      "Iteration 443, loss = 1.22325183\n",
      "Training set score: 0.657512\n",
      "Test set score: 0.308138\n",
      "\n",
      "Iteration 444, loss = 1.22300116\n",
      "Training set score: 0.657810\n",
      "Test set score: 0.308443\n",
      "\n",
      "Iteration 445, loss = 1.22270808\n",
      "Training set score: 0.657693\n",
      "Test set score: 0.307861\n",
      "\n",
      "Iteration 446, loss = 1.22236440\n",
      "Training set score: 0.657672\n",
      "Test set score: 0.308304\n",
      "\n",
      "Iteration 447, loss = 1.22226251\n",
      "Training set score: 0.657541\n",
      "Test set score: 0.308027\n",
      "\n",
      "Iteration 448, loss = 1.22192888\n",
      "Training set score: 0.657599\n",
      "Test set score: 0.307639\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 449, loss = 1.22161893\n",
      "Training set score: 0.657635\n",
      "Test set score: 0.308165\n",
      "\n",
      "Iteration 450, loss = 1.22125753\n",
      "Training set score: 0.657737\n",
      "Test set score: 0.308193\n",
      "\n",
      "Iteration 451, loss = 1.22101729\n",
      "Training set score: 0.657752\n",
      "Test set score: 0.307750\n",
      "\n",
      "Iteration 452, loss = 1.22066575\n",
      "Training set score: 0.657962\n",
      "Test set score: 0.307500\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 453, loss = 1.22053681\n",
      "Training set score: 0.657795\n",
      "Test set score: 0.307805\n",
      "\n",
      "Iteration 454, loss = 1.22015406\n",
      "Training set score: 0.657890\n",
      "Test set score: 0.306946\n",
      "\n",
      "Iteration 455, loss = 1.21979858\n",
      "Training set score: 0.658079\n",
      "Test set score: 0.307307\n",
      "\n",
      "Iteration 456, loss = 1.21965881\n",
      "Training set score: 0.658050\n",
      "Test set score: 0.307694\n",
      "\n",
      "Iteration 457, loss = 1.21935027\n",
      "Training set score: 0.658042\n",
      "Test set score: 0.307694\n",
      "\n",
      "Iteration 458, loss = 1.21901248\n",
      "Training set score: 0.658130\n",
      "Test set score: 0.308332\n",
      "\n",
      "Iteration 459, loss = 1.21877771\n",
      "Training set score: 0.658551\n",
      "Test set score: 0.307307\n",
      "\n",
      "Iteration 460, loss = 1.21849255\n",
      "Training set score: 0.658304\n",
      "Test set score: 0.307667\n",
      "\n",
      "Iteration 461, loss = 1.21810701\n",
      "Training set score: 0.658399\n",
      "Test set score: 0.307778\n",
      "\n",
      "Iteration 462, loss = 1.21805116\n",
      "Training set score: 0.658210\n",
      "Test set score: 0.307750\n",
      "\n",
      "Iteration 463, loss = 1.21764285\n",
      "Training set score: 0.658646\n",
      "Test set score: 0.307861\n",
      "\n",
      "Iteration 464, loss = 1.21738678\n",
      "Training set score: 0.658406\n",
      "Test set score: 0.307473\n",
      "\n",
      "Iteration 465, loss = 1.21714395\n",
      "Training set score: 0.658486\n",
      "Test set score: 0.307584\n",
      "\n",
      "Iteration 466, loss = 1.21692351\n",
      "Training set score: 0.658690\n",
      "Test set score: 0.307750\n",
      "\n",
      "Iteration 467, loss = 1.21662067\n",
      "Training set score: 0.658501\n",
      "Test set score: 0.307500\n",
      "\n",
      "Iteration 468, loss = 1.21631755\n",
      "Training set score: 0.658428\n",
      "Test set score: 0.307750\n",
      "\n",
      "Iteration 469, loss = 1.21604238\n",
      "Training set score: 0.658617\n",
      "Test set score: 0.307584\n",
      "\n",
      "Iteration 470, loss = 1.21571662\n",
      "Training set score: 0.658857\n",
      "Test set score: 0.307750\n",
      "\n",
      "Iteration 471, loss = 1.21551979\n",
      "Training set score: 0.658828\n",
      "Test set score: 0.307833\n",
      "\n",
      "Iteration 472, loss = 1.21535724\n",
      "Training set score: 0.658522\n",
      "Test set score: 0.307916\n",
      "\n",
      "Iteration 473, loss = 1.21501985\n",
      "Training set score: 0.658741\n",
      "Test set score: 0.308110\n",
      "\n",
      "Iteration 474, loss = 1.21488350\n",
      "Training set score: 0.658850\n",
      "Test set score: 0.307972\n",
      "\n",
      "Iteration 475, loss = 1.21437838\n",
      "Training set score: 0.658886\n",
      "Test set score: 0.307750\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 476, loss = 1.21416846\n",
      "Training set score: 0.659119\n",
      "Test set score: 0.307972\n",
      "\n",
      "Iteration 477, loss = 1.21378653\n",
      "Training set score: 0.659133\n",
      "Test set score: 0.307944\n",
      "\n",
      "Iteration 478, loss = 1.21362736\n",
      "Training set score: 0.658944\n",
      "Test set score: 0.308193\n",
      "\n",
      "Iteration 479, loss = 1.21347069\n",
      "Training set score: 0.659264\n",
      "Test set score: 0.308193\n",
      "\n",
      "Iteration 480, loss = 1.21307425\n",
      "Training set score: 0.659344\n",
      "Test set score: 0.308055\n",
      "\n",
      "Iteration 481, loss = 1.21297024\n",
      "Training set score: 0.659271\n",
      "Test set score: 0.307722\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 482, loss = 1.21257745\n",
      "Training set score: 0.659111\n",
      "Test set score: 0.308110\n",
      "\n",
      "Iteration 483, loss = 1.21241685\n",
      "Training set score: 0.659490\n",
      "Test set score: 0.307805\n",
      "\n",
      "Iteration 484, loss = 1.21217768\n",
      "Training set score: 0.659388\n",
      "Test set score: 0.307999\n",
      "\n",
      "Iteration 485, loss = 1.21193898\n",
      "Training set score: 0.659577\n",
      "Test set score: 0.308055\n",
      "\n",
      "Iteration 486, loss = 1.21165869\n",
      "Training set score: 0.659446\n",
      "Test set score: 0.308138\n",
      "\n",
      "Iteration 487, loss = 1.21137255\n",
      "Training set score: 0.659540\n",
      "Test set score: 0.308165\n",
      "\n",
      "Iteration 488, loss = 1.21114482\n",
      "Training set score: 0.659540\n",
      "Test set score: 0.307611\n",
      "\n",
      "Iteration 489, loss = 1.21084913\n",
      "Training set score: 0.659671\n",
      "Test set score: 0.308055\n",
      "\n",
      "Iteration 490, loss = 1.21079132\n",
      "Training set score: 0.659380\n",
      "Test set score: 0.308221\n",
      "\n",
      "Iteration 491, loss = 1.21037540\n",
      "Training set score: 0.659526\n",
      "Test set score: 0.308526\n",
      "\n",
      "Iteration 492, loss = 1.21032457\n",
      "Training set score: 0.659424\n",
      "Test set score: 0.308359\n",
      "\n",
      "Iteration 493, loss = 1.20997727\n",
      "Training set score: 0.659802\n",
      "Test set score: 0.308470\n",
      "\n",
      "Iteration 494, loss = 1.20982389\n",
      "Training set score: 0.659446\n",
      "Test set score: 0.308249\n",
      "\n",
      "Iteration 495, loss = 1.20947877\n",
      "Training set score: 0.659482\n",
      "Test set score: 0.308747\n",
      "\n",
      "Iteration 496, loss = 1.20923935\n",
      "Training set score: 0.659548\n",
      "Test set score: 0.308387\n",
      "\n",
      "Iteration 497, loss = 1.20909441\n",
      "Training set score: 0.659271\n",
      "Test set score: 0.309412\n",
      "\n",
      "Iteration 498, loss = 1.20876769\n",
      "Training set score: 0.659664\n",
      "Test set score: 0.308886\n",
      "\n",
      "Iteration 499, loss = 1.20855423\n",
      "Training set score: 0.659540\n",
      "Test set score: 0.308526\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n",
      "Iteration 500, loss = 1.20842413\n",
      "Training set score: 0.659591\n",
      "Test set score: 0.308387\n",
      "\n",
      "Test scores decreased in last 2 iter. Stopping.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "# mlp = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=400, alpha=1e-4,\n",
    "#                     solver='sgd', verbose=10, tol=1e-4, random_state=1)\n",
    "mlp5 = MLPClassifier(hidden_layer_sizes=(200,), max_iter=1, alpha=1e-4,\n",
    "                    solver='sgd', verbose=10, tol=1e-4, random_state=1,\n",
    "                    learning_rate_init=.01, learning_rate='adaptive',\n",
    "                    warm_start=True)\n",
    "test_scores = []\n",
    "for i in range(500):\n",
    "    mlp5.fit(X_train, Y_train)\n",
    "    print(\"Training set score: %f\" % mlp5.score(X_train, Y_train))\n",
    "    sc = mlp5.score(X_test, Y_test)\n",
    "    print(\"Test set score: %f\" % sc)\n",
    "    print()\n",
    "    test_scores.append(sc)\n",
    "    if i>2 and test_scores[i] < test_scores[i-1] and test_scores[i-1] < test_scores[i-2]:\n",
    "        print('Test scores decreased in last 2 iter. Stopping.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.859484777518\n",
      "maxlen 496\n"
     ]
    }
   ],
   "source": [
    "# segment acc\n",
    "from scipy import stats\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "# test\n",
    "maxlen = 0\n",
    "for speaker_id, feature_list in test.items():\n",
    "    speaker_id = idx[speaker_id]\n",
    "    for features in feature_list:\n",
    "        maxlen = max(maxlen, features.shape[1])\n",
    "        x = []\n",
    "        # y = []\n",
    "        frames = concat(features)\n",
    "        for frame in frames:\n",
    "            x.append(frame)\n",
    "            # y.append(speaker_id)\n",
    "        x = scaler.transform(x)\n",
    "        pred = stats.mode(mlp5.predict(x)).mode[0]\n",
    "        y_true.append(speaker_id)\n",
    "        y_pred.append(pred)\n",
    "print(sum(np.array(y_true) == np.array(y_pred))/len(y_true))\n",
    "print('maxlen', maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.975\n",
      "maxlen 496\n"
     ]
    }
   ],
   "source": [
    "# all segment acc ~ file\n",
    "from scipy import stats\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "# test\n",
    "maxlen = 0\n",
    "for speaker_id, feature_list in test.items():\n",
    "    speaker_id = idx[speaker_id]\n",
    "    x = []\n",
    "    for features in feature_list:\n",
    "        maxlen = max(maxlen, features.shape[1])\n",
    "        # y = []\n",
    "        frames = concat(features)\n",
    "        for frame in frames:\n",
    "            x.append(frame)\n",
    "            # y.append(speaker_id)\n",
    "    x = scaler.transform(x)\n",
    "    pred = stats.mode(mlp5.predict(x)).mode[0]\n",
    "    y_true.append(speaker_id)\n",
    "    y_pred.append(pred)\n",
    "print(sum(np.array(y_true) == np.array(y_pred))/len(y_true))\n",
    "print('maxlen', maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
